[
    {
        "pre_patch": "  void UpdateNetworkManagerStatus() {\n    if (!BrowserThread::CurrentlyOn(BrowserThread::UI)) {\n      BrowserThread::PostTask(\n          BrowserThread::UI, FROM_HERE,\n          NewRunnableMethod(this,\n                            &NetworkLibraryImpl::UpdateNetworkManagerStatus));\n      return;\n    }\n\n    SystemInfo* system = GetSystemInfo();\n    if (!system)\n      return;\n\n\n    std::string prev_cellular_service_path = cellular_ ?\n        cellular_->service_path() : std::string();\n\n    ClearNetworks();\n\n    ParseSystem(system, &ethernet_, &wifi_networks_, &cellular_networks_,\n                &remembered_wifi_networks_);\n\n    wifi_ = NULL;\n    for (size_t i = 0; i < wifi_networks_.size(); i++) {\n      if (wifi_networks_[i]->connecting_or_connected()) {\n        wifi_ = wifi_networks_[i];\n        break;  // There is only one connected or connecting wifi network.\n      }\n    }\n    cellular_ = NULL;\n     for (size_t i = 0; i < cellular_networks_.size(); i++) {\n       if (cellular_networks_[i]->connecting_or_connected()) {\n         cellular_ = cellular_networks_[i];\n         if (cellular_networks_[i]->service_path() !=\n                 prev_cellular_service_path) {\n          CellularDataPlanList* list = RetrieveCellularDataPlans(\n              cellular_->service_path().c_str());\n          UpdateCellularDataPlan(list);\n          FreeCellularDataPlanList(list);\n         }\n         break;  // There is only one connected or connecting cellular network.\n       }\n    }\n\n    available_devices_ = system->available_technologies;\n    enabled_devices_ = system->enabled_technologies;\n    connected_devices_ = system->connected_technologies;\n    offline_mode_ = system->offline_mode;\n\n    NotifyNetworkManagerChanged();\n    FreeSystemInfo(system);\n  }\n",
        "post_patch": "  void UpdateNetworkManagerStatus() {\n    if (!BrowserThread::CurrentlyOn(BrowserThread::UI)) {\n      BrowserThread::PostTask(\n          BrowserThread::UI, FROM_HERE,\n          NewRunnableMethod(this,\n                            &NetworkLibraryImpl::UpdateNetworkManagerStatus));\n      return;\n    }\n\n    SystemInfo* system = GetSystemInfo();\n    if (!system)\n      return;\n\n\n    std::string prev_cellular_service_path = cellular_ ?\n        cellular_->service_path() : std::string();\n\n    ClearNetworks();\n\n    ParseSystem(system, &ethernet_, &wifi_networks_, &cellular_networks_,\n                &remembered_wifi_networks_);\n\n    wifi_ = NULL;\n    for (size_t i = 0; i < wifi_networks_.size(); i++) {\n      if (wifi_networks_[i]->connecting_or_connected()) {\n        wifi_ = wifi_networks_[i];\n        break;  // There is only one connected or connecting wifi network.\n      }\n    }\n    cellular_ = NULL;\n     for (size_t i = 0; i < cellular_networks_.size(); i++) {\n       if (cellular_networks_[i]->connecting_or_connected()) {\n         cellular_ = cellular_networks_[i];\n        // If new cellular, then request update of the data plan list.\n         if (cellular_networks_[i]->service_path() !=\n                 prev_cellular_service_path) {\n          RefreshCellularDataPlans(cellular_);\n         }\n         break;  // There is only one connected or connecting cellular network.\n       }\n    }\n\n    available_devices_ = system->available_technologies;\n    enabled_devices_ = system->enabled_technologies;\n    connected_devices_ = system->connected_technologies;\n    offline_mode_ = system->offline_mode;\n\n    NotifyNetworkManagerChanged();\n    FreeSystemInfo(system);\n  }\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "int64 ClientUsageTracker::GetCachedHostUsage(const std::string& host) {\n   HostUsageMap::const_iterator found = cached_usage_.find(host);\n   if (found == cached_usage_.end())\n     return 0;\n\n  int64 usage = 0;\n  const UsageMap& map = found->second;\n  for (UsageMap::const_iterator iter = map.begin();\n       iter != map.end(); ++iter) {\n    usage += iter->second;\n  }\n  return usage;\n}\n",
        "post_patch": "int64 ClientUsageTracker::GetCachedHostUsage(const std::string& host) {\nint64 ClientUsageTracker::GetCachedHostUsage(const std::string& host) const {\n   HostUsageMap::const_iterator found = cached_usage_.find(host);\n   if (found == cached_usage_.end())\n     return 0;\n\n  int64 usage = 0;\n  const UsageMap& map = found->second;\n  for (UsageMap::const_iterator iter = map.begin();\n       iter != map.end(); ++iter) {\n    usage += iter->second;\n  }\n  return usage;\n}\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "void AddInstallerCopyTasks(const InstallerState& installer_state,\n                           const FilePath& setup_path,\n                           const FilePath& archive_path,\n                           const FilePath& temp_path,\n                           const Version& new_version,\n                           WorkItemList* install_list) {\n  DCHECK(install_list);\n  FilePath installer_dir(installer_state.GetInstallerDirectory(new_version));\n  install_list->AddCreateDirWorkItem(installer_dir);\n\n   FilePath exe_dst(installer_dir.Append(setup_path.BaseName()));\n   FilePath archive_dst(installer_dir.Append(archive_path.BaseName()));\n \n  install_list->AddMoveTreeWorkItem(setup_path.value(), exe_dst.value(),\n                                    temp_path.value(), WorkItem::ALWAYS_MOVE);\n   install_list->AddMoveTreeWorkItem(archive_path.value(), archive_dst.value(),\n                                     temp_path.value(), WorkItem::ALWAYS_MOVE);\n }\n",
        "post_patch": "void AddInstallerCopyTasks(const InstallerState& installer_state,\n                           const FilePath& setup_path,\n                           const FilePath& archive_path,\n                           const FilePath& temp_path,\n                           const Version& new_version,\n                           WorkItemList* install_list) {\n  DCHECK(install_list);\n  FilePath installer_dir(installer_state.GetInstallerDirectory(new_version));\n  install_list->AddCreateDirWorkItem(installer_dir);\n\n   FilePath exe_dst(installer_dir.Append(setup_path.BaseName()));\n   FilePath archive_dst(installer_dir.Append(archive_path.BaseName()));\n \n  install_list->AddCopyTreeWorkItem(setup_path.value(), exe_dst.value(),\n                                    temp_path.value(), WorkItem::ALWAYS);\n\n  // otherwise), there is no need to do this for the archive.  Setup.exe, on\n  // the other hand, is created elsewhere so it must always be copied.\n   install_list->AddMoveTreeWorkItem(archive_path.value(), archive_dst.value(),\n                                     temp_path.value(), WorkItem::ALWAYS_MOVE);\n }\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "bool decode(ArgumentDecoder* decoder, RetainPtr<CFURLRef>& result)\n{\n    RetainPtr<CFURLRef> baseURL;\n    bool hasBaseURL;\n    if (!decoder->decodeBool(hasBaseURL))\n        return false;\n    if (hasBaseURL) {\n        if (!decode(decoder, baseURL))\n            return false;\n    }\n\n    RetainPtr<CFStringRef> string;\n     if (!decode(decoder, string))\n         return false;\n \n     CFURLRef url = CFURLCreateWithString(0, string.get(), baseURL.get());\n     if (!url)\n         return false;\n\n    result.adoptCF(url);\n    return true;\n}\n",
        "post_patch": "bool decode(ArgumentDecoder* decoder, RetainPtr<CFURLRef>& result)\n{\n    RetainPtr<CFURLRef> baseURL;\n    bool hasBaseURL;\n    if (!decoder->decodeBool(hasBaseURL))\n        return false;\n    if (hasBaseURL) {\n        if (!decode(decoder, baseURL))\n            return false;\n    }\n\n    RetainPtr<CFStringRef> string;\n     if (!decode(decoder, string))\n         return false;\n \n#if PLATFORM(MAC)\n    // FIXME: Move this to ArgumentCodersCFMac.mm and change this file back to be C++\n    // instead of Objective-C++.\n    if (!CFStringGetLength(string.get())) {\n        // CFURL can't hold an empty URL, unlike NSURL.\n        result = reinterpret_cast<CFURLRef>([NSURL URLWithString:@\"\"]);\n        return true;\n    }\n#endif\n                    \n     CFURLRef url = CFURLCreateWithString(0, string.get(), baseURL.get());\n     if (!url)\n         return false;\n\n    result.adoptCF(url);\n    return true;\n}\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "void WebProcessProxy::addExistingWebPage(WebPageProxy* webPage, uint64_t pageID)\n{\n     m_pageMap.set(pageID, webPage);\n     globalPageMap().set(pageID, webPage);\n #if PLATFORM(MAC)\n    if (pageIsProcessSuppressible(webPage));\n         m_processSuppressiblePages.add(pageID);\n     updateProcessSuppressionState();\n #endif\n}\n",
        "post_patch": "void WebProcessProxy::addExistingWebPage(WebPageProxy* webPage, uint64_t pageID)\n{\n     m_pageMap.set(pageID, webPage);\n     globalPageMap().set(pageID, webPage);\n #if PLATFORM(MAC)\n    if (pageIsProcessSuppressible(webPage))\n         m_processSuppressiblePages.add(pageID);\n     updateProcessSuppressionState();\n #endif\n}\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "v8::Handle<v8::Value> V8ThrowException::createDOMException(v8::Isolate* isolate, int ec, const String& sanitizedMessage, const String& unsanitizedMessage, const v8::Handle<v8::Object>& creationContext)\n{\n    if (ec <= 0 || v8::V8::IsExecutionTerminating())\n        return v8Undefined();\n\n    ASSERT(ec == SecurityError || unsanitizedMessage.isEmpty());\n\n    if (ec == V8GeneralError)\n        return V8ThrowException::createGeneralError(isolate, sanitizedMessage);\n    if (ec == V8TypeError)\n        return V8ThrowException::createTypeError(isolate, sanitizedMessage);\n    if (ec == V8RangeError)\n        return V8ThrowException::createRangeError(isolate, sanitizedMessage);\n    if (ec == V8SyntaxError)\n        return V8ThrowException::createSyntaxError(isolate, sanitizedMessage);\n     if (ec == V8ReferenceError)\n         return V8ThrowException::createReferenceError(isolate, sanitizedMessage);\n \n     RefPtrWillBeRawPtr<DOMException> domException = DOMException::create(ec, sanitizedMessage, unsanitizedMessage);\n    v8::Handle<v8::Value> exception = toV8(domException.get(), creationContext, isolate);\n \n     if (exception.IsEmpty())\n         return v8Undefined();\n\n    v8::Handle<v8::Value> error = v8::Exception::Error(v8String(isolate, domException->message()));\n    ASSERT(!error.IsEmpty());\n    ASSERT(exception->IsObject());\n    exception->ToObject(isolate)->SetAccessor(v8AtomicString(isolate, \"stack\"), domExceptionStackGetter, domExceptionStackSetter, error);\n    V8HiddenValue::setHiddenValue(isolate, exception->ToObject(isolate), V8HiddenValue::error(isolate), error);\n\n    return exception;\n}\n",
        "post_patch": "v8::Handle<v8::Value> V8ThrowException::createDOMException(v8::Isolate* isolate, int ec, const String& sanitizedMessage, const String& unsanitizedMessage, const v8::Handle<v8::Object>& creationContext)\n{\n    if (ec <= 0 || v8::V8::IsExecutionTerminating())\n        return v8Undefined();\n\n    ASSERT(ec == SecurityError || unsanitizedMessage.isEmpty());\n\n    if (ec == V8GeneralError)\n        return V8ThrowException::createGeneralError(isolate, sanitizedMessage);\n    if (ec == V8TypeError)\n        return V8ThrowException::createTypeError(isolate, sanitizedMessage);\n    if (ec == V8RangeError)\n        return V8ThrowException::createRangeError(isolate, sanitizedMessage);\n    if (ec == V8SyntaxError)\n        return V8ThrowException::createSyntaxError(isolate, sanitizedMessage);\n     if (ec == V8ReferenceError)\n         return V8ThrowException::createReferenceError(isolate, sanitizedMessage);\n \n    v8::Handle<v8::Object> sanitizedCreationContext = creationContext;\n\n    // FIXME: Is the current context always the right choice?\n    Frame* frame = toFrameIfNotDetached(creationContext->CreationContext());\n    if (!frame || !BindingSecurity::shouldAllowAccessToFrame(isolate, frame, DoNotReportSecurityError))\n        sanitizedCreationContext = isolate->GetCurrentContext()->Global();\n\n\n     RefPtrWillBeRawPtr<DOMException> domException = DOMException::create(ec, sanitizedMessage, unsanitizedMessage);\n    v8::Handle<v8::Value> exception = toV8(domException.get(), sanitizedCreationContext, isolate);\n \n     if (exception.IsEmpty())\n         return v8Undefined();\n\n    v8::Handle<v8::Value> error = v8::Exception::Error(v8String(isolate, domException->message()));\n    ASSERT(!error.IsEmpty());\n    ASSERT(exception->IsObject());\n    exception->ToObject(isolate)->SetAccessor(v8AtomicString(isolate, \"stack\"), domExceptionStackGetter, domExceptionStackSetter, error);\n    V8HiddenValue::setHiddenValue(isolate, exception->ToObject(isolate), V8HiddenValue::error(isolate), error);\n\n    return exception;\n}\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "void OverlayWindowViews::OnGestureEvent(ui::GestureEvent* event) {\n  if (event->type() != ui::ET_GESTURE_TAP)\n    return;\n\n  hide_controls_timer_.Reset();\n\n  if (!GetControlsScrimLayer()->visible()) {\n    UpdateControlsVisibility(true);\n    return;\n  }\n\n  if (GetCloseControlsBounds().Contains(event->location())) {\n    controller_->Close(true /* should_pause_video */,\n                       true /* should_reset_pip_player */);\n    event->SetHandled();\n  } else if (GetPlayPauseControlsBounds().Contains(event->location())) {\n     TogglePlayPause();\n     event->SetHandled();\n   }\n  views::Widget::OnGestureEvent(event);\n }\n",
        "post_patch": "void OverlayWindowViews::OnGestureEvent(ui::GestureEvent* event) {\n  if (event->type() != ui::ET_GESTURE_TAP)\n    return;\n\n  hide_controls_timer_.Reset();\n\n  if (!GetControlsScrimLayer()->visible()) {\n    UpdateControlsVisibility(true);\n    return;\n  }\n\n  if (GetCloseControlsBounds().Contains(event->location())) {\n    controller_->Close(true /* should_pause_video */,\n                       true /* should_reset_pip_player */);\n    event->SetHandled();\n  } else if (GetPlayPauseControlsBounds().Contains(event->location())) {\n     TogglePlayPause();\n     event->SetHandled();\n   }\n }\n",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "static MagickBooleanType GetEXIFProperty(const Image *image,\n  const char *property)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define EXIF_FMT_BYTE  1\n#define EXIF_FMT_STRING  2\n#define EXIF_FMT_USHORT  3\n#define EXIF_FMT_ULONG  4\n#define EXIF_FMT_URATIONAL  5\n#define EXIF_FMT_SBYTE  6\n#define EXIF_FMT_UNDEFINED  7\n#define EXIF_FMT_SSHORT  8\n#define EXIF_FMT_SLONG  9\n#define EXIF_FMT_SRATIONAL  10\n#define EXIF_FMT_SINGLE  11\n#define EXIF_FMT_DOUBLE  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_GPS_OFFSET  0x8825\n#define TAG_INTEROP_OFFSET  0xa005\n\n#define EXIFMultipleValues(size,format,arg) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",arg); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n#define EXIFMultipleFractions(size,format,arg1,arg2) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",(arg1),(arg2)); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n  typedef struct _DirectoryInfo\n  {\n    const unsigned char\n      *directory;\n\n    size_t\n      entry;\n\n    ssize_t\n      offset;\n  } DirectoryInfo;\n\n  typedef struct _TagInfo\n  {\n    size_t\n      tag;\n\n    const char\n      description[36];\n  } TagInfo;\n\n  static const TagInfo\n    EXIFTag[] =\n    {\n      {  0x001, \"exif:InteroperabilityIndex\" },\n      {  0x002, \"exif:InteroperabilityVersion\" },\n      {  0x100, \"exif:ImageWidth\" },\n      {  0x101, \"exif:ImageLength\" },\n      {  0x102, \"exif:BitsPerSample\" },\n      {  0x103, \"exif:Compression\" },\n      {  0x106, \"exif:PhotometricInterpretation\" },\n      {  0x10a, \"exif:FillOrder\" },\n      {  0x10d, \"exif:DocumentName\" },\n      {  0x10e, \"exif:ImageDescription\" },\n      {  0x10f, \"exif:Make\" },\n      {  0x110, \"exif:Model\" },\n      {  0x111, \"exif:StripOffsets\" },\n      {  0x112, \"exif:Orientation\" },\n      {  0x115, \"exif:SamplesPerPixel\" },\n      {  0x116, \"exif:RowsPerStrip\" },\n      {  0x117, \"exif:StripByteCounts\" },\n      {  0x11a, \"exif:XResolution\" },\n      {  0x11b, \"exif:YResolution\" },\n      {  0x11c, \"exif:PlanarConfiguration\" },\n      {  0x11d, \"exif:PageName\" },\n      {  0x11e, \"exif:XPosition\" },\n      {  0x11f, \"exif:YPosition\" },\n      {  0x118, \"exif:MinSampleValue\" },\n      {  0x119, \"exif:MaxSampleValue\" },\n      {  0x120, \"exif:FreeOffsets\" },\n      {  0x121, \"exif:FreeByteCounts\" },\n      {  0x122, \"exif:GrayResponseUnit\" },\n      {  0x123, \"exif:GrayResponseCurve\" },\n      {  0x124, \"exif:T4Options\" },\n      {  0x125, \"exif:T6Options\" },\n      {  0x128, \"exif:ResolutionUnit\" },\n      {  0x12d, \"exif:TransferFunction\" },\n      {  0x131, \"exif:Software\" },\n      {  0x132, \"exif:DateTime\" },\n      {  0x13b, \"exif:Artist\" },\n      {  0x13e, \"exif:WhitePoint\" },\n      {  0x13f, \"exif:PrimaryChromaticities\" },\n      {  0x140, \"exif:ColorMap\" },\n      {  0x141, \"exif:HalfToneHints\" },\n      {  0x142, \"exif:TileWidth\" },\n      {  0x143, \"exif:TileLength\" },\n      {  0x144, \"exif:TileOffsets\" },\n      {  0x145, \"exif:TileByteCounts\" },\n      {  0x14a, \"exif:SubIFD\" },\n      {  0x14c, \"exif:InkSet\" },\n      {  0x14d, \"exif:InkNames\" },\n      {  0x14e, \"exif:NumberOfInks\" },\n      {  0x150, \"exif:DotRange\" },\n      {  0x151, \"exif:TargetPrinter\" },\n      {  0x152, \"exif:ExtraSample\" },\n      {  0x153, \"exif:SampleFormat\" },\n      {  0x154, \"exif:SMinSampleValue\" },\n      {  0x155, \"exif:SMaxSampleValue\" },\n      {  0x156, \"exif:TransferRange\" },\n      {  0x157, \"exif:ClipPath\" },\n      {  0x158, \"exif:XClipPathUnits\" },\n      {  0x159, \"exif:YClipPathUnits\" },\n      {  0x15a, \"exif:Indexed\" },\n      {  0x15b, \"exif:JPEGTables\" },\n      {  0x15f, \"exif:OPIProxy\" },\n      {  0x200, \"exif:JPEGProc\" },\n      {  0x201, \"exif:JPEGInterchangeFormat\" },\n      {  0x202, \"exif:JPEGInterchangeFormatLength\" },\n      {  0x203, \"exif:JPEGRestartInterval\" },\n      {  0x205, \"exif:JPEGLosslessPredictors\" },\n      {  0x206, \"exif:JPEGPointTransforms\" },\n      {  0x207, \"exif:JPEGQTables\" },\n      {  0x208, \"exif:JPEGDCTables\" },\n      {  0x209, \"exif:JPEGACTables\" },\n      {  0x211, \"exif:YCbCrCoefficients\" },\n      {  0x212, \"exif:YCbCrSubSampling\" },\n      {  0x213, \"exif:YCbCrPositioning\" },\n      {  0x214, \"exif:ReferenceBlackWhite\" },\n      {  0x2bc, \"exif:ExtensibleMetadataPlatform\" },\n      {  0x301, \"exif:Gamma\" },\n      {  0x302, \"exif:ICCProfileDescriptor\" },\n      {  0x303, \"exif:SRGBRenderingIntent\" },\n      {  0x320, \"exif:ImageTitle\" },\n      {  0x5001, \"exif:ResolutionXUnit\" },\n      {  0x5002, \"exif:ResolutionYUnit\" },\n      {  0x5003, \"exif:ResolutionXLengthUnit\" },\n      {  0x5004, \"exif:ResolutionYLengthUnit\" },\n      {  0x5005, \"exif:PrintFlags\" },\n      {  0x5006, \"exif:PrintFlagsVersion\" },\n      {  0x5007, \"exif:PrintFlagsCrop\" },\n      {  0x5008, \"exif:PrintFlagsBleedWidth\" },\n      {  0x5009, \"exif:PrintFlagsBleedWidthScale\" },\n      {  0x500A, \"exif:HalftoneLPI\" },\n      {  0x500B, \"exif:HalftoneLPIUnit\" },\n      {  0x500C, \"exif:HalftoneDegree\" },\n      {  0x500D, \"exif:HalftoneShape\" },\n      {  0x500E, \"exif:HalftoneMisc\" },\n      {  0x500F, \"exif:HalftoneScreen\" },\n      {  0x5010, \"exif:JPEGQuality\" },\n      {  0x5011, \"exif:GridSize\" },\n      {  0x5012, \"exif:ThumbnailFormat\" },\n      {  0x5013, \"exif:ThumbnailWidth\" },\n      {  0x5014, \"exif:ThumbnailHeight\" },\n      {  0x5015, \"exif:ThumbnailColorDepth\" },\n      {  0x5016, \"exif:ThumbnailPlanes\" },\n      {  0x5017, \"exif:ThumbnailRawBytes\" },\n      {  0x5018, \"exif:ThumbnailSize\" },\n      {  0x5019, \"exif:ThumbnailCompressedSize\" },\n      {  0x501a, \"exif:ColorTransferFunction\" },\n      {  0x501b, \"exif:ThumbnailData\" },\n      {  0x5020, \"exif:ThumbnailImageWidth\" },\n      {  0x5021, \"exif:ThumbnailImageHeight\" },\n      {  0x5022, \"exif:ThumbnailBitsPerSample\" },\n      {  0x5023, \"exif:ThumbnailCompression\" },\n      {  0x5024, \"exif:ThumbnailPhotometricInterp\" },\n      {  0x5025, \"exif:ThumbnailImageDescription\" },\n      {  0x5026, \"exif:ThumbnailEquipMake\" },\n      {  0x5027, \"exif:ThumbnailEquipModel\" },\n      {  0x5028, \"exif:ThumbnailStripOffsets\" },\n      {  0x5029, \"exif:ThumbnailOrientation\" },\n      {  0x502a, \"exif:ThumbnailSamplesPerPixel\" },\n      {  0x502b, \"exif:ThumbnailRowsPerStrip\" },\n      {  0x502c, \"exif:ThumbnailStripBytesCount\" },\n      {  0x502d, \"exif:ThumbnailResolutionX\" },\n      {  0x502e, \"exif:ThumbnailResolutionY\" },\n      {  0x502f, \"exif:ThumbnailPlanarConfig\" },\n      {  0x5030, \"exif:ThumbnailResolutionUnit\" },\n      {  0x5031, \"exif:ThumbnailTransferFunction\" },\n      {  0x5032, \"exif:ThumbnailSoftwareUsed\" },\n      {  0x5033, \"exif:ThumbnailDateTime\" },\n      {  0x5034, \"exif:ThumbnailArtist\" },\n      {  0x5035, \"exif:ThumbnailWhitePoint\" },\n      {  0x5036, \"exif:ThumbnailPrimaryChromaticities\" },\n      {  0x5037, \"exif:ThumbnailYCbCrCoefficients\" },\n      {  0x5038, \"exif:ThumbnailYCbCrSubsampling\" },\n      {  0x5039, \"exif:ThumbnailYCbCrPositioning\" },\n      {  0x503A, \"exif:ThumbnailRefBlackWhite\" },\n      {  0x503B, \"exif:ThumbnailCopyRight\" },\n      {  0x5090, \"exif:LuminanceTable\" },\n      {  0x5091, \"exif:ChrominanceTable\" },\n      {  0x5100, \"exif:FrameDelay\" },\n      {  0x5101, \"exif:LoopCount\" },\n      {  0x5110, \"exif:PixelUnit\" },\n      {  0x5111, \"exif:PixelPerUnitX\" },\n      {  0x5112, \"exif:PixelPerUnitY\" },\n      {  0x5113, \"exif:PaletteHistogram\" },\n      {  0x1000, \"exif:RelatedImageFileFormat\" },\n      {  0x1001, \"exif:RelatedImageLength\" },\n      {  0x1002, \"exif:RelatedImageWidth\" },\n      {  0x800d, \"exif:ImageID\" },\n      {  0x80e3, \"exif:Matteing\" },\n      {  0x80e4, \"exif:DataType\" },\n      {  0x80e5, \"exif:ImageDepth\" },\n      {  0x80e6, \"exif:TileDepth\" },\n      {  0x828d, \"exif:CFARepeatPatternDim\" },\n      {  0x828e, \"exif:CFAPattern2\" },\n      {  0x828f, \"exif:BatteryLevel\" },\n      {  0x8298, \"exif:Copyright\" },\n      {  0x829a, \"exif:ExposureTime\" },\n      {  0x829d, \"exif:FNumber\" },\n      {  0x83bb, \"exif:IPTC/NAA\" },\n      {  0x84e3, \"exif:IT8RasterPadding\" },\n      {  0x84e5, \"exif:IT8ColorTable\" },\n      {  0x8649, \"exif:ImageResourceInformation\" },\n      {  0x8769, \"exif:ExifOffset\" },  /* specs as \"Exif IFD Pointer\"? */\n      {  0x8773, \"exif:InterColorProfile\" },\n      {  0x8822, \"exif:ExposureProgram\" },\n      {  0x8824, \"exif:SpectralSensitivity\" },\n      {  0x8825, \"exif:GPSInfo\" }, /* specs as \"GPSInfo IFD Pointer\"? */\n      {  0x8827, \"exif:PhotographicSensitivity\" },\n      {  0x8828, \"exif:OECF\" },\n      {  0x8829, \"exif:Interlace\" },      \n      {  0x882a, \"exif:TimeZoneOffset\" },\n      {  0x882b, \"exif:SelfTimerMode\" },\n      {  0x8830, \"exif:SensitivityType\" },\n      {  0x8831, \"exif:StandardOutputSensitivity\" },\n      {  0x8832, \"exif:RecommendedExposureIndex\" },\n      {  0x8833, \"exif:ISOSpeed\" },\n      {  0x8834, \"exif:ISOSpeedLatitudeyyy\" },\n      {  0x8835, \"exif:ISOSpeedLatitudezzz\" },\n      {  0x9000, \"exif:ExifVersion\" },\n      {  0x9003, \"exif:DateTimeOriginal\" },\n      {  0x9004, \"exif:DateTimeDigitized\" },\n      {  0x9010, \"exif:OffsetTime\" },\n      {  0x9011, \"exif:OffsetTimeOriginal\" },\n      {  0x9012, \"exif:OffsetTimeDigitized\" },\n      {  0x9101, \"exif:ComponentsConfiguration\" },\n      {  0x9102, \"exif:CompressedBitsPerPixel\" },\n      {  0x9201, \"exif:ShutterSpeedValue\" },\n      {  0x9202, \"exif:ApertureValue\" },\n      {  0x9203, \"exif:BrightnessValue\" },\n      {  0x9204, \"exif:ExposureBiasValue\" },\n      {  0x9205, \"exif:MaxApertureValue\" },\n      {  0x9206, \"exif:SubjectDistance\" },\n      {  0x9207, \"exif:MeteringMode\" },\n      {  0x9208, \"exif:LightSource\" },\n      {  0x9209, \"exif:Flash\" },\n      {  0x920a, \"exif:FocalLength\" },\n      {  0x920b, \"exif:FlashEnergy\" },\n      {  0x920c, \"exif:SpatialFrequencyResponse\" },\n      {  0x920d, \"exif:Noise\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9211, \"exif:ImageNumber\" },\n      {  0x9212, \"exif:SecurityClassification\" },\n      {  0x9213, \"exif:ImageHistory\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9215, \"exif:ExposureIndex\" },\n      {  0x9216, \"exif:TIFF-EPStandardID\" },\n      {  0x927c, \"exif:MakerNote\" },\n      {  0x9286, \"exif:UserComment\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9400, \"exif:Temperature\" },\n      {  0x9401, \"exif:Humidity\" },\n      {  0x9402, \"exif:Pressure\" },\n      {  0x9403, \"exif:WaterDepth\" },\n      {  0x9404, \"exif:Acceleration\" },\n      {  0x9405, \"exif:CameraElevationAngle\" },    \n      {  0x9C9b, \"exif:WinXP-Title\" },\n      {  0x9C9c, \"exif:WinXP-Comments\" },\n      {  0x9C9d, \"exif:WinXP-Author\" },\n      {  0x9C9e, \"exif:WinXP-Keywords\" },\n      {  0x9C9f, \"exif:WinXP-Subject\" },      \n      {  0xa000, \"exif:FlashPixVersion\" },\n      {  0xa001, \"exif:ColorSpace\" },\n      {  0xa002, \"exif:PixelXDimension\" },\n      {  0xa003, \"exif:PixelYDimension\" },\n      {  0xa004, \"exif:RelatedSoundFile\" },\n      {  0xa005, \"exif:InteroperabilityOffset\" },\n      {  0xa20b, \"exif:FlashEnergy\" },\n      {  0xa20c, \"exif:SpatialFrequencyResponse\" },\n      {  0xa20d, \"exif:Noise\" },\n      {  0xa20e, \"exif:FocalPlaneXResolution\" },\n      {  0xa20f, \"exif:FocalPlaneYResolution\" },\n      {  0xa210, \"exif:FocalPlaneResolutionUnit\" },\n      {  0xa214, \"exif:SubjectLocation\" },\n      {  0xa215, \"exif:ExposureIndex\" },\n      {  0xa216, \"exif:TIFF/EPStandardID\" },\n      {  0xa217, \"exif:SensingMethod\" },\n      {  0xa300, \"exif:FileSource\" },\n      {  0xa301, \"exif:SceneType\" },\n      {  0xa302, \"exif:CFAPattern\" },\n      {  0xa401, \"exif:CustomRendered\" },\n      {  0xa402, \"exif:ExposureMode\" },\n      {  0xa403, \"exif:WhiteBalance\" },\n      {  0xa404, \"exif:DigitalZoomRatio\" },\n      {  0xa405, \"exif:FocalLengthIn35mmFilm\" },\n      {  0xa406, \"exif:SceneCaptureType\" },\n      {  0xa407, \"exif:GainControl\" },\n      {  0xa408, \"exif:Contrast\" },\n      {  0xa409, \"exif:Saturation\" },\n      {  0xa40a, \"exif:Sharpness\" },\n      {  0xa40b, \"exif:DeviceSettingDescription\" },\n      {  0xa40c, \"exif:SubjectDistanceRange\" },\n      {  0xa420, \"exif:ImageUniqueID\" },\n      {  0xa430, \"exif:CameraOwnerName\" },\n      {  0xa431, \"exif:BodySerialNumber\" },\n      {  0xa432, \"exif:LensSpecification\" },\n      {  0xa433, \"exif:LensMake\" },\n      {  0xa434, \"exif:LensModel\" },\n      {  0xa435, \"exif:LensSerialNumber\" },\n      {  0xc4a5, \"exif:PrintImageMatching\" },\n      {  0xa500, \"exif:Gamma\" },\n      {  0xc640, \"exif:CR2Slice\" },\n      { 0x10000, \"exif:GPSVersionID\" },\n      { 0x10001, \"exif:GPSLatitudeRef\" },\n      { 0x10002, \"exif:GPSLatitude\" },\n      { 0x10003, \"exif:GPSLongitudeRef\" },\n      { 0x10004, \"exif:GPSLongitude\" },\n      { 0x10005, \"exif:GPSAltitudeRef\" },\n      { 0x10006, \"exif:GPSAltitude\" },\n      { 0x10007, \"exif:GPSTimeStamp\" },\n      { 0x10008, \"exif:GPSSatellites\" },\n      { 0x10009, \"exif:GPSStatus\" },\n      { 0x1000a, \"exif:GPSMeasureMode\" },\n      { 0x1000b, \"exif:GPSDop\" },\n      { 0x1000c, \"exif:GPSSpeedRef\" },\n      { 0x1000d, \"exif:GPSSpeed\" },\n      { 0x1000e, \"exif:GPSTrackRef\" },\n      { 0x1000f, \"exif:GPSTrack\" },\n      { 0x10010, \"exif:GPSImgDirectionRef\" },\n      { 0x10011, \"exif:GPSImgDirection\" },\n      { 0x10012, \"exif:GPSMapDatum\" },\n      { 0x10013, \"exif:GPSDestLatitudeRef\" },\n      { 0x10014, \"exif:GPSDestLatitude\" },\n      { 0x10015, \"exif:GPSDestLongitudeRef\" },\n      { 0x10016, \"exif:GPSDestLongitude\" },\n      { 0x10017, \"exif:GPSDestBearingRef\" },\n      { 0x10018, \"exif:GPSDestBearing\" },\n      { 0x10019, \"exif:GPSDestDistanceRef\" },\n      { 0x1001a, \"exif:GPSDestDistance\" },\n      { 0x1001b, \"exif:GPSProcessingMethod\" },\n      { 0x1001c, \"exif:GPSAreaInformation\" },\n      { 0x1001d, \"exif:GPSDateStamp\" },\n      { 0x1001e, \"exif:GPSDifferential\" },\n      { 0x1001f, \"exif:GPSHPositioningError\" },\n      { 0x00000, \"\" }\n    };  /* http://www.cipa.jp/std/documents/e/DC-008-Translation-2016-E.pdf */\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *directory,\n    *exif;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  MagickBooleanType\n    status;\n\n  ssize_t\n    i;\n\n  size_t\n    entry,\n    length,\n    number_entries,\n    tag,\n    tag_value;\n\n  SplayTreeInfo\n    *exif_resources;\n\n  ssize_t\n    all,\n    id,\n    level,\n    offset,\n    tag_offset;\n\n  static int\n    tag_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  /*\n    If EXIF data exists, then try to parse the request for a tag.\n  */\n  profile=GetImageProfile(image,\"exif\");\n  if (profile == (const StringInfo *) NULL)\n    return(MagickFalse);\n  if ((property == (const char *) NULL) || (*property == '\\0'))\n    return(MagickFalse);\n  while (isspace((int) ((unsigned char) *property)) != 0)\n    property++;\n  if (strlen(property) <= 5)\n    return(MagickFalse);\n  all=0;\n  tag=(~0UL);\n  switch (*(property+5))\n  {\n    case '*':\n    {\n      /*\n        Caller has asked for all the tags in the EXIF data.\n      */\n      tag=0;\n      all=1; /* return the data in description=value format */\n      break;\n    }\n    case '!':\n    {\n      tag=0;\n      all=2; /* return the data in tagid=value format */\n      break;\n    }\n    case '#':\n    case '@':\n    {\n      int\n        c;\n\n      size_t\n        n;\n\n      /*\n        Check for a hex based tag specification first.\n      */\n      tag=(*(property+5) == '@') ? 1UL : 0UL;\n      property+=6;\n      n=strlen(property);\n      if (n != 4)\n        return(MagickFalse);\n      /*\n        Parse tag specification as a hex number.\n      */\n      n/=4;\n      do\n      {\n        for (i=(ssize_t) n-1L; i >= 0; i--)\n        {\n          c=(*property++);\n          tag<<=4;\n          if ((c >= '0') && (c <= '9'))\n            tag|=(c-'0');\n          else\n            if ((c >= 'A') && (c <= 'F'))\n              tag|=(c-('A'-10));\n            else\n              if ((c >= 'a') && (c <= 'f'))\n                tag|=(c-('a'-10));\n              else\n                return(MagickFalse);\n        }\n      } while (*property != '\\0');\n      break;\n    }\n    default:\n    {\n      /*\n        Try to match the text with a tag name instead.\n      */\n      for (i=0; ; i++)\n      {\n        if (EXIFTag[i].tag == 0)\n          break;\n        if (LocaleCompare(EXIFTag[i].description,property) == 0)\n          {\n            tag=(size_t) EXIFTag[i].tag;\n            break;\n          }\n      }\n      break;\n    }\n  }\n  if (tag == (~0UL))\n    return(MagickFalse);\n  length=GetStringInfoLength(profile);\n  if (length < 6)\n    return(MagickFalse);\n  exif=GetStringInfoDatum(profile);\n  while (length != 0)\n  {\n    if (ReadPropertyByte(&exif,&length) != 0x45)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x78)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x69)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x66)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    break;\n  }\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadPropertySignedShort(LSBEndian,exif);\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadPropertyUnsignedShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadPropertySignedLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  /*\n    Set the pointer to the first IFD and follow it were it leads.\n  */\n  status=MagickFalse;\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  tag_offset=0;\n  exif_resources=NewSplayTree((int (*)(const void *,const void *)) NULL,\n    (void *(*)(void *)) NULL,(void *(*)(void *)) NULL);\n  do\n  {\n    /*\n      If there is anything on the stack then pop it off.\n    */\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n        tag_offset=directory_stack[level].offset;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=(size_t) ReadPropertyUnsignedShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      unsigned char\n        *p,\n        *q;\n\n      size_t\n        format;\n\n      ssize_t\n        number_bytes,\n        components;\n\n      q=(unsigned char *) (directory+(12*entry)+2);\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      if (GetValueFromSplayTree(exif_resources,q) == q)\n        break;\n      (void) AddValueToSplayTree(exif_resources,q,q);\n      tag_value=(size_t) ReadPropertyUnsignedShort(endian,q)+tag_offset;\n      format=(size_t) ReadPropertyUnsignedShort(endian,q+2);\n      if (format >= (sizeof(tag_bytes)/sizeof(*tag_bytes)))\n        break;\n      if (format == 0)\n        break;  /* corrupt EXIF */\n      components=(ssize_t) ReadPropertySignedLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*tag_bytes[format];\n      if (number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          ssize_t\n            dir_offset;\n\n          /*\n            The directory entry contains an offset.\n          */\n          dir_offset=(ssize_t) ReadPropertySignedLong(endian,q+8);\n          if ((dir_offset < 0) || (size_t) dir_offset >= length)\n            continue;\n          if (((size_t) dir_offset+number_bytes) < (size_t) dir_offset)\n            continue;  /* prevent overflow */\n          if (((size_t) dir_offset+number_bytes) > length)\n            continue;\n          p=(unsigned char *) (exif+dir_offset);\n        }\n      if ((all != 0) || (tag == (size_t) tag_value))\n        {\n          char\n            buffer[MaxTextExtent],\n            *value;\n\n          if ((p < exif) || (p > (exif+length-tag_bytes[format])))\n            break;\n          value=(char *) NULL;\n          *buffer='\\0';\n          switch (format)\n          {\n            case EXIF_FMT_BYTE:\n            case EXIF_FMT_UNDEFINED:\n            {\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if (isprint((int) p[i]) != 0) \n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n            case EXIF_FMT_SBYTE:\n            {\n              EXIFMultipleValues(1,\"%.20g\",(double) (*(signed char *) p1));\n              break;\n            }\n            case EXIF_FMT_SSHORT:\n            {\n              EXIFMultipleValues(2,\"%hd\",ReadPropertySignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_USHORT:\n            {\n              EXIFMultipleValues(2,\"%hu\",ReadPropertyUnsignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_ULONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_SLONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertySignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_URATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1),(double)\n                ReadPropertyUnsignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SRATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertySignedLong(endian,p1),(double)\n                ReadPropertySignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SINGLE:\n            {\n              EXIFMultipleValues(4,\"%f\",(double) *(float *) p1);\n              break;\n            }\n            case EXIF_FMT_DOUBLE:\n            {\n              EXIFMultipleValues(8,\"%f\",*(double *) p1);\n              break;\n            }\n            case EXIF_FMT_STRING:\n            default:\n            {\n              if ((p < exif) || (p > (exif+length-number_bytes)))\n                break;\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  ssize_t\n                    i;\n\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if ((isprint((int) p[i]) != 0) || (p[i] == '\\0'))\n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n          }\n          if (value != (char *) NULL)\n            {\n              char\n                *key;\n\n              const char\n                *p;\n\n              key=AcquireString(property);\n              switch (all)\n              {\n                case 1:\n                {\n                  const char\n                    *description;\n\n                  ssize_t\n                    i;\n\n                  description=\"unknown\";\n                  for (i=0; ; i++)\n                  {\n                    if (EXIFTag[i].tag == 0)\n                      break;\n                    if (EXIFTag[i].tag == tag_value)\n                      {\n                        description=EXIFTag[i].description;\n                        break;\n                      }\n                  }\n                  (void) FormatLocaleString(key,MaxTextExtent,\"%s\",\n                    description);\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                  break;\n                }\n                case 2:\n                {\n                  if (tag_value < 0x10000)\n                    (void) FormatLocaleString(key,MaxTextExtent,\"#%04lx\",\n                      (unsigned long) tag_value);\n                  else\n                    if (tag_value < 0x20000)\n                      (void) FormatLocaleString(key,MaxTextExtent,\"@%04lx\",\n                        (unsigned long) (tag_value & 0xffff));\n                    else\n                      (void) FormatLocaleString(key,MaxTextExtent,\"unknown\");\n                  break;\n                }\n                default:\n                {\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                }\n              }\n              p=(const char *) NULL;\n              if (image->properties != (void *) NULL)\n                p=(const char *) GetValueFromSplayTree((SplayTreeInfo *)\n                  image->properties,key);\n              if (p == (const char *) NULL)\n                (void) SetImageProperty((Image *) image,key,value);\n              value=DestroyString(value);\n              key=DestroyString(key);\n              status=MagickTrue;\n            }\n        }\n        if ((tag_value == TAG_EXIF_OFFSET) ||\n            (tag_value == TAG_INTEROP_OFFSET) || (tag_value == TAG_GPS_OFFSET))\n          {\n            ssize_t\n              offset;\n\n            offset=(ssize_t) ReadPropertySignedLong(endian,p);\n            if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n              {\n                ssize_t\n                  tag_offset1;\n\n                tag_offset1=(ssize_t) ((tag_value == TAG_GPS_OFFSET) ? 0x10000 :\n                  0);\n                directory_stack[level].directory=directory;\n                entry++;\n                directory_stack[level].entry=entry;\n                directory_stack[level].offset=tag_offset;\n                level++;\n                /*\n                  Check for duplicate tag.\n                */\n                for (i=0; i < level; i++)\n                  if (directory_stack[i].directory == (exif+tag_offset1))\n                    break;\n                if (i < level)\n                  break;  /* duplicate tag */\n                directory_stack[level].directory=exif+offset;\n                directory_stack[level].offset=tag_offset1;\n                directory_stack[level].entry=0;\n                level++;\n                if ((directory+2+(12*number_entries)+4) > (exif+length))\n                  break;\n                offset=(ssize_t) ReadPropertySignedLong(endian,directory+2+(12*\n                  number_entries));\n                if ((offset != 0) && ((size_t) offset < length) &&\n                    (level < (MaxDirectoryStack-2)))\n                  {\n                    directory_stack[level].directory=exif+offset;\n                    directory_stack[level].entry=0;\n                    directory_stack[level].offset=tag_offset1;\n                    level++;\n                  }\n              }\n            break;\n          }\n    }\n  } while (level > 0);\n  exif_resources=DestroySplayTree(exif_resources);\n  return(status);\n}",
        "post_patch": "static MagickBooleanType GetEXIFProperty(const Image *image,\n  const char *property)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define EXIF_FMT_BYTE  1\n#define EXIF_FMT_STRING  2\n#define EXIF_FMT_USHORT  3\n#define EXIF_FMT_ULONG  4\n#define EXIF_FMT_URATIONAL  5\n#define EXIF_FMT_SBYTE  6\n#define EXIF_FMT_UNDEFINED  7\n#define EXIF_FMT_SSHORT  8\n#define EXIF_FMT_SLONG  9\n#define EXIF_FMT_SRATIONAL  10\n#define EXIF_FMT_SINGLE  11\n#define EXIF_FMT_DOUBLE  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_GPS_OFFSET  0x8825\n#define TAG_INTEROP_OFFSET  0xa005\n\n#define EXIFMultipleValues(size,format,arg) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",arg); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n#define EXIFMultipleFractions(size,format,arg1,arg2) \\\n{ \\\n   ssize_t \\\n     component; \\\n \\\n   size_t \\\n     length; \\\n \\\n   unsigned char \\\n     *p1; \\\n \\\n   length=0; \\\n   p1=p; \\\n   for (component=0; component < components; component++) \\\n   { \\\n     length+=FormatLocaleString(buffer+length,MaxTextExtent-length, \\\n       format\", \",(arg1),(arg2)); \\\n     if (length >= (MaxTextExtent-1)) \\\n       length=MaxTextExtent-1; \\\n     p1+=size; \\\n   } \\\n   if (length > 1) \\\n     buffer[length-2]='\\0'; \\\n   value=AcquireString(buffer); \\\n}\n\n  typedef struct _DirectoryInfo\n  {\n    const unsigned char\n      *directory;\n\n    size_t\n      entry;\n\n    ssize_t\n      offset;\n  } DirectoryInfo;\n\n  typedef struct _TagInfo\n  {\n    size_t\n      tag;\n\n    const char\n      description[36];\n  } TagInfo;\n\n  static const TagInfo\n    EXIFTag[] =\n    {\n      {  0x001, \"exif:InteroperabilityIndex\" },\n      {  0x002, \"exif:InteroperabilityVersion\" },\n      {  0x100, \"exif:ImageWidth\" },\n      {  0x101, \"exif:ImageLength\" },\n      {  0x102, \"exif:BitsPerSample\" },\n      {  0x103, \"exif:Compression\" },\n      {  0x106, \"exif:PhotometricInterpretation\" },\n      {  0x10a, \"exif:FillOrder\" },\n      {  0x10d, \"exif:DocumentName\" },\n      {  0x10e, \"exif:ImageDescription\" },\n      {  0x10f, \"exif:Make\" },\n      {  0x110, \"exif:Model\" },\n      {  0x111, \"exif:StripOffsets\" },\n      {  0x112, \"exif:Orientation\" },\n      {  0x115, \"exif:SamplesPerPixel\" },\n      {  0x116, \"exif:RowsPerStrip\" },\n      {  0x117, \"exif:StripByteCounts\" },\n      {  0x11a, \"exif:XResolution\" },\n      {  0x11b, \"exif:YResolution\" },\n      {  0x11c, \"exif:PlanarConfiguration\" },\n      {  0x11d, \"exif:PageName\" },\n      {  0x11e, \"exif:XPosition\" },\n      {  0x11f, \"exif:YPosition\" },\n      {  0x118, \"exif:MinSampleValue\" },\n      {  0x119, \"exif:MaxSampleValue\" },\n      {  0x120, \"exif:FreeOffsets\" },\n      {  0x121, \"exif:FreeByteCounts\" },\n      {  0x122, \"exif:GrayResponseUnit\" },\n      {  0x123, \"exif:GrayResponseCurve\" },\n      {  0x124, \"exif:T4Options\" },\n      {  0x125, \"exif:T6Options\" },\n      {  0x128, \"exif:ResolutionUnit\" },\n      {  0x12d, \"exif:TransferFunction\" },\n      {  0x131, \"exif:Software\" },\n      {  0x132, \"exif:DateTime\" },\n      {  0x13b, \"exif:Artist\" },\n      {  0x13e, \"exif:WhitePoint\" },\n      {  0x13f, \"exif:PrimaryChromaticities\" },\n      {  0x140, \"exif:ColorMap\" },\n      {  0x141, \"exif:HalfToneHints\" },\n      {  0x142, \"exif:TileWidth\" },\n      {  0x143, \"exif:TileLength\" },\n      {  0x144, \"exif:TileOffsets\" },\n      {  0x145, \"exif:TileByteCounts\" },\n      {  0x14a, \"exif:SubIFD\" },\n      {  0x14c, \"exif:InkSet\" },\n      {  0x14d, \"exif:InkNames\" },\n      {  0x14e, \"exif:NumberOfInks\" },\n      {  0x150, \"exif:DotRange\" },\n      {  0x151, \"exif:TargetPrinter\" },\n      {  0x152, \"exif:ExtraSample\" },\n      {  0x153, \"exif:SampleFormat\" },\n      {  0x154, \"exif:SMinSampleValue\" },\n      {  0x155, \"exif:SMaxSampleValue\" },\n      {  0x156, \"exif:TransferRange\" },\n      {  0x157, \"exif:ClipPath\" },\n      {  0x158, \"exif:XClipPathUnits\" },\n      {  0x159, \"exif:YClipPathUnits\" },\n      {  0x15a, \"exif:Indexed\" },\n      {  0x15b, \"exif:JPEGTables\" },\n      {  0x15f, \"exif:OPIProxy\" },\n      {  0x200, \"exif:JPEGProc\" },\n      {  0x201, \"exif:JPEGInterchangeFormat\" },\n      {  0x202, \"exif:JPEGInterchangeFormatLength\" },\n      {  0x203, \"exif:JPEGRestartInterval\" },\n      {  0x205, \"exif:JPEGLosslessPredictors\" },\n      {  0x206, \"exif:JPEGPointTransforms\" },\n      {  0x207, \"exif:JPEGQTables\" },\n      {  0x208, \"exif:JPEGDCTables\" },\n      {  0x209, \"exif:JPEGACTables\" },\n      {  0x211, \"exif:YCbCrCoefficients\" },\n      {  0x212, \"exif:YCbCrSubSampling\" },\n      {  0x213, \"exif:YCbCrPositioning\" },\n      {  0x214, \"exif:ReferenceBlackWhite\" },\n      {  0x2bc, \"exif:ExtensibleMetadataPlatform\" },\n      {  0x301, \"exif:Gamma\" },\n      {  0x302, \"exif:ICCProfileDescriptor\" },\n      {  0x303, \"exif:SRGBRenderingIntent\" },\n      {  0x320, \"exif:ImageTitle\" },\n      {  0x5001, \"exif:ResolutionXUnit\" },\n      {  0x5002, \"exif:ResolutionYUnit\" },\n      {  0x5003, \"exif:ResolutionXLengthUnit\" },\n      {  0x5004, \"exif:ResolutionYLengthUnit\" },\n      {  0x5005, \"exif:PrintFlags\" },\n      {  0x5006, \"exif:PrintFlagsVersion\" },\n      {  0x5007, \"exif:PrintFlagsCrop\" },\n      {  0x5008, \"exif:PrintFlagsBleedWidth\" },\n      {  0x5009, \"exif:PrintFlagsBleedWidthScale\" },\n      {  0x500A, \"exif:HalftoneLPI\" },\n      {  0x500B, \"exif:HalftoneLPIUnit\" },\n      {  0x500C, \"exif:HalftoneDegree\" },\n      {  0x500D, \"exif:HalftoneShape\" },\n      {  0x500E, \"exif:HalftoneMisc\" },\n      {  0x500F, \"exif:HalftoneScreen\" },\n      {  0x5010, \"exif:JPEGQuality\" },\n      {  0x5011, \"exif:GridSize\" },\n      {  0x5012, \"exif:ThumbnailFormat\" },\n      {  0x5013, \"exif:ThumbnailWidth\" },\n      {  0x5014, \"exif:ThumbnailHeight\" },\n      {  0x5015, \"exif:ThumbnailColorDepth\" },\n      {  0x5016, \"exif:ThumbnailPlanes\" },\n      {  0x5017, \"exif:ThumbnailRawBytes\" },\n      {  0x5018, \"exif:ThumbnailSize\" },\n      {  0x5019, \"exif:ThumbnailCompressedSize\" },\n      {  0x501a, \"exif:ColorTransferFunction\" },\n      {  0x501b, \"exif:ThumbnailData\" },\n      {  0x5020, \"exif:ThumbnailImageWidth\" },\n      {  0x5021, \"exif:ThumbnailImageHeight\" },\n      {  0x5022, \"exif:ThumbnailBitsPerSample\" },\n      {  0x5023, \"exif:ThumbnailCompression\" },\n      {  0x5024, \"exif:ThumbnailPhotometricInterp\" },\n      {  0x5025, \"exif:ThumbnailImageDescription\" },\n      {  0x5026, \"exif:ThumbnailEquipMake\" },\n      {  0x5027, \"exif:ThumbnailEquipModel\" },\n      {  0x5028, \"exif:ThumbnailStripOffsets\" },\n      {  0x5029, \"exif:ThumbnailOrientation\" },\n      {  0x502a, \"exif:ThumbnailSamplesPerPixel\" },\n      {  0x502b, \"exif:ThumbnailRowsPerStrip\" },\n      {  0x502c, \"exif:ThumbnailStripBytesCount\" },\n      {  0x502d, \"exif:ThumbnailResolutionX\" },\n      {  0x502e, \"exif:ThumbnailResolutionY\" },\n      {  0x502f, \"exif:ThumbnailPlanarConfig\" },\n      {  0x5030, \"exif:ThumbnailResolutionUnit\" },\n      {  0x5031, \"exif:ThumbnailTransferFunction\" },\n      {  0x5032, \"exif:ThumbnailSoftwareUsed\" },\n      {  0x5033, \"exif:ThumbnailDateTime\" },\n      {  0x5034, \"exif:ThumbnailArtist\" },\n      {  0x5035, \"exif:ThumbnailWhitePoint\" },\n      {  0x5036, \"exif:ThumbnailPrimaryChromaticities\" },\n      {  0x5037, \"exif:ThumbnailYCbCrCoefficients\" },\n      {  0x5038, \"exif:ThumbnailYCbCrSubsampling\" },\n      {  0x5039, \"exif:ThumbnailYCbCrPositioning\" },\n      {  0x503A, \"exif:ThumbnailRefBlackWhite\" },\n      {  0x503B, \"exif:ThumbnailCopyRight\" },\n      {  0x5090, \"exif:LuminanceTable\" },\n      {  0x5091, \"exif:ChrominanceTable\" },\n      {  0x5100, \"exif:FrameDelay\" },\n      {  0x5101, \"exif:LoopCount\" },\n      {  0x5110, \"exif:PixelUnit\" },\n      {  0x5111, \"exif:PixelPerUnitX\" },\n      {  0x5112, \"exif:PixelPerUnitY\" },\n      {  0x5113, \"exif:PaletteHistogram\" },\n      {  0x1000, \"exif:RelatedImageFileFormat\" },\n      {  0x1001, \"exif:RelatedImageLength\" },\n      {  0x1002, \"exif:RelatedImageWidth\" },\n      {  0x800d, \"exif:ImageID\" },\n      {  0x80e3, \"exif:Matteing\" },\n      {  0x80e4, \"exif:DataType\" },\n      {  0x80e5, \"exif:ImageDepth\" },\n      {  0x80e6, \"exif:TileDepth\" },\n      {  0x828d, \"exif:CFARepeatPatternDim\" },\n      {  0x828e, \"exif:CFAPattern2\" },\n      {  0x828f, \"exif:BatteryLevel\" },\n      {  0x8298, \"exif:Copyright\" },\n      {  0x829a, \"exif:ExposureTime\" },\n      {  0x829d, \"exif:FNumber\" },\n      {  0x83bb, \"exif:IPTC/NAA\" },\n      {  0x84e3, \"exif:IT8RasterPadding\" },\n      {  0x84e5, \"exif:IT8ColorTable\" },\n      {  0x8649, \"exif:ImageResourceInformation\" },\n      {  0x8769, \"exif:ExifOffset\" },  /* specs as \"Exif IFD Pointer\"? */\n      {  0x8773, \"exif:InterColorProfile\" },\n      {  0x8822, \"exif:ExposureProgram\" },\n      {  0x8824, \"exif:SpectralSensitivity\" },\n      {  0x8825, \"exif:GPSInfo\" }, /* specs as \"GPSInfo IFD Pointer\"? */\n      {  0x8827, \"exif:PhotographicSensitivity\" },\n      {  0x8828, \"exif:OECF\" },\n      {  0x8829, \"exif:Interlace\" },      \n      {  0x882a, \"exif:TimeZoneOffset\" },\n      {  0x882b, \"exif:SelfTimerMode\" },\n      {  0x8830, \"exif:SensitivityType\" },\n      {  0x8831, \"exif:StandardOutputSensitivity\" },\n      {  0x8832, \"exif:RecommendedExposureIndex\" },\n      {  0x8833, \"exif:ISOSpeed\" },\n      {  0x8834, \"exif:ISOSpeedLatitudeyyy\" },\n      {  0x8835, \"exif:ISOSpeedLatitudezzz\" },\n      {  0x9000, \"exif:ExifVersion\" },\n      {  0x9003, \"exif:DateTimeOriginal\" },\n      {  0x9004, \"exif:DateTimeDigitized\" },\n      {  0x9010, \"exif:OffsetTime\" },\n      {  0x9011, \"exif:OffsetTimeOriginal\" },\n      {  0x9012, \"exif:OffsetTimeDigitized\" },\n      {  0x9101, \"exif:ComponentsConfiguration\" },\n      {  0x9102, \"exif:CompressedBitsPerPixel\" },\n      {  0x9201, \"exif:ShutterSpeedValue\" },\n      {  0x9202, \"exif:ApertureValue\" },\n      {  0x9203, \"exif:BrightnessValue\" },\n      {  0x9204, \"exif:ExposureBiasValue\" },\n      {  0x9205, \"exif:MaxApertureValue\" },\n      {  0x9206, \"exif:SubjectDistance\" },\n      {  0x9207, \"exif:MeteringMode\" },\n      {  0x9208, \"exif:LightSource\" },\n      {  0x9209, \"exif:Flash\" },\n      {  0x920a, \"exif:FocalLength\" },\n      {  0x920b, \"exif:FlashEnergy\" },\n      {  0x920c, \"exif:SpatialFrequencyResponse\" },\n      {  0x920d, \"exif:Noise\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9211, \"exif:ImageNumber\" },\n      {  0x9212, \"exif:SecurityClassification\" },\n      {  0x9213, \"exif:ImageHistory\" },\n      {  0x9214, \"exif:SubjectArea\" },\n      {  0x9215, \"exif:ExposureIndex\" },\n      {  0x9216, \"exif:TIFF-EPStandardID\" },\n      {  0x927c, \"exif:MakerNote\" },\n      {  0x9286, \"exif:UserComment\" },\n      {  0x9290, \"exif:SubSecTime\" },\n      {  0x9291, \"exif:SubSecTimeOriginal\" },\n      {  0x9292, \"exif:SubSecTimeDigitized\" },    \n      {  0x9400, \"exif:Temperature\" },\n      {  0x9401, \"exif:Humidity\" },\n      {  0x9402, \"exif:Pressure\" },\n      {  0x9403, \"exif:WaterDepth\" },\n      {  0x9404, \"exif:Acceleration\" },\n      {  0x9405, \"exif:CameraElevationAngle\" },    \n      {  0x9C9b, \"exif:WinXP-Title\" },\n      {  0x9C9c, \"exif:WinXP-Comments\" },\n      {  0x9C9d, \"exif:WinXP-Author\" },\n      {  0x9C9e, \"exif:WinXP-Keywords\" },\n      {  0x9C9f, \"exif:WinXP-Subject\" },      \n      {  0xa000, \"exif:FlashPixVersion\" },\n      {  0xa001, \"exif:ColorSpace\" },\n      {  0xa002, \"exif:PixelXDimension\" },\n      {  0xa003, \"exif:PixelYDimension\" },\n      {  0xa004, \"exif:RelatedSoundFile\" },\n      {  0xa005, \"exif:InteroperabilityOffset\" },\n      {  0xa20b, \"exif:FlashEnergy\" },\n      {  0xa20c, \"exif:SpatialFrequencyResponse\" },\n      {  0xa20d, \"exif:Noise\" },\n      {  0xa20e, \"exif:FocalPlaneXResolution\" },\n      {  0xa20f, \"exif:FocalPlaneYResolution\" },\n      {  0xa210, \"exif:FocalPlaneResolutionUnit\" },\n      {  0xa214, \"exif:SubjectLocation\" },\n      {  0xa215, \"exif:ExposureIndex\" },\n      {  0xa216, \"exif:TIFF/EPStandardID\" },\n      {  0xa217, \"exif:SensingMethod\" },\n      {  0xa300, \"exif:FileSource\" },\n      {  0xa301, \"exif:SceneType\" },\n      {  0xa302, \"exif:CFAPattern\" },\n      {  0xa401, \"exif:CustomRendered\" },\n      {  0xa402, \"exif:ExposureMode\" },\n      {  0xa403, \"exif:WhiteBalance\" },\n      {  0xa404, \"exif:DigitalZoomRatio\" },\n      {  0xa405, \"exif:FocalLengthIn35mmFilm\" },\n      {  0xa406, \"exif:SceneCaptureType\" },\n      {  0xa407, \"exif:GainControl\" },\n      {  0xa408, \"exif:Contrast\" },\n      {  0xa409, \"exif:Saturation\" },\n      {  0xa40a, \"exif:Sharpness\" },\n      {  0xa40b, \"exif:DeviceSettingDescription\" },\n      {  0xa40c, \"exif:SubjectDistanceRange\" },\n      {  0xa420, \"exif:ImageUniqueID\" },\n      {  0xa430, \"exif:CameraOwnerName\" },\n      {  0xa431, \"exif:BodySerialNumber\" },\n      {  0xa432, \"exif:LensSpecification\" },\n      {  0xa433, \"exif:LensMake\" },\n      {  0xa434, \"exif:LensModel\" },\n      {  0xa435, \"exif:LensSerialNumber\" },\n      {  0xc4a5, \"exif:PrintImageMatching\" },\n      {  0xa500, \"exif:Gamma\" },\n      {  0xc640, \"exif:CR2Slice\" },\n      { 0x10000, \"exif:GPSVersionID\" },\n      { 0x10001, \"exif:GPSLatitudeRef\" },\n      { 0x10002, \"exif:GPSLatitude\" },\n      { 0x10003, \"exif:GPSLongitudeRef\" },\n      { 0x10004, \"exif:GPSLongitude\" },\n      { 0x10005, \"exif:GPSAltitudeRef\" },\n      { 0x10006, \"exif:GPSAltitude\" },\n      { 0x10007, \"exif:GPSTimeStamp\" },\n      { 0x10008, \"exif:GPSSatellites\" },\n      { 0x10009, \"exif:GPSStatus\" },\n      { 0x1000a, \"exif:GPSMeasureMode\" },\n      { 0x1000b, \"exif:GPSDop\" },\n      { 0x1000c, \"exif:GPSSpeedRef\" },\n      { 0x1000d, \"exif:GPSSpeed\" },\n      { 0x1000e, \"exif:GPSTrackRef\" },\n      { 0x1000f, \"exif:GPSTrack\" },\n      { 0x10010, \"exif:GPSImgDirectionRef\" },\n      { 0x10011, \"exif:GPSImgDirection\" },\n      { 0x10012, \"exif:GPSMapDatum\" },\n      { 0x10013, \"exif:GPSDestLatitudeRef\" },\n      { 0x10014, \"exif:GPSDestLatitude\" },\n      { 0x10015, \"exif:GPSDestLongitudeRef\" },\n      { 0x10016, \"exif:GPSDestLongitude\" },\n      { 0x10017, \"exif:GPSDestBearingRef\" },\n      { 0x10018, \"exif:GPSDestBearing\" },\n      { 0x10019, \"exif:GPSDestDistanceRef\" },\n      { 0x1001a, \"exif:GPSDestDistance\" },\n      { 0x1001b, \"exif:GPSProcessingMethod\" },\n      { 0x1001c, \"exif:GPSAreaInformation\" },\n      { 0x1001d, \"exif:GPSDateStamp\" },\n      { 0x1001e, \"exif:GPSDifferential\" },\n      { 0x1001f, \"exif:GPSHPositioningError\" },\n      { 0x00000, \"\" }\n    };  /* http://www.cipa.jp/std/documents/e/DC-008-Translation-2016-E.pdf */\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *directory,\n    *exif;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  MagickBooleanType\n    status;\n\n  ssize_t\n    i;\n\n  size_t\n    entry,\n    length,\n    number_entries,\n    tag,\n    tag_value;\n\n  SplayTreeInfo\n    *exif_resources;\n\n  ssize_t\n    all,\n    id,\n    level,\n    offset,\n    tag_offset;\n\n  static int\n    tag_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  /*\n    If EXIF data exists, then try to parse the request for a tag.\n  */\n  profile=GetImageProfile(image,\"exif\");\n  if (profile == (const StringInfo *) NULL)\n    return(MagickFalse);\n  if ((property == (const char *) NULL) || (*property == '\\0'))\n    return(MagickFalse);\n  while (isspace((int) ((unsigned char) *property)) != 0)\n    property++;\n  if (strlen(property) <= 5)\n    return(MagickFalse);\n  all=0;\n  tag=(~0UL);\n  switch (*(property+5))\n  {\n    case '*':\n    {\n      /*\n        Caller has asked for all the tags in the EXIF data.\n      */\n      tag=0;\n      all=1; /* return the data in description=value format */\n      break;\n    }\n    case '!':\n    {\n      tag=0;\n      all=2; /* return the data in tagid=value format */\n      break;\n    }\n    case '#':\n    case '@':\n    {\n      int\n        c;\n\n      size_t\n        n;\n\n      /*\n        Check for a hex based tag specification first.\n      */\n      tag=(*(property+5) == '@') ? 1UL : 0UL;\n      property+=6;\n      n=strlen(property);\n      if (n != 4)\n        return(MagickFalse);\n      /*\n        Parse tag specification as a hex number.\n      */\n      n/=4;\n      do\n      {\n        for (i=(ssize_t) n-1L; i >= 0; i--)\n        {\n          c=(*property++);\n          tag<<=4;\n          if ((c >= '0') && (c <= '9'))\n            tag|=(c-'0');\n          else\n            if ((c >= 'A') && (c <= 'F'))\n              tag|=(c-('A'-10));\n            else\n              if ((c >= 'a') && (c <= 'f'))\n                tag|=(c-('a'-10));\n              else\n                return(MagickFalse);\n        }\n      } while (*property != '\\0');\n      break;\n    }\n    default:\n    {\n      /*\n        Try to match the text with a tag name instead.\n      */\n      for (i=0; ; i++)\n      {\n        if (EXIFTag[i].tag == 0)\n          break;\n        if (LocaleCompare(EXIFTag[i].description,property) == 0)\n          {\n            tag=(size_t) EXIFTag[i].tag;\n            break;\n          }\n      }\n      break;\n    }\n  }\n  if (tag == (~0UL))\n    return(MagickFalse);\n  length=GetStringInfoLength(profile);\n  if (length < 6)\n    return(MagickFalse);\n  exif=GetStringInfoDatum(profile);\n  while (length != 0)\n  {\n    if (ReadPropertyByte(&exif,&length) != 0x45)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x78)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x69)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x66)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    if (ReadPropertyByte(&exif,&length) != 0x00)\n      continue;\n    break;\n  }\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadPropertySignedShort(LSBEndian,exif);\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadPropertyUnsignedShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadPropertySignedLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  /*\n    Set the pointer to the first IFD and follow it were it leads.\n  */\n  status=MagickFalse;\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  tag_offset=0;\n  exif_resources=NewSplayTree((int (*)(const void *,const void *)) NULL,\n    (void *(*)(void *)) NULL,(void *(*)(void *)) NULL);\n  do\n  {\n    /*\n      If there is anything on the stack then pop it off.\n    */\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n        tag_offset=directory_stack[level].offset;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=(size_t) ReadPropertyUnsignedShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      unsigned char\n        *p,\n        *q;\n\n      size_t\n        format;\n\n      ssize_t\n        number_bytes,\n        components;\n\n      q=(unsigned char *) (directory+(12*entry)+2);\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      if (GetValueFromSplayTree(exif_resources,q) == q)\n        break;\n      (void) AddValueToSplayTree(exif_resources,q,q);\n      tag_value=(size_t) ReadPropertyUnsignedShort(endian,q)+tag_offset;\n      format=(size_t) ReadPropertyUnsignedShort(endian,q+2);\n      if (format >= (sizeof(tag_bytes)/sizeof(*tag_bytes)))\n        break;\n      if (format == 0)\n        break;  /* corrupt EXIF */\n      components=(ssize_t) ReadPropertySignedLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*tag_bytes[format];\n      if (number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          ssize_t\n            dir_offset;\n\n          /*\n            The directory entry contains an offset.\n          */\n          dir_offset=(ssize_t) ReadPropertySignedLong(endian,q+8);\n          if ((dir_offset < 0) || (size_t) dir_offset >= length)\n            continue;\n          if (((size_t) dir_offset+number_bytes) < (size_t) dir_offset)\n            continue;  /* prevent overflow */\n          if (((size_t) dir_offset+number_bytes) > length)\n            continue;\n          p=(unsigned char *) (exif+dir_offset);\n        }\n      if ((all != 0) || (tag == (size_t) tag_value))\n        {\n          char\n            buffer[MaxTextExtent],\n            *value;\n\n          if ((p < exif) || (p > (exif+length-tag_bytes[format])))\n            break;\n          value=(char *) NULL;\n          *buffer='\\0';\n          switch (format)\n          {\n            case EXIF_FMT_BYTE:\n            case EXIF_FMT_UNDEFINED:\n            {\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if (isprint((int) p[i]) != 0) \n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n            case EXIF_FMT_SBYTE:\n            {\n              EXIFMultipleValues(1,\"%.20g\",(double) (*(signed char *) p1));\n              break;\n            }\n            case EXIF_FMT_SSHORT:\n            {\n              EXIFMultipleValues(2,\"%hd\",ReadPropertySignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_USHORT:\n            {\n              EXIFMultipleValues(2,\"%hu\",ReadPropertyUnsignedShort(endian,p1));\n              break;\n            }\n            case EXIF_FMT_ULONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_SLONG:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertySignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_URATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertyUnsignedLong(endian,p1),(double)\n                ReadPropertyUnsignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SRATIONAL:\n            {\n              EXIFMultipleFractions(8,\"%.20g/%.20g\",(double)\n                ReadPropertySignedLong(endian,p1),(double)\n                ReadPropertySignedLong(endian,p1+4));\n              break;\n            }\n            case EXIF_FMT_SINGLE:\n            {\n              EXIFMultipleValues(4,\"%.20g\",(double)\n                ReadPropertySignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_DOUBLE:\n            {\n              EXIFMultipleValues(8,\"%.20g\",(double)\n                ReadPropertySignedLong(endian,p1));\n              break;\n            }\n            case EXIF_FMT_STRING:\n            default:\n            {\n              if ((p < exif) || (p > (exif+length-number_bytes)))\n                break;\n              value=(char *) NULL;\n              if (~((size_t) number_bytes) >= 1)\n                value=(char *) AcquireQuantumMemory((size_t) number_bytes+1UL,\n                  sizeof(*value));\n              if (value != (char *) NULL)\n                {\n                  ssize_t\n                    i;\n\n                  for (i=0; i < (ssize_t) number_bytes; i++)\n                  {\n                    value[i]='.';\n                    if ((isprint((int) p[i]) != 0) || (p[i] == '\\0'))\n                      value[i]=(char) p[i];\n                  }\n                  value[i]='\\0';\n                }\n              break;\n            }\n          }\n          if (value != (char *) NULL)\n            {\n              char\n                *key;\n\n              const char\n                *p;\n\n              key=AcquireString(property);\n              switch (all)\n              {\n                case 1:\n                {\n                  const char\n                    *description;\n\n                  ssize_t\n                    i;\n\n                  description=\"unknown\";\n                  for (i=0; ; i++)\n                  {\n                    if (EXIFTag[i].tag == 0)\n                      break;\n                    if (EXIFTag[i].tag == tag_value)\n                      {\n                        description=EXIFTag[i].description;\n                        break;\n                      }\n                  }\n                  (void) FormatLocaleString(key,MaxTextExtent,\"%s\",\n                    description);\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                  break;\n                }\n                case 2:\n                {\n                  if (tag_value < 0x10000)\n                    (void) FormatLocaleString(key,MaxTextExtent,\"#%04lx\",\n                      (unsigned long) tag_value);\n                  else\n                    if (tag_value < 0x20000)\n                      (void) FormatLocaleString(key,MaxTextExtent,\"@%04lx\",\n                        (unsigned long) (tag_value & 0xffff));\n                    else\n                      (void) FormatLocaleString(key,MaxTextExtent,\"unknown\");\n                  break;\n                }\n                default:\n                {\n                  if (level == 2)\n                    (void) SubstituteString(&key,\"exif:\",\"exif:thumbnail:\");\n                }\n              }\n              p=(const char *) NULL;\n              if (image->properties != (void *) NULL)\n                p=(const char *) GetValueFromSplayTree((SplayTreeInfo *)\n                  image->properties,key);\n              if (p == (const char *) NULL)\n                (void) SetImageProperty((Image *) image,key,value);\n              value=DestroyString(value);\n              key=DestroyString(key);\n              status=MagickTrue;\n            }\n        }\n        if ((tag_value == TAG_EXIF_OFFSET) ||\n            (tag_value == TAG_INTEROP_OFFSET) || (tag_value == TAG_GPS_OFFSET))\n          {\n            ssize_t\n              offset;\n\n            offset=(ssize_t) ReadPropertySignedLong(endian,p);\n            if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n              {\n                ssize_t\n                  tag_offset1;\n\n                tag_offset1=(ssize_t) ((tag_value == TAG_GPS_OFFSET) ? 0x10000 :\n                  0);\n                directory_stack[level].directory=directory;\n                entry++;\n                directory_stack[level].entry=entry;\n                directory_stack[level].offset=tag_offset;\n                level++;\n                /*\n                  Check for duplicate tag.\n                */\n                for (i=0; i < level; i++)\n                  if (directory_stack[i].directory == (exif+tag_offset1))\n                    break;\n                if (i < level)\n                  break;  /* duplicate tag */\n                directory_stack[level].directory=exif+offset;\n                directory_stack[level].offset=tag_offset1;\n                directory_stack[level].entry=0;\n                level++;\n                if ((directory+2+(12*number_entries)+4) > (exif+length))\n                  break;\n                offset=(ssize_t) ReadPropertySignedLong(endian,directory+2+(12*\n                  number_entries));\n                if ((offset != 0) && ((size_t) offset < length) &&\n                    (level < (MaxDirectoryStack-2)))\n                  {\n                    directory_stack[level].directory=exif+offset;\n                    directory_stack[level].entry=0;\n                    directory_stack[level].offset=tag_offset1;\n                    level++;\n                  }\n              }\n            break;\n          }\n    }\n  } while (level > 0);\n  exif_resources=DestroySplayTree(exif_resources);\n  return(status);\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "static MagickBooleanType ReadPSDChannelPixels(Image *image,\n  const size_t channels,const ssize_t row,const ssize_t type,\n  const unsigned char *pixels,ExceptionInfo *exception)\n{\n  Quantum\n    pixel;\n\n  const unsigned char\n    *p;\n\n  IndexPacket\n    *indexes;\n\n  PixelPacket\n    *q;\n\n  ssize_t\n    x;\n\n  size_t\n    packet_size;\n\n  unsigned short\n    nibble;\n\n  p=pixels;\n  q=GetAuthenticPixels(image,0,row,image->columns,1,exception);\n  if (q == (PixelPacket *) NULL)\n    return MagickFalse;\n  indexes=GetAuthenticIndexQueue(image);\n  packet_size=GetPSDPacketSize(image);\n  for (x=0; x < (ssize_t) image->columns; x++)\n  {\n    if (packet_size == 1)\n      pixel=ScaleCharToQuantum(*p++);\n    else\n      if (packet_size == 2)\n        {\n          p=PushShortPixel(MSBEndian,p,&nibble);\n          pixel=ScaleShortToQuantum(nibble);\n        }\n      else\n        {\n          MagickFloatType\n            nibble;\n\n          p=PushFloatPixel(MSBEndian,p,&nibble);\n          pixel=ClampToQuantum((MagickRealType)QuantumRange*nibble);\n        }\n    if (image->depth > 1)\n      {\n        SetPSDPixel(image,channels,type,packet_size,pixel,q,indexes,x);\n        q++;\n      }\n    else\n      {\n        ssize_t\n          bit,\n          number_bits;\n\n        number_bits=(ssize_t) image->columns-x;\n        if (number_bits > 8)\n          number_bits=8;\n        for (bit=0; bit < number_bits; bit++)\n        {\n          SetPSDPixel(image,channels,type,packet_size,(((unsigned char) pixel)\n            & (0x01 << (7-bit))) != 0 ? 0 : QuantumRange,q++,indexes,x++);\n        }\n        if (x != (ssize_t) image->columns)\n          x--;\n        continue;\n      }\n  }\n  return(SyncAuthenticPixels(image,exception));\n}",
        "post_patch": "static MagickBooleanType ReadPSDChannelPixels(Image *image,\n  const size_t channels,const ssize_t row,const ssize_t type,\n  const unsigned char *pixels,ExceptionInfo *exception)\n{\n  Quantum\n    pixel;\n\n  const unsigned char\n    *p;\n\n  IndexPacket\n    *indexes;\n\n  PixelPacket\n    *q;\n\n  ssize_t\n    x;\n\n  size_t\n    packet_size;\n\n  unsigned short\n    nibble;\n\n  p=pixels;\n  q=GetAuthenticPixels(image,0,row,image->columns,1,exception);\n  if (q == (PixelPacket *) NULL)\n    return MagickFalse;\n  indexes=GetAuthenticIndexQueue(image);\n  packet_size=GetPSDPacketSize(image);\n  for (x=0; x < (ssize_t) image->columns; x++)\n  {\n    if (packet_size == 1)\n      pixel=ScaleCharToQuantum(*p++);\n    else\n      if (packet_size == 2)\n        {\n          p=PushShortPixel(MSBEndian,p,&nibble);\n          pixel=ScaleShortToQuantum(nibble);\n        }\n      else\n        {\n          MagickFloatType\n            nibble;\n\n          p=PushFloatPixel(MSBEndian,p,&nibble);\n          pixel=ClampToQuantum((MagickRealType)QuantumRange*nibble);\n        }\n    if (image->depth > 1)\n      {\n        SetPSDPixel(image,channels,type,packet_size,pixel,q,indexes,x);\n        q++;\n      }\n    else\n      {\n        ssize_t\n          bit,\n          number_bits;\n\n        number_bits=(ssize_t) image->columns-x;\n        if (number_bits > 8)\n          number_bits=8;\n        for (bit=0; bit < number_bits; bit++)\n        {\n          SetPSDPixel(image,channels,type,packet_size,\n            (((unsigned char) ((ssize_t) pixel)) & (0x01 << (7-bit))) != 0 ? 0 :\n            QuantumRange,q++,indexes,x++);\n        }\n        if (x != (ssize_t) image->columns)\n          x--;\n        continue;\n      }\n  }\n  return(SyncAuthenticPixels(image,exception));\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "Status ImmutableExecutorState::Initialize(const Graph& graph) {\n  TF_RETURN_IF_ERROR(gview_.Initialize(&graph));\n\n  // Build the information about frames in this subgraph.\n  ControlFlowInfo cf_info;\n  TF_RETURN_IF_ERROR(BuildControlFlowInfo(&graph, &cf_info));\n\n  for (auto& it : cf_info.unique_frame_names) {\n    EnsureFrameInfo(it)->nodes =\n        absl::make_unique<std::vector<const NodeItem*>>();\n  }\n  root_frame_info_ = frame_info_[\"\"].get();\n\n  pending_ids_.resize(gview_.num_nodes());\n\n  // Preprocess every node in the graph to create an instance of op\n  // kernel for each node.\n  requires_control_flow_ = false;\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    if (IsSwitch(n) || IsMerge(n) || IsEnter(n) || IsExit(n)) {\n      requires_control_flow_ = true;\n    } else if (IsRecv(n)) {\n      // A Recv node from a different device may produce dead tensors from\n      // non-local control-flow nodes.\n      //\n      // TODO(mrry): Track whether control flow was present in the\n      // pre-partitioned graph, and enable the caller (e.g.\n      // `DirectSession`) to relax this constraint.\n      string send_device;\n      string recv_device;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"send_device\", &send_device));\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"recv_device\", &recv_device));\n      if (send_device != recv_device) {\n        requires_control_flow_ = true;\n      }\n    }\n\n    const int id = n->id();\n    const string& frame_name = cf_info.frame_names[id];\n    FrameInfo* frame_info = EnsureFrameInfo(frame_name);\n\n    NodeItem* item = gview_.node(id);\n    item->node_id = id;\n\n    item->input_start = frame_info->total_inputs;\n    frame_info->total_inputs += n->num_inputs();\n\n    Status s = params_.create_kernel(n->properties(), &item->kernel);\n    if (!s.ok()) {\n      item->kernel = nullptr;\n      s = AttachDef(s, *n);\n      return s;\n    }\n    CHECK(item->kernel);\n    item->kernel_is_async = (item->kernel->AsAsync() != nullptr);\n    item->is_merge = IsMerge(n);\n    item->is_any_consumer_merge_or_control_trigger = false;\n    for (const Node* consumer : n->out_nodes()) {\n      if (IsMerge(consumer) || IsControlTrigger(consumer)) {\n        item->is_any_consumer_merge_or_control_trigger = true;\n        break;\n      }\n    }\n    const Tensor* const_tensor = item->kernel->const_tensor();\n    if (const_tensor) {\n      // Hold onto a shallow copy of the constant tensor in `*this` so that the\n      // reference count does not drop to 1. This prevents the constant tensor\n      // from being forwarded, and its buffer reused.\n      const_tensors_.emplace_back(*const_tensor);\n    }\n    item->const_tensor = const_tensor;\n    item->is_noop = (item->kernel->type_string_view() == \"NoOp\");\n    item->is_enter = IsEnter(n);\n    if (item->is_enter) {\n      bool is_constant_enter;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"is_constant\", &is_constant_enter));\n      item->is_constant_enter = is_constant_enter;\n\n      string frame_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &frame_name));\n      FrameInfo* frame_info = frame_info_[frame_name].get();\n\n      int parallel_iterations;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"parallel_iterations\", &parallel_iterations));\n\n      if (frame_info->parallel_iterations == -1) {\n        frame_info->parallel_iterations = parallel_iterations;\n      } else if (frame_info->parallel_iterations != parallel_iterations) {\n        LOG(WARNING) << \"Loop frame \\\"\" << frame_name\n                     << \"\\\" had two different values for parallel_iterations: \"\n                     << frame_info->parallel_iterations << \" vs. \"\n                     << parallel_iterations << \".\";\n      }\n\n      if (enter_frame_info_.size() <= id) {\n        enter_frame_info_.resize(id + 1);\n      }\n      enter_frame_info_[id] = frame_info;\n    } else {\n      item->is_constant_enter = false;\n    }\n    item->is_exit = IsExit(n);\n    item->is_control_trigger = IsControlTrigger(n);\n    item->is_source = IsSource(n);\n    item->is_enter_exit_or_next_iter =\n        (IsEnter(n) || IsExit(n) || IsNextIteration(n));\n    item->is_transfer_node = IsTransferNode(n);\n    item->is_initialization_op = IsInitializationOp(n);\n    item->is_recv_or_switch = IsRecv(n) || IsSwitch(n);\n    item->is_next_iteration = IsNextIteration(n);\n    item->is_distributed_communication = IsDistributedCommunication(n);\n\n    // Compute the maximum values we'll store for this node in the\n    // pending counts data structure, and allocate a handle in\n    // that frame's pending counts data structure that has enough\n    // space to store these maximal count values.\n    size_t max_pending, max_dead;\n    GetMaxPendingCounts(n, &max_pending, &max_dead);\n    pending_ids_[id] =\n        frame_info->pending_counts_layout.CreateHandle(max_pending, max_dead);\n\n    // See if this node is a root node, and if so, add item to root_nodes_.\n    if (n->in_edges().empty()) {\n      root_nodes_.push_back(item);\n    }\n\n    // Initialize static information about the frames in the graph.\n    frame_info->nodes->push_back(item);\n    if (item->is_enter) {\n      string enter_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &enter_name));\n      EnsureFrameInfo(enter_name)->input_count++;\n    }\n\n    // Record information about whether each output of the op is used.\n    std::unique_ptr<bool[]> outputs_required(new bool[n->num_outputs()]);\n    std::fill(&outputs_required[0], &outputs_required[n->num_outputs()], false);\n    int32_t unused_outputs = n->num_outputs();\n    for (const Edge* e : n->out_edges()) {\n      if (IsSink(e->dst())) continue;\n      if (e->src_output() >= 0) {\n        if (!outputs_required[e->src_output()]) {\n          --unused_outputs;\n          outputs_required[e->src_output()] = true;\n        }\n      }\n    }\n    if (unused_outputs > 0) {\n      for (int i = 0; i < n->num_outputs(); ++i) {\n        if (!outputs_required[i]) {\n          metrics::RecordUnusedOutput(n->type_string());\n        }\n      }\n      item->outputs_required = std::move(outputs_required);\n    }\n  }\n\n  // Rewrite each `EdgeInfo::input_slot` member to refer directly to the input\n  // location.\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    const int id = n->id();\n    NodeItem* item = gview_.node(id);\n\n    for (EdgeInfo& e : item->mutable_output_edges()) {\n      const int dst_id = e.dst_id;\n      NodeItem* dst_item = gview_.node(dst_id);\n      e.input_slot += dst_item->input_start;\n    }\n  }\n\n  // Initialize PendingCounts only after pending_ids_[node.id] is initialized\n  // for all nodes.\n  InitializePending(&graph, cf_info);\n  return gview_.SetAllocAttrs(&graph, params_.device);\n}",
        "post_patch": "Status ImmutableExecutorState::Initialize(const Graph& graph) {\n  TF_RETURN_IF_ERROR(gview_.Initialize(&graph));\n\n  // Build the information about frames in this subgraph.\n  ControlFlowInfo cf_info;\n  TF_RETURN_IF_ERROR(BuildControlFlowInfo(&graph, &cf_info));\n\n  for (auto& it : cf_info.unique_frame_names) {\n    EnsureFrameInfo(it)->nodes =\n        absl::make_unique<std::vector<const NodeItem*>>();\n  }\n  root_frame_info_ = frame_info_[\"\"].get();\n\n  pending_ids_.resize(gview_.num_nodes());\n\n  // Preprocess every node in the graph to create an instance of op\n  // kernel for each node.\n  requires_control_flow_ = false;\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    if (IsSwitch(n) || IsMerge(n) || IsEnter(n) || IsExit(n)) {\n      requires_control_flow_ = true;\n    } else if (IsRecv(n)) {\n      // A Recv node from a different device may produce dead tensors from\n      // non-local control-flow nodes.\n      //\n      // TODO(mrry): Track whether control flow was present in the\n      // pre-partitioned graph, and enable the caller (e.g.\n      // `DirectSession`) to relax this constraint.\n      string send_device;\n      string recv_device;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"send_device\", &send_device));\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"recv_device\", &recv_device));\n      if (send_device != recv_device) {\n        requires_control_flow_ = true;\n      }\n    }\n\n    const int id = n->id();\n    const string& frame_name = cf_info.frame_names[id];\n    FrameInfo* frame_info = EnsureFrameInfo(frame_name);\n\n    NodeItem* item = gview_.node(id);\n    item->node_id = id;\n\n    item->input_start = frame_info->total_inputs;\n    frame_info->total_inputs += n->num_inputs();\n\n    Status s = params_.create_kernel(n->properties(), &item->kernel);\n    if (!s.ok()) {\n      params_.delete_kernel(item->kernel);\n      item->kernel = nullptr;\n      s = AttachDef(s, *n);\n      return s;\n    }\n    CHECK(item->kernel);\n    item->kernel_is_async = (item->kernel->AsAsync() != nullptr);\n    item->is_merge = IsMerge(n);\n    item->is_any_consumer_merge_or_control_trigger = false;\n    for (const Node* consumer : n->out_nodes()) {\n      if (IsMerge(consumer) || IsControlTrigger(consumer)) {\n        item->is_any_consumer_merge_or_control_trigger = true;\n        break;\n      }\n    }\n    const Tensor* const_tensor = item->kernel->const_tensor();\n    if (const_tensor) {\n      // Hold onto a shallow copy of the constant tensor in `*this` so that the\n      // reference count does not drop to 1. This prevents the constant tensor\n      // from being forwarded, and its buffer reused.\n      const_tensors_.emplace_back(*const_tensor);\n    }\n    item->const_tensor = const_tensor;\n    item->is_noop = (item->kernel->type_string_view() == \"NoOp\");\n    item->is_enter = IsEnter(n);\n    if (item->is_enter) {\n      bool is_constant_enter;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"is_constant\", &is_constant_enter));\n      item->is_constant_enter = is_constant_enter;\n\n      string frame_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &frame_name));\n      FrameInfo* frame_info = frame_info_[frame_name].get();\n\n      int parallel_iterations;\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(n->attrs(), \"parallel_iterations\", &parallel_iterations));\n\n      if (frame_info->parallel_iterations == -1) {\n        frame_info->parallel_iterations = parallel_iterations;\n      } else if (frame_info->parallel_iterations != parallel_iterations) {\n        LOG(WARNING) << \"Loop frame \\\"\" << frame_name\n                     << \"\\\" had two different values for parallel_iterations: \"\n                     << frame_info->parallel_iterations << \" vs. \"\n                     << parallel_iterations << \".\";\n      }\n\n      if (enter_frame_info_.size() <= id) {\n        enter_frame_info_.resize(id + 1);\n      }\n      enter_frame_info_[id] = frame_info;\n    } else {\n      item->is_constant_enter = false;\n    }\n    item->is_exit = IsExit(n);\n    item->is_control_trigger = IsControlTrigger(n);\n    item->is_source = IsSource(n);\n    item->is_enter_exit_or_next_iter =\n        (IsEnter(n) || IsExit(n) || IsNextIteration(n));\n    item->is_transfer_node = IsTransferNode(n);\n    item->is_initialization_op = IsInitializationOp(n);\n    item->is_recv_or_switch = IsRecv(n) || IsSwitch(n);\n    item->is_next_iteration = IsNextIteration(n);\n    item->is_distributed_communication = IsDistributedCommunication(n);\n\n    // Compute the maximum values we'll store for this node in the\n    // pending counts data structure, and allocate a handle in\n    // that frame's pending counts data structure that has enough\n    // space to store these maximal count values.\n    size_t max_pending, max_dead;\n    GetMaxPendingCounts(n, &max_pending, &max_dead);\n    pending_ids_[id] =\n        frame_info->pending_counts_layout.CreateHandle(max_pending, max_dead);\n\n    // See if this node is a root node, and if so, add item to root_nodes_.\n    if (n->in_edges().empty()) {\n      root_nodes_.push_back(item);\n    }\n\n    // Initialize static information about the frames in the graph.\n    frame_info->nodes->push_back(item);\n    if (item->is_enter) {\n      string enter_name;\n      TF_RETURN_IF_ERROR(GetNodeAttr(n->attrs(), \"frame_name\", &enter_name));\n      EnsureFrameInfo(enter_name)->input_count++;\n    }\n\n    // Record information about whether each output of the op is used.\n    std::unique_ptr<bool[]> outputs_required(new bool[n->num_outputs()]);\n    std::fill(&outputs_required[0], &outputs_required[n->num_outputs()], false);\n    int32_t unused_outputs = n->num_outputs();\n    for (const Edge* e : n->out_edges()) {\n      if (IsSink(e->dst())) continue;\n      if (e->src_output() >= 0) {\n        if (!outputs_required[e->src_output()]) {\n          --unused_outputs;\n          outputs_required[e->src_output()] = true;\n        }\n      }\n    }\n    if (unused_outputs > 0) {\n      for (int i = 0; i < n->num_outputs(); ++i) {\n        if (!outputs_required[i]) {\n          metrics::RecordUnusedOutput(n->type_string());\n        }\n      }\n      item->outputs_required = std::move(outputs_required);\n    }\n  }\n\n  // Rewrite each `EdgeInfo::input_slot` member to refer directly to the input\n  // location.\n  for (const Node* n : graph.nodes()) {\n    if (IsSink(n)) continue;\n    const int id = n->id();\n    NodeItem* item = gview_.node(id);\n\n    for (EdgeInfo& e : item->mutable_output_edges()) {\n      const int dst_id = e.dst_id;\n      NodeItem* dst_item = gview_.node(dst_id);\n      e.input_slot += dst_item->input_start;\n    }\n  }\n\n  // Initialize PendingCounts only after pending_ids_[node.id] is initialized\n  // for all nodes.\n  InitializePending(&graph, cf_info);\n  return gview_.SetAllocAttrs(&graph, params_.device);\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n                 string* init_op_name) {\n  const auto& sig_def_map = meta_graph_def.signature_def();\n  const auto& init_op_sig_it =\n      meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n  if (init_op_sig_it != sig_def_map.end()) {\n    *init_op_name = init_op_sig_it->second.outputs()\n                        .find(kSavedModelInitOpSignatureKey)\n                        ->second.name();\n    return Status::OK();\n  }\n\n  const auto& collection_def_map = meta_graph_def.collection_def();\n  string init_op_collection_key;\n  if (collection_def_map.find(kSavedModelMainOpKey) !=\n      collection_def_map.end()) {\n    init_op_collection_key = kSavedModelMainOpKey;\n  } else {\n    init_op_collection_key = kSavedModelLegacyInitOpKey;\n  }\n\n  const auto init_op_it = collection_def_map.find(init_op_collection_key);\n  if (init_op_it != collection_def_map.end()) {\n    if (init_op_it->second.node_list().value_size() != 1) {\n      return errors::FailedPrecondition(\n          strings::StrCat(\"Expected exactly one main op in : \", export_dir));\n    }\n    *init_op_name = init_op_it->second.node_list().value(0);\n  }\n  return Status::OK();\n}",
        "post_patch": "Status GetInitOp(const string& export_dir, const MetaGraphDef& meta_graph_def,\n                 string* init_op_name) {\n  const auto& sig_def_map = meta_graph_def.signature_def();\n  const auto& init_op_sig_it =\n      meta_graph_def.signature_def().find(kSavedModelInitOpSignatureKey);\n  if (init_op_sig_it != sig_def_map.end()) {\n    const auto& sig_def_outputs = init_op_sig_it->second.outputs();\n    const auto& sig_def_outputs_it =\n        sig_def_outputs.find(kSavedModelInitOpSignatureKey);\n    if (sig_def_outputs_it == sig_def_outputs.end()) {\n      return errors::FailedPrecondition(\"Could not find output \",\n                                        kSavedModelInitOpSignatureKey);\n    }\n    *init_op_name = sig_def_outputs_it->second.name();\n    return Status::OK();\n  }\n\n  const auto& collection_def_map = meta_graph_def.collection_def();\n  string init_op_collection_key;\n  if (collection_def_map.find(kSavedModelMainOpKey) !=\n      collection_def_map.end()) {\n    init_op_collection_key = kSavedModelMainOpKey;\n  } else {\n    init_op_collection_key = kSavedModelLegacyInitOpKey;\n  }\n\n  const auto init_op_it = collection_def_map.find(init_op_collection_key);\n  if (init_op_it != collection_def_map.end()) {\n    if (init_op_it->second.node_list().value_size() != 1) {\n      return errors::FailedPrecondition(\n          strings::StrCat(\"Expected exactly one main op in : \", export_dir));\n    }\n    *init_op_name = init_op_it->second.node_list().value(0);\n  }\n  return Status::OK();\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "Status ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    TF_CHECK_OK(TensorShapeUtils::MakeShape(shp, &new_dims));\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}",
        "post_patch": "Status ConstantFolding::IsSimplifiableReshape(\n    const NodeDef& node, const GraphProperties& properties) const {\n  if (!IsReshape(node)) {\n    return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");\n  }\n  if (2 > node.input_size()) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have at most 2 inputs but has \",\n                            node.input_size());\n  }\n  const NodeDef* new_shape = node_map_->GetNode(node.input(1));\n  if (!IsReallyConstant(*new_shape)) {\n    return errors::Internal(\"Node \", node.name(), \" has shape \",\n                            new_shape->DebugString(),\n                            \" which is not a constant\");\n  }\n  TensorVector outputs;\n  auto outputs_cleanup = gtl::MakeCleanup([&outputs] {\n    for (const auto& output : outputs) {\n      delete output.tensor;\n    }\n  });\n\n  Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);\n  if (!s.ok()) {\n    return errors::Internal(\"Could not evaluate node \", node.name());\n  }\n  if (outputs.size() != 1) {\n    return errors::Internal(\"Node \", node.name(),\n                            \" must have exactly 1 output but has \",\n                            outputs.size());\n  }\n\n  const std::vector<OpInfo::TensorProperties>& props =\n      properties.GetInputProperties(node.name());\n  if (props.empty()) {\n    return errors::Internal(\"Node \", node.name(), \" has no properties\");\n  }\n  const OpInfo::TensorProperties& prop = props[0];\n  if (prop.dtype() == DT_INVALID) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with invalid dtype\");\n  }\n  const PartialTensorShape shape(prop.shape());\n  if (!shape.IsFullyDefined()) {\n    return errors::Internal(\"Node \", node.name(), \" has property \",\n                            prop.DebugString(), \" with shape \",\n                            shape.DebugString(), \" which is not fully defined\");\n  }\n\n  PartialTensorShape new_dims;\n  if (outputs[0]->dtype() == DT_INT32) {\n    std::vector<int32> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int32_t dim = outputs[0]->flat<int32>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  } else {\n    std::vector<int64_t> shp;\n    for (int i = 0; i < outputs[0]->NumElements(); ++i) {\n      int64_t dim = outputs[0]->flat<int64_t>()(i);\n      shp.push_back(dim);\n    }\n    s = TensorShapeUtils::MakeShape(shp, &new_dims);\n    if (!s.ok()) return s;\n  }\n\n  if (!shape.IsCompatibleWith(new_dims)) {\n    return errors::Internal(\"Expected shape \", shape.DebugString(),\n                            \"to be compatible with \", new_dims.DebugString());\n  }\n\n  return Status::OK();\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "u32 GetHintFormat(GF_TrackBox *trak)\n{\n\tGF_HintMediaHeaderBox *hmhd = (GF_HintMediaHeaderBox *)trak->Media->information->InfoHeader;\n\tif (hmhd->type != GF_ISOM_BOX_TYPE_HMHD)\n\t\treturn 0;\n\t\t\n\tif (!hmhd || !hmhd->subType) {\n\t\tGF_Box *a = (GF_Box *)gf_list_get(trak->Media->information->sampleTable->SampleDescription->child_boxes, 0);\n\t\tif (!hmhd) return a ? a->type : 0;\n\t\tif (a) hmhd->subType = a->type;\n\t\treturn hmhd->subType;\n\t}\n\treturn hmhd->subType;\n}",
        "post_patch": "u32 GetHintFormat(GF_TrackBox *trak)\n{\n\tGF_HintMediaHeaderBox *hmhd = (GF_HintMediaHeaderBox *)trak->Media->information->InfoHeader;\n\tif (!hmhd || (hmhd->type != GF_ISOM_BOX_TYPE_HMHD))\n\t\treturn 0;\n\t\t\n\tif (!hmhd || !hmhd->subType) {\n\t\tGF_Box *a = (GF_Box *)gf_list_get(trak->Media->information->sampleTable->SampleDescription->child_boxes, 0);\n\t\tif (!hmhd) return a ? a->type : 0;\n\t\tif (a) hmhd->subType = a->type;\n\t\treturn hmhd->subType;\n\t}\n\treturn hmhd->subType;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "post_patch": "Status ConstantFolding::EvaluateOneFoldable(const NodeDef& node,\n                                            std::vector<NodeDef>* outputs,\n                                            bool* result_too_large) {\n  TensorVector inputs;\n  TensorVector output_tensors;\n  auto inputs_cleanup = gtl::MakeCleanup([&inputs, &output_tensors] {\n    for (const auto& input : inputs) {\n      delete input.tensor;\n    }\n    for (const auto& output : output_tensors) {\n      if (output.tensor) {\n        delete output.tensor;\n      }\n    }\n  });\n\n  size_t total_inputs_size = 0;\n  for (const auto& input : node.input()) {\n    const TensorId input_tensor = ParseTensorName(input);\n    if (input_tensor.index() < 0) {\n      // Control dependency\n      break;\n    }\n    const NodeDef* input_node = node_map_->GetNode(input);\n    if (!IsReallyConstant(*input_node)) {\n      return Status(error::INVALID_ARGUMENT,\n                    strings::StrCat(\"Can't fold \", node.name(), \", its \", input,\n                                    \" isn't constant\"));\n    }\n    TF_RETURN_IF_ERROR(CheckAttrExists(*input_node, \"value\"));\n    const TensorProto& raw_val = input_node->attr().at(\"value\").tensor();\n    if (raw_val.dtype() == DT_INVALID) {\n      return Status(\n          error::INVALID_ARGUMENT,\n          strings::StrCat(\"A tensor in the input node, with TensorId of \",\n                          input_tensor.ToString(),\n                          \" has a dtype of DT_INVALID.\"));\n    }\n    if (IsRefType(raw_val.dtype())) {\n      return errors::InvalidArgument(\n          \"Not allowed to construct a tensor with reference dtype, got \",\n          DataTypeString(raw_val.dtype()));\n    }\n    Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());\n    if (!value->FromProto(raw_val)) {\n      delete (value);\n      return errors::InvalidArgument(\"Unable to make Tensor from proto for \",\n                                     node.name(), \" with shape \",\n                                     raw_val.tensor_shape().DebugString());\n    }\n    inputs.emplace_back(value);\n    total_inputs_size += value->TotalBytes();\n  }\n\n  TF_RETURN_IF_ERROR(EvaluateNode(node, inputs, &output_tensors));\n  if (output_tensors.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"Expected at least one output.\");\n  }\n\n  outputs->resize(output_tensors.size());\n  for (size_t i = 0; i < output_tensors.size(); i++) {\n    string node_name = OptimizedNodeName(node, \"-folded\");\n    if (output_tensors.size() > 1) {\n      node_name = strings::StrCat(node_name, \"-\", i);\n    }\n    if (output_tensors[i].tensor) {\n      Status s = CreateNodeDef(node_name, output_tensors[i], &outputs->at(i),\n                               total_inputs_size);\n      if (!s.ok()) {\n        *result_too_large = true;\n        return s;\n      }\n    } else {\n      // Create an empty NodeDef to identify dead outputs (e.g. the output of a\n      // switch that's not selected by the switch predicate).\n      outputs->at(i) = NodeDef();\n    }\n  }\n  return Status::OK();\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "int callback_glewlwyd_user_auth (const struct _u_request * request, struct _u_response * response, void * user_data) {\n  struct config_elements * config = (struct config_elements *)user_data;\n  json_t * j_param = ulfius_get_json_body_request(request, NULL), * j_result = NULL;\n  const char * ip_source = get_ip_source(request);\n  char * issued_for = get_client_hostname(request);\n  char * session_uid, expires[129];\n  time_t now;\n  struct tm ts;\n  \n  time(&now);\n  now += GLEWLWYD_DEFAULT_SESSION_EXPIRATION_COOKIE;\n  gmtime_r(&now, &ts);\n  strftime(expires, 128, \"%a, %d %b %Y %T %Z\", &ts);\n  if (j_param != NULL) {\n    if (json_string_length(json_object_get(j_param, \"username\"))) {\n      if (json_object_get(j_param, \"scheme_type\") == NULL || 0 == o_strcmp(json_string_value(json_object_get(j_param, \"scheme_type\")), \"password\")) {\n        if (json_string_length(json_object_get(j_param, \"password\"))) {\n          j_result = auth_check_user_credentials(config, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"password\")));\n          if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (1)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with password\", json_string_value(json_object_get(j_param, \"username\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          } else {\n            if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n              y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            }\n            if ((session_uid = get_session_id(config, request)) != NULL && user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (2)\");\n            }\n            o_free(session_uid);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          }\n          json_decref(j_result);\n        } else if (json_object_get(j_param, \"password\") != NULL && !json_is_string(json_object_get(j_param, \"password\"))) {\n          ulfius_set_string_body_response(response, 400, \"password must be a string\");\n        } else {\n          session_uid = get_session_id(config, request);\n          j_result = get_users_for_session(config, session_uid);\n          if (check_result_value(j_result, G_OK)) {\n            // Refresh username to set as default\n            if (user_session_update(config, u_map_get(request->map_cookie, config->session_key), u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 0) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (3)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            }\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 401;\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error get_users_for_session\");\n            response->status = 500;\n          }\n          o_free(session_uid);\n          json_decref(j_result);\n        }\n      } else {\n        if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n          j_result = auth_check_user_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_string_value(json_object_get(j_param, \"username\")), json_object_get(j_param, \"value\"), request);\n          if (check_result_value(j_result, G_ERROR_PARAM)) {\n            ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n          } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n            y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 404;\n          } else if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n            response->status = 500;\n          }\n          json_decref(j_result);\n        } else {\n          ulfius_set_string_body_response(response, 400, \"scheme_type, scheme_name and value are mandatory\");\n        }\n      }\n    } else {\n      if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n        j_result = auth_check_identify_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_object_get(j_param, \"value\"), request);\n        if (check_result_value(j_result, G_ERROR_PARAM)) {\n          ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n        } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n          y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username <UNKNOWN> at IP Address %s\", ip_source);\n          response->status = 401;\n        } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n          response->status = 404;\n        } else if (check_result_value(j_result, G_OK)) {\n          if ((session_uid = get_session_id(config, request)) == NULL) {\n            session_uid = generate_session_id();\n          }\n          if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n            response->status = 500;\n          } else {\n            ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n          }\n          o_free(session_uid);\n        } else {\n          y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n          response->status = 500;\n        }\n        json_decref(j_result);\n      } else {\n        ulfius_set_string_body_response(response, 400, \"username is mandatory\");\n      }\n    }\n  } else {\n    ulfius_set_string_body_response(response, 400, \"Input parameters must be in JSON format\");\n  }\n  json_decref(j_param);\n  o_free(issued_for);\n\n  return U_CALLBACK_CONTINUE;\n}",
        "post_patch": "int callback_glewlwyd_user_auth (const struct _u_request * request, struct _u_response * response, void * user_data) {\n  struct config_elements * config = (struct config_elements *)user_data;\n  json_t * j_param = ulfius_get_json_body_request(request, NULL), * j_result = NULL;\n  const char * ip_source = get_ip_source(request);\n  char * issued_for = get_client_hostname(request);\n  char * session_uid, expires[129];\n  time_t now;\n  struct tm ts;\n  \n  time(&now);\n  now += GLEWLWYD_DEFAULT_SESSION_EXPIRATION_COOKIE;\n  gmtime_r(&now, &ts);\n  strftime(expires, 128, \"%a, %d %b %Y %T %Z\", &ts);\n  if (j_param != NULL) {\n    if (json_string_length(json_object_get(j_param, \"username\"))) {\n      if (json_object_get(j_param, \"scheme_type\") == NULL || 0 == o_strcmp(json_string_value(json_object_get(j_param, \"scheme_type\")), \"password\")) {\n        if (json_string_length(json_object_get(j_param, \"password\"))) {\n          j_result = auth_check_user_credentials(config, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"password\")));\n          if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (1)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with password\", json_string_value(json_object_get(j_param, \"username\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          } else {\n            if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n              y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            }\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", \"password\", NULL);\n          }\n          json_decref(j_result);\n        } else if (json_object_get(j_param, \"password\") != NULL && !json_is_string(json_object_get(j_param, \"password\"))) {\n          ulfius_set_string_body_response(response, 400, \"password must be a string\");\n        } else {\n          session_uid = get_session_id(config, request);\n          j_result = get_users_for_session(config, session_uid);\n          if (check_result_value(j_result, G_OK)) {\n            // Refresh username to set as default\n            if (user_session_update(config, u_map_get(request->map_cookie, config->session_key), u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), NULL, 0) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (3)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            }\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 401;\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error get_users_for_session\");\n            response->status = 500;\n          }\n          o_free(session_uid);\n          json_decref(j_result);\n        }\n      } else {\n        if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n          j_result = auth_check_user_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_string_value(json_object_get(j_param, \"username\")), json_object_get(j_param, \"value\"), request);\n          if (check_result_value(j_result, G_ERROR_PARAM)) {\n            ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n          } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n            y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username %s at IP Address %s\", json_string_value(json_object_get(j_param, \"username\")), ip_source);\n            response->status = 401;\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_INVALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n            response->status = 404;\n          } else if (check_result_value(j_result, G_OK)) {\n            if ((session_uid = get_session_id(config, request)) == NULL) {\n              session_uid = generate_session_id();\n            }\n            if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n              y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n              response->status = 500;\n            } else {\n              ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n              y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_param, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n            }\n            o_free(session_uid);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID, 1, NULL);\n            glewlwyd_metrics_increment_counter_va(config, GLWD_METRICS_AUTH_USER_VALID_SCHEME, 1, \"scheme_type\", json_string_value(json_object_get(j_param, \"scheme_type\")), \"scheme_name\", json_string_value(json_object_get(j_param, \"scheme_name\")), NULL);\n          } else {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n            response->status = 500;\n          }\n          json_decref(j_result);\n        } else {\n          ulfius_set_string_body_response(response, 400, \"scheme_type, scheme_name and value are mandatory\");\n        }\n      }\n    } else {\n      if (json_string_length(json_object_get(j_param, \"scheme_type\")) && json_string_length(json_object_get(j_param, \"scheme_name\")) && json_is_object(json_object_get(j_param, \"value\"))) {\n        j_result = auth_check_identify_scheme(config, json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")), json_object_get(j_param, \"value\"), request);\n        if (check_result_value(j_result, G_ERROR_PARAM)) {\n          ulfius_set_string_body_response(response, 400, \"bad scheme response\");\n        } else if (check_result_value(j_result, G_ERROR_UNAUTHORIZED)) {\n          y_log_message(Y_LOG_LEVEL_WARNING, \"Security - Authorization invalid for username <UNKNOWN> at IP Address %s\", ip_source);\n          response->status = 401;\n        } else if (check_result_value(j_result, G_ERROR_NOT_FOUND)) {\n          response->status = 404;\n        } else if (check_result_value(j_result, G_OK)) {\n          if ((session_uid = get_session_id(config, request)) == NULL) {\n            session_uid = generate_session_id();\n          }\n          if (user_session_update(config, session_uid, u_map_get_case(request->map_header, \"user-agent\"), issued_for, json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_name\")), 1) != G_OK) {\n            y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error user_session_update (4)\");\n            response->status = 500;\n          } else {\n            ulfius_add_cookie_to_response(response, config->session_key, session_uid, expires, 0, config->cookie_domain, \"/\", config->cookie_secure, 0);\n            y_log_message(Y_LOG_LEVEL_INFO, \"Event - User '%s' authenticated with scheme '%s/%s'\", json_string_value(json_object_get(j_result, \"username\")), json_string_value(json_object_get(j_param, \"scheme_type\")), json_string_value(json_object_get(j_param, \"scheme_name\")));\n          }\n          o_free(session_uid);\n        } else {\n          y_log_message(Y_LOG_LEVEL_ERROR, \"callback_glewlwyd_user_auth - Error auth_check_user_scheme\");\n          response->status = 500;\n        }\n        json_decref(j_result);\n      } else {\n        ulfius_set_string_body_response(response, 400, \"username is mandatory\");\n      }\n    }\n  } else {\n    ulfius_set_string_body_response(response, 400, \"Input parameters must be in JSON format\");\n  }\n  json_decref(j_param);\n  o_free(issued_for);\n\n  return U_CALLBACK_CONTINUE;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }",
        "post_patch": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n\n    TensorShape tensor_input_shape;\n    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(input_shape_vec,\n                                                          &tensor_input_shape));\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "nfs4_file_open(struct inode *inode, struct file *filp)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *dentry = file_dentry(filp);\n\tstruct dentry *parent = NULL;\n\tstruct inode *dir;\n\tunsigned openflags = filp->f_flags;\n\tstruct iattr attr;\n\tint err;\n\n\t/*\n\t * If no cached dentry exists or if it's negative, NFSv4 handled the\n\t * opens in ->lookup() or ->create().\n\t *\n\t * We only get this far for a cached positive dentry.  We skipped\n\t * revalidation, so handle it here by dropping the dentry and returning\n\t * -EOPENSTALE.  The VFS will retry the lookup/create/open.\n\t */\n\n\tdprintk(\"NFS: open file(%pd2)\\n\", dentry);\n\n\terr = nfs_check_flags(openflags);\n\tif (err)\n\t\treturn err;\n\n\tif ((openflags & O_ACCMODE) == 3)\n\t\treturn nfs_open(inode, filp);\n\n\t/* We can't create new files here */\n\topenflags &= ~(O_CREAT|O_EXCL);\n\n\tparent = dget_parent(dentry);\n\tdir = d_inode(parent);\n\n\tctx = alloc_nfs_open_context(file_dentry(filp), filp->f_mode, filp);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\tattr.ia_valid = ATTR_OPEN;\n\tif (openflags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t}\n\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, openflags, &attr, NULL);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tswitch (err) {\n\t\tdefault:\n\t\t\tgoto out_put_ctx;\n\t\tcase -ENOENT:\n\t\tcase -ESTALE:\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\tcase -ELOOP:\n\t\t\tgoto out_drop;\n\t\t}\n\t}\n\tif (inode != d_inode(dentry))\n\t\tgoto out_drop;\n\n\tnfs_file_set_open_context(filp, ctx);\n\tnfs_fscache_open_file(inode, filp);\n\terr = 0;\n\nout_put_ctx:\n\tput_nfs_open_context(ctx);\nout:\n\tdput(parent);\n\treturn err;\n\nout_drop:\n\td_drop(dentry);\n\terr = -EOPENSTALE;\n\tgoto out_put_ctx;\n}",
        "post_patch": "nfs4_file_open(struct inode *inode, struct file *filp)\n{\n\tstruct nfs_open_context *ctx;\n\tstruct dentry *dentry = file_dentry(filp);\n\tstruct dentry *parent = NULL;\n\tstruct inode *dir;\n\tunsigned openflags = filp->f_flags;\n\tstruct iattr attr;\n\tint err;\n\n\t/*\n\t * If no cached dentry exists or if it's negative, NFSv4 handled the\n\t * opens in ->lookup() or ->create().\n\t *\n\t * We only get this far for a cached positive dentry.  We skipped\n\t * revalidation, so handle it here by dropping the dentry and returning\n\t * -EOPENSTALE.  The VFS will retry the lookup/create/open.\n\t */\n\n\tdprintk(\"NFS: open file(%pd2)\\n\", dentry);\n\n\terr = nfs_check_flags(openflags);\n\tif (err)\n\t\treturn err;\n\n\tif ((openflags & O_ACCMODE) == 3)\n\t\topenflags--;\n\n\t/* We can't create new files here */\n\topenflags &= ~(O_CREAT|O_EXCL);\n\n\tparent = dget_parent(dentry);\n\tdir = d_inode(parent);\n\n\tctx = alloc_nfs_open_context(file_dentry(filp), filp->f_mode, filp);\n\terr = PTR_ERR(ctx);\n\tif (IS_ERR(ctx))\n\t\tgoto out;\n\n\tattr.ia_valid = ATTR_OPEN;\n\tif (openflags & O_TRUNC) {\n\t\tattr.ia_valid |= ATTR_SIZE;\n\t\tattr.ia_size = 0;\n\t\tfilemap_write_and_wait(inode->i_mapping);\n\t}\n\n\tinode = NFS_PROTO(dir)->open_context(dir, ctx, openflags, &attr, NULL);\n\tif (IS_ERR(inode)) {\n\t\terr = PTR_ERR(inode);\n\t\tswitch (err) {\n\t\tdefault:\n\t\t\tgoto out_put_ctx;\n\t\tcase -ENOENT:\n\t\tcase -ESTALE:\n\t\tcase -EISDIR:\n\t\tcase -ENOTDIR:\n\t\tcase -ELOOP:\n\t\t\tgoto out_drop;\n\t\t}\n\t}\n\tif (inode != d_inode(dentry))\n\t\tgoto out_drop;\n\n\tnfs_file_set_open_context(filp, ctx);\n\tnfs_fscache_open_file(inode, filp);\n\terr = 0;\n\nout_put_ctx:\n\tput_nfs_open_context(ctx);\nout:\n\tdput(parent);\n\treturn err;\n\nout_drop:\n\td_drop(dentry);\n\terr = -EOPENSTALE;\n\tgoto out_put_ctx;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({1, height, width, decode.channels}), &output));\n    } else {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({height, width, decode.channels}), &output));\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "post_patch": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // If we reach this point, then there is data in `decode` which must be\n    // freed by the time we end execution in this function. We cannot call\n    // `png::CommonFreeDecode()` before an `OP_REQUIRES` because if\n    // `OP_REQUIRES` constraint is satisfied then the data would be freed\n    // prematurely. Instead, let's use a `Cleanup` object.\n    auto cleanup = gtl::MakeCleanup([&decode]() {\n      std::cerr << \"Cleanup called...\\n\";\n      png::CommonFreeDecode(&decode);\n    });\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({1, height, width, decode.channels}), &output));\n    } else {\n      OP_REQUIRES_OK(\n          context,\n          context->allocate_output(\n              0, TensorShape({height, width, decode.channels}), &output));\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "void Node::RunForwardTypeInference() {\n  VLOG(4) << \"Forward type inference: \" << props_->node_def.DebugString();\n\n  if (props_->fwd_type_fn == nullptr) {\n    return;\n  }\n\n  std::vector<Node*> input_nodes(props_->input_types.size(), nullptr);\n  std::vector<int> input_idx(props_->input_types.size(), 0);\n  for (const auto& edge : in_edges_) {\n    if (edge->IsControlEdge()) {\n      continue;\n    }\n    DCHECK(edge->dst_input() < input_nodes.size()) << DebugString();\n    int i = edge->dst_input();\n    input_nodes.at(i) = edge->src();\n    input_idx.at(i) = edge->src_output();\n  }\n\n  // Note: technically, we could use a very generic type when some of the inputs\n  // are unknown. But there is an expectation that a node will have complete\n  // inputs soon, so updating intermediate types is largely unnecessary.\n\n  for (const auto* node : input_nodes) {\n    if (node == nullptr) {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  static FullTypeDef* no_type = new FullTypeDef();\n\n  std::vector<std::reference_wrapper<const FullTypeDef>> input_types;\n  for (int i = 0; i < input_nodes.size(); i++) {\n    const auto* node = input_nodes[i];\n    if (node->def().has_experimental_type()) {\n      const auto& node_t = node->def().experimental_type();\n      if (node_t.type_id() != TFT_UNSET) {\n        int ix = input_idx[i];\n        DCHECK(ix < node_t.args_size())\n            << \"input \" << i << \" should have an output \" << ix\n            << \" but instead only has \" << node_t.args_size()\n            << \" outputs: \" << node_t.DebugString();\n        input_types.emplace_back(node_t.args(ix));\n      } else {\n        input_types.emplace_back(*no_type);\n      }\n    } else {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  const auto infer_type = props_->fwd_type_fn(input_types);\n  const FullTypeDef infer_typedef = infer_type.ValueOrDie();\n  if (infer_typedef.type_id() != TFT_UNSET) {\n    MaybeCopyOnWrite();\n    *(props_->node_def.mutable_experimental_type()) = infer_typedef;\n  }\n}",
        "post_patch": "void Node::RunForwardTypeInference() {\n  VLOG(4) << \"Forward type inference: \" << props_->node_def.DebugString();\n\n  if (props_->fwd_type_fn == nullptr) {\n    return;\n  }\n\n  std::vector<Node*> input_nodes(props_->input_types.size(), nullptr);\n  std::vector<int> input_idx(props_->input_types.size(), 0);\n  for (const auto& edge : in_edges_) {\n    if (edge->IsControlEdge()) {\n      continue;\n    }\n    DCHECK(edge->dst_input() < input_nodes.size()) << DebugString();\n    int i = edge->dst_input();\n    input_nodes.at(i) = edge->src();\n    input_idx.at(i) = edge->src_output();\n  }\n\n  // Note: technically, we could use a very generic type when some of the inputs\n  // are unknown. But there is an expectation that a node will have complete\n  // inputs soon, so updating intermediate types is largely unnecessary.\n\n  for (const auto* node : input_nodes) {\n    if (node == nullptr) {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  static FullTypeDef* no_type = new FullTypeDef();\n\n  std::vector<std::reference_wrapper<const FullTypeDef>> input_types;\n  for (int i = 0; i < input_nodes.size(); i++) {\n    const auto* node = input_nodes[i];\n    if (node->def().has_experimental_type()) {\n      const auto& node_t = node->def().experimental_type();\n      if (node_t.type_id() != TFT_UNSET) {\n        int ix = input_idx[i];\n        if (ix >= node_t.args_size()) {\n          LOG(WARNING) << name() << \" has bad type information: input \" << i\n                       << \" should have an output \" << ix\n                       << \" but instead only has \" << node_t.args_size()\n                       << \" outputs: \" << node_t.DebugString()\n                       << \"\\nThis indicates either \"\n                          \"a bug in op registration or a corrupted graph.\";\n          ClearTypeInfo();\n          return;\n        }\n        input_types.emplace_back(node_t.args(ix));\n      } else {\n        input_types.emplace_back(*no_type);\n      }\n    } else {\n      // Incomplete inputs, bail.\n      ClearTypeInfo();\n      return;\n    }\n  }\n\n  const auto infer_type = props_->fwd_type_fn(input_types);\n  const FullTypeDef infer_typedef = infer_type.ValueOrDie();\n  if (infer_typedef.type_id() != TFT_UNSET) {\n    MaybeCopyOnWrite();\n    *(props_->node_def.mutable_experimental_type()) = infer_typedef;\n  }\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n{\n  struct RArray *a = mrb_ary_ptr(self);\n  mrb_int len = ARY_LEN(a);\n  mrb_int n;\n  mrb_value val;\n\n  if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n    return mrb_ary_shift(mrb, self);\n  };\n  ary_modify_check(mrb, a);\n  if (len == 0 || n == 0) return mrb_ary_new(mrb);\n  if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n  if (n > len) n = len;\n  val = mrb_ary_new_from_values(mrb, n, ARY_PTR(a));\n  if (ARY_SHARED_P(a)) {\n  L_SHIFT:\n    a->as.heap.ptr+=n;\n    a->as.heap.len-=n;\n    return val;\n  }\n  if (len > ARY_SHIFT_SHARED_MIN) {\n    ary_make_shared(mrb, a);\n    goto L_SHIFT;\n  }\n  else if (len == n) {\n    ARY_SET_LEN(a, 0);\n  }\n  else {\n    mrb_value *ptr = ARY_PTR(a);\n    mrb_int size = len-n;\n\n    while (size--) {\n      *ptr = *(ptr+n);\n      ++ptr;\n    }\n    ARY_SET_LEN(a, len-n);\n  }\n  return val;\n}",
        "post_patch": "mrb_ary_shift_m(mrb_state *mrb, mrb_value self)\n{\n  mrb_int n;\n\n  if (mrb_get_args(mrb, \"|i\", &n) == 0) {\n    return mrb_ary_shift(mrb, self);\n  }\n\n  struct RArray *a = mrb_ary_ptr(self);\n  mrb_int len = ARY_LEN(a);\n  mrb_value val;\n\n  ary_modify_check(mrb, a);\n  if (len == 0 || n == 0) return mrb_ary_new(mrb);\n  if (n < 0) mrb_raise(mrb, E_ARGUMENT_ERROR, \"negative array shift\");\n  if (n > len) n = len;\n  val = mrb_ary_new_from_values(mrb, n, ARY_PTR(a));\n  if (ARY_SHARED_P(a)) {\n  L_SHIFT:\n    a->as.heap.ptr+=n;\n    a->as.heap.len-=n;\n    return val;\n  }\n  if (len > ARY_SHIFT_SHARED_MIN) {\n    ary_make_shared(mrb, a);\n    goto L_SHIFT;\n  }\n  else if (len == n) {\n    ARY_SET_LEN(a, 0);\n  }\n  else {\n    mrb_value *ptr = ARY_PTR(a);\n    mrb_int size = len-n;\n\n    while (size--) {\n      *ptr = *(ptr+n);\n      ++ptr;\n    }\n    ARY_SET_LEN(a, len-n);\n  }\n  return val;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void operator()(OpKernelContext* ctx, const Tensor& input,\n                  const Tensor& filter, int row_stride, int col_stride,\n                  int row_dilation, int col_dilation, const Padding& padding,\n                  const std::vector<int64_t>& explicit_paddings, Tensor* output,\n                  TensorFormat data_format) {\n    DCHECK(data_format == FORMAT_NHWC)\n        << \"Grouped conv implementation only \"\n           \"supports NHWC tensor format for now.\";\n\n    const int64_t in_depth = input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n    const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3, 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0), tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3) / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2), tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary tensor.\n    Tensor input_shuffled(input.dtype(), TensorShape(post_shuffle(input)));\n    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary tensor.\n    Tensor filter_shuffled(filter.dtype(), TensorShape(post_shuffle(filter)));\n    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group convolution results into temporary output tensor.\n    Tensor output_shuffled(output->dtype(), TensorShape(post_shuffle(*output)));\n\n    for (int64_t i = 0; i < num_groups; ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async Eigen\n      // assignment). This requires small changes to Eigen to support async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev): Grouped convolution should also support 1x1 filter\n      // optimization.\n\n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1, 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device) =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }",
        "post_patch": "  void operator()(OpKernelContext* ctx, const Tensor& input,\n                  const Tensor& filter, int row_stride, int col_stride,\n                  int row_dilation, int col_dilation, const Padding& padding,\n                  const std::vector<int64_t>& explicit_paddings, Tensor* output,\n                  TensorFormat data_format) {\n    DCHECK(data_format == FORMAT_NHWC)\n        << \"Grouped conv implementation only \"\n           \"supports NHWC tensor format for now.\";\n\n    const int64_t in_depth = input.dim_size(3);\n    const int64_t patch_depth = filter.dim_size(2);\n    const int64_t num_groups = in_depth / patch_depth;\n\n    // Shuffle input/filter tensors to have group as a leading dimension.\n    std::array<int64_t, 5> shuffle({3, 0, 1, 2, 4});\n\n    // Compute pre shuffle dimemnsions.\n    auto pre_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {tensor.dim_size(0), tensor.dim_size(1), tensor.dim_size(2),\n              num_groups, tensor.dim_size(3) / num_groups};\n    };\n\n    // Compute post shuffle dimemnsions.\n    auto post_shuffle = [&](const Tensor& tensor) -> std::array<int64, 5> {\n      return {num_groups, tensor.dim_size(0), tensor.dim_size(1),\n              tensor.dim_size(2), tensor.dim_size(3) / num_groups};\n    };\n\n    auto& device = ctx->eigen_device<CPUDevice>();\n\n    absl::BlockingCounter shuffles_completed(2);\n    auto on_shuffled = [&]() { shuffles_completed.DecrementCount(); };\n\n    // Shuffle input into temporary tensor.\n    Tensor input_shuffled;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_temp(input.dtype(), TensorShape(post_shuffle(input)),\n                                &input_shuffled));\n    input_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        input.shaped<T, 5>(pre_shuffle(input)).shuffle(shuffle);\n\n    // Shuffle filter into temporary tensor.\n    Tensor filter_shuffled;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(filter.dtype(),\n                                           TensorShape(post_shuffle(filter)),\n                                           &filter_shuffled));\n    filter_shuffled.tensor<T, 5>().device(device, on_shuffled) =\n        filter.shaped<T, 5>(pre_shuffle(filter)).shuffle(shuffle);\n\n    // Wait for the completion of input/filter shuffles.\n    shuffles_completed.Wait();\n\n    // Write group convolution results into temporary output tensor.\n    Tensor output_shuffled;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(output->dtype(),\n                                           TensorShape(post_shuffle(*output)),\n                                           &output_shuffled));\n\n    for (int64_t i = 0; i < num_groups; ++i) {\n      // TODO(ezhulenev): Run this loop using `parallelFor` (regular parallelFor\n      // will lead to deadlock, SpatialConvolution has to use async Eigen\n      // assignment). This requires small changes to Eigen to support async\n      // exeuction for tensor chipping operation.\n\n      // TODO(ezhulenev): Grouped convolution should also support 1x1 filter\n      // optimization.\n\n      auto input_slice = input_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto filter_slice = filter_shuffled.tensor<T, 5>().template chip<0>(i);\n      auto output_slice = output_shuffled.tensor<T, 5>().template chip<0>(i);\n\n      if (padding == EXPLICIT) {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            static_cast<int>(explicit_paddings[2]),\n            static_cast<int>(explicit_paddings[3]),\n            static_cast<int>(explicit_paddings[4]),\n            static_cast<int>(explicit_paddings[5]));\n      } else {\n        functor::SpatialConvolution<CPUDevice, T>()(\n            ctx->eigen_device<CPUDevice>(), output_slice, input_slice,\n            filter_slice, row_stride, col_stride, row_dilation, col_dilation,\n            BrainPadding2EigenPadding(padding));\n      }\n    }\n\n    // Shuffle temporary output back into pre-shuffled shape.\n    std::array<int64_t, 5> rev_shuffle({1, 2, 3, 0, 4});\n    output->shaped<T, 5>(pre_shuffle(*output)).device(device) =\n        output_shuffled.tensor<T, 5>().shuffle(rev_shuffle);\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n                                const XlaPlatformInfo& platform_info,\n                                XlaCompilationCache** cache) {\n  if (platform_info.xla_device_metadata()) {\n    *cache = new XlaCompilationCache(\n        platform_info.xla_device_metadata()->client(),\n        platform_info.xla_device_metadata()->jit_device_type());\n    return Status::OK();\n  }\n\n  auto platform =\n      se::MultiPlatformManager::PlatformWithId(platform_info.platform_id());\n  if (!platform.ok()) {\n    return platform.status();\n  }\n\n  StatusOr<xla::Compiler*> compiler_for_platform =\n      xla::Compiler::GetForPlatform(platform.ValueOrDie());\n  if (!compiler_for_platform.ok()) {\n    // In some rare cases (usually in unit tests with very small clusters) we\n    // may end up transforming an XLA cluster with at least one GPU operation\n    // (which would normally force the cluster to be compiled using XLA:GPU)\n    // into an XLA cluster with no GPU operations (i.e. containing only CPU\n    // operations).  Such a cluster can fail compilation (in way that\n    // MarkForCompilation could not have detected) if the CPU JIT is not linked\n    // in.\n    //\n    // So bail out of _XlaCompile in this case, and let the executor handle the\n    // situation for us.\n    const Status& status = compiler_for_platform.status();\n    if (status.code() == error::NOT_FOUND) {\n      return errors::Unimplemented(\"Could not find compiler for platform \",\n                                   platform.ValueOrDie()->Name(), \": \",\n                                   status.ToString());\n    }\n  }\n\n  xla::LocalClientOptions client_options;\n  client_options.set_platform(platform.ValueOrDie());\n  client_options.set_intra_op_parallelism_threads(\n      device->tensorflow_cpu_worker_threads()->num_threads);\n\n  string allowed_gpus =\n      flr->config_proto()->gpu_options().visible_device_list();\n  TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n                      ParseVisibleDeviceList(allowed_gpus));\n  client_options.set_allowed_devices(gpu_ids);\n\n  auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n  if (!client.ok()) {\n    return client.status();\n  }\n  const XlaOpRegistry::DeviceRegistration* registration;\n  if (!XlaOpRegistry::GetCompilationDevice(platform_info.device_type().type(),\n                                           &registration)) {\n    return errors::InvalidArgument(\"No JIT device registered for \",\n                                   platform_info.device_type().type());\n  }\n  *cache = new XlaCompilationCache(\n      client.ValueOrDie(), DeviceType(registration->compilation_device_name));\n  return Status::OK();\n}",
        "post_patch": "Status BuildXlaCompilationCache(DeviceBase* device, FunctionLibraryRuntime* flr,\n                                const XlaPlatformInfo& platform_info,\n                                XlaCompilationCache** cache) {\n  if (platform_info.xla_device_metadata()) {\n    *cache = new XlaCompilationCache(\n        platform_info.xla_device_metadata()->client(),\n        platform_info.xla_device_metadata()->jit_device_type());\n    return Status::OK();\n  }\n\n  auto platform =\n      se::MultiPlatformManager::PlatformWithId(platform_info.platform_id());\n  if (!platform.ok()) {\n    return platform.status();\n  }\n\n  StatusOr<xla::Compiler*> compiler_for_platform =\n      xla::Compiler::GetForPlatform(platform.ValueOrDie());\n  if (!compiler_for_platform.ok()) {\n    // In some rare cases (usually in unit tests with very small clusters) we\n    // may end up transforming an XLA cluster with at least one GPU operation\n    // (which would normally force the cluster to be compiled using XLA:GPU)\n    // into an XLA cluster with no GPU operations (i.e. containing only CPU\n    // operations).  Such a cluster can fail compilation (in way that\n    // MarkForCompilation could not have detected) if the CPU JIT is not linked\n    // in.\n    //\n    // So bail out of _XlaCompile in this case, and let the executor handle the\n    // situation for us.\n    const Status& status = compiler_for_platform.status();\n    if (status.code() == error::NOT_FOUND) {\n      return errors::Unimplemented(\"Could not find compiler for platform \",\n                                   platform.ValueOrDie()->Name(), \": \",\n                                   status.ToString());\n    }\n  }\n\n  xla::LocalClientOptions client_options;\n  client_options.set_platform(platform.ValueOrDie());\n  client_options.set_intra_op_parallelism_threads(\n      device->tensorflow_cpu_worker_threads()->num_threads);\n\n  if (flr->config_proto()) {\n    string allowed_gpus =\n        flr->config_proto()->gpu_options().visible_device_list();\n    TF_ASSIGN_OR_RETURN(absl::optional<std::set<int>> gpu_ids,\n                        ParseVisibleDeviceList(allowed_gpus));\n    client_options.set_allowed_devices(gpu_ids);\n  }\n\n  auto client = xla::ClientLibrary::GetOrCreateLocalClient(client_options);\n  if (!client.ok()) {\n    return client.status();\n  }\n  const XlaOpRegistry::DeviceRegistration* registration;\n  if (!XlaOpRegistry::GetCompilationDevice(platform_info.device_type().type(),\n                                           &registration)) {\n    return errors::InvalidArgument(\"No JIT device registered for \",\n                                   platform_info.device_type().type());\n  }\n  *cache = new XlaCompilationCache(\n      client.ValueOrDie(), DeviceType(registration->compilation_device_name));\n  return Status::OK();\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void Compute(OpKernelContext* context) override {\n    const Tensor& indices = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& shape = context->input(2);\n    const Tensor& weights = context->input(3);\n    bool use_weights = weights.NumElements() > 0;\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices must be a 2-dimensional tensor. Got: \",\n                    indices.shape().DebugString()));\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    OP_REQUIRES(context, shape.NumElements() != 0,\n                errors::InvalidArgument(\n                    \"The shape argument requires at least one element.\"));\n\n    bool is_1d = shape.NumElements() == 1;\n    auto shape_vector = shape.flat<int64_t>();\n    int num_batches = is_1d ? 1 : shape_vector(0);\n    int num_values = values.NumElements();\n\n    for (int b = 0; b < shape_vector.size(); b++) {\n      OP_REQUIRES(context, shape_vector(b) >= 0,\n                  errors::InvalidArgument(\n                      \"Elements in dense_shape must be >= 0. Instead got:\",\n                      shape.DebugString()));\n    }\n\n    OP_REQUIRES(context, num_values == indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"Number of values must match first dimension of indices.\",\n                    \"Got \", num_values,\n                    \" values, indices shape: \", indices.shape().DebugString()));\n\n    const auto indices_values = indices.matrix<int64_t>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n\n    T max_value = 0;\n\n    OP_REQUIRES(context, num_values <= indices.shape().dim_size(0),\n                errors::InvalidArgument(\n                    \"The first dimension of indices must be equal to or \"\n                    \"greather than number of values. ( \",\n                    indices.shape().dim_size(0), \" vs. \", num_values, \" )\"));\n    OP_REQUIRES(context, indices.shape().dim_size(1) > 0,\n                errors::InvalidArgument(\"The second dimension of indices must \"\n                                        \"be greater than 0. Received: \",\n                                        indices.shape().dim_size(1)));\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      int batch = is_1d ? 0 : indices_values(idx, 0);\n      if (batch >= num_batches) {\n        OP_REQUIRES(context, batch < num_batches,\n                    errors::InvalidArgument(\n                        \"Indices value along the first dimension must be \",\n                        \"lower than the first index of the shape.\", \"Got \",\n                        batch, \" as batch and \", num_batches,\n                        \" as the first dimension of the shape.\"));\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "post_patch": "  void Compute(OpKernelContext* context) override {\n    const Tensor& splits = context->input(0);\n    const Tensor& values = context->input(1);\n    const Tensor& weights = context->input(2);\n    bool use_weights = weights.NumElements() > 0;\n    bool is_1d = false;\n\n    if (use_weights) {\n      OP_REQUIRES(\n          context, weights.shape() == values.shape(),\n          errors::InvalidArgument(\n              \"Weights and values must have the same shape. Weight shape: \",\n              weights.shape().DebugString(),\n              \"; values shape: \", values.shape().DebugString()));\n    }\n\n    const auto splits_values = splits.flat<int64_t>();\n    const auto values_values = values.flat<T>();\n    const auto weight_values = weights.flat<W>();\n    int num_batches = splits.NumElements() - 1;\n    int num_values = values.NumElements();\n\n    OP_REQUIRES(\n        context, num_batches > 0,\n        errors::InvalidArgument(\n            \"Must provide at least 2 elements for the splits argument\"));\n    OP_REQUIRES(context, splits_values(0) == 0,\n                errors::InvalidArgument(\"Splits must start with 0, not with \",\n                                        splits_values(0)));\n    OP_REQUIRES(context, splits_values(num_batches) == num_values,\n                errors::InvalidArgument(\n                    \"Splits must end with the number of values, got \",\n                    splits_values(num_batches), \" instead of \", num_values));\n\n    auto per_batch_counts = BatchedMap<W>(num_batches);\n    T max_value = 0;\n    int batch_idx = 0;\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits_values(batch_idx)) {\n        batch_idx++;\n      }\n      const auto& value = values_values(idx);\n      if (value >= 0 && (maxlength_ <= 0 || value < maxlength_)) {\n        if (binary_output_) {\n          per_batch_counts[batch_idx - 1][value] = 1;\n        } else if (use_weights) {\n          per_batch_counts[batch_idx - 1][value] += weight_values(idx);\n        } else {\n          per_batch_counts[batch_idx - 1][value]++;\n        }\n        if (value > max_value) {\n          max_value = value;\n        }\n      }\n    }\n\n    int num_output_values = GetOutputSize(max_value, maxlength_, minlength_);\n    OP_REQUIRES_OK(context, OutputSparse<W>(per_batch_counts, num_output_values,\n                                            is_1d, context));\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;\n  float* array_end_ptr = array_ptr + array_size;\n  const auto clamp_min_vec = vdupq_n_f32(clamp_min);\n  const auto clamp_max_vec = vdupq_n_f32(clamp_max);\n  for (; array_ptr != array_end_ptr; array_ptr += bias_size) {\n    int i = 0;\n    for (; i <= bias_size - 16; i += 16) {\n      auto b0 = vld1q_f32(bias_data + i);\n      auto b1 = vld1q_f32(bias_data + i + 4);\n      auto b2 = vld1q_f32(bias_data + i + 8);\n      auto b3 = vld1q_f32(bias_data + i + 12);\n      auto a0 = vld1q_f32(array_ptr + i);\n      auto a1 = vld1q_f32(array_ptr + i + 4);\n      auto a2 = vld1q_f32(array_ptr + i + 8);\n      auto a3 = vld1q_f32(array_ptr + i + 12);\n      auto x0 = vaddq_f32(a0, b0);\n      auto x1 = vaddq_f32(a1, b1);\n      auto x2 = vaddq_f32(a2, b2);\n      auto x3 = vaddq_f32(a3, b3);\n      x0 = vmaxq_f32(clamp_min_vec, x0);\n      x1 = vmaxq_f32(clamp_min_vec, x1);\n      x2 = vmaxq_f32(clamp_min_vec, x2);\n      x3 = vmaxq_f32(clamp_min_vec, x3);\n      x0 = vminq_f32(clamp_max_vec, x0);\n      x1 = vminq_f32(clamp_max_vec, x1);\n      x2 = vminq_f32(clamp_max_vec, x2);\n      x3 = vminq_f32(clamp_max_vec, x3);\n      vst1q_f32(array_ptr + i, x0);\n      vst1q_f32(array_ptr + i + 4, x1);\n      vst1q_f32(array_ptr + i + 8, x2);\n      vst1q_f32(array_ptr + i + 12, x3);\n    }\n    for (; i <= bias_size - 4; i += 4) {\n      auto b = vld1q_f32(bias_data + i);\n      auto a = vld1q_f32(array_ptr + i);\n      auto x = vaddq_f32(a, b);\n      x = vmaxq_f32(clamp_min_vec, x);\n      x = vminq_f32(clamp_max_vec, x);\n      vst1q_f32(array_ptr + i, x);\n    }\n    for (; i < bias_size; i++) {\n      array_ptr[i] = ActivationFunctionWithMinMax(array_ptr[i] + bias_data[i],\n                                                  clamp_min, clamp_max);\n    }\n  }\n#else  // not NEON\n  for (int array_offset = 0; array_offset < array_size;\n       array_offset += bias_size) {\n    for (int i = 0; i < bias_size; i++) {\n      array_data[array_offset + i] = ActivationFunctionWithMinMax(\n          array_data[array_offset + i] + bias_data[i], clamp_min, clamp_max);\n    }\n  }\n#endif\n}",
        "post_patch": "inline void BiasAndClamp(float clamp_min, float clamp_max, int bias_size,\n                         const float* bias_data, int array_size,\n                         float* array_data) {\n  if (bias_size == 0) return;\n  // Note: see b/132215220: in May 2019 we thought it would be OK to replace\n  // this with the Eigen one-liner:\n  //   return (array.colwise() + bias).cwiseMin(clamp_max).cwiseMin(clamp_max).\n  // This turned out to severely regress performance: +4ms (i.e. 8%) on\n  // MobileNet v2 / 1.0 / 224. So we keep custom NEON code for now.\n  TFLITE_DCHECK_EQ((array_size % bias_size), 0);\n#ifdef USE_NEON\n  float* array_ptr = array_data;\n  float* array_end_ptr = array_ptr + array_size;\n  const auto clamp_min_vec = vdupq_n_f32(clamp_min);\n  const auto clamp_max_vec = vdupq_n_f32(clamp_max);\n  for (; array_ptr != array_end_ptr; array_ptr += bias_size) {\n    int i = 0;\n    for (; i <= bias_size - 16; i += 16) {\n      auto b0 = vld1q_f32(bias_data + i);\n      auto b1 = vld1q_f32(bias_data + i + 4);\n      auto b2 = vld1q_f32(bias_data + i + 8);\n      auto b3 = vld1q_f32(bias_data + i + 12);\n      auto a0 = vld1q_f32(array_ptr + i);\n      auto a1 = vld1q_f32(array_ptr + i + 4);\n      auto a2 = vld1q_f32(array_ptr + i + 8);\n      auto a3 = vld1q_f32(array_ptr + i + 12);\n      auto x0 = vaddq_f32(a0, b0);\n      auto x1 = vaddq_f32(a1, b1);\n      auto x2 = vaddq_f32(a2, b2);\n      auto x3 = vaddq_f32(a3, b3);\n      x0 = vmaxq_f32(clamp_min_vec, x0);\n      x1 = vmaxq_f32(clamp_min_vec, x1);\n      x2 = vmaxq_f32(clamp_min_vec, x2);\n      x3 = vmaxq_f32(clamp_min_vec, x3);\n      x0 = vminq_f32(clamp_max_vec, x0);\n      x1 = vminq_f32(clamp_max_vec, x1);\n      x2 = vminq_f32(clamp_max_vec, x2);\n      x3 = vminq_f32(clamp_max_vec, x3);\n      vst1q_f32(array_ptr + i, x0);\n      vst1q_f32(array_ptr + i + 4, x1);\n      vst1q_f32(array_ptr + i + 8, x2);\n      vst1q_f32(array_ptr + i + 12, x3);\n    }\n    for (; i <= bias_size - 4; i += 4) {\n      auto b = vld1q_f32(bias_data + i);\n      auto a = vld1q_f32(array_ptr + i);\n      auto x = vaddq_f32(a, b);\n      x = vmaxq_f32(clamp_min_vec, x);\n      x = vminq_f32(clamp_max_vec, x);\n      vst1q_f32(array_ptr + i, x);\n    }\n    for (; i < bias_size; i++) {\n      array_ptr[i] = ActivationFunctionWithMinMax(array_ptr[i] + bias_data[i],\n                                                  clamp_min, clamp_max);\n    }\n  }\n#else  // not NEON\n  for (int array_offset = 0; array_offset < array_size;\n       array_offset += bias_size) {\n    for (int i = 0; i < bias_size; i++) {\n      array_data[array_offset + i] = ActivationFunctionWithMinMax(\n          array_data[array_offset + i] + bias_data[i], clamp_min, clamp_max);\n    }\n  }\n#endif\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  CHECK(input != nullptr) << \"node = \" << node.name()\n                          << \" input = \" << node.input(0);\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}",
        "post_patch": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  if (input == nullptr) {\n    VLOG(1) << \"node = \" << node.name() << \" input = \" << node.input(0);\n    return false;\n  }\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "GF_Err mpgviddmx_process(GF_Filter *filter)\n{\n\tGF_MPGVidDmxCtx *ctx = gf_filter_get_udta(filter);\n\tGF_FilterPacket *pck, *dst_pck;\n\tu64 byte_offset;\n\ts64 vosh_start = -1;\n\ts64 vosh_end = -1;\n\tGF_Err e;\n\tchar *data;\n\tu8 *start;\n\tu32 pck_size;\n\ts32 remain;\n\n\t//always reparse duration\n\tif (!ctx->duration.num)\n\t\tmpgviddmx_check_dur(filter, ctx);\n\n\tpck = gf_filter_pid_get_packet(ctx->ipid);\n\tif (!pck) {\n\t\tif (gf_filter_pid_is_eos(ctx->ipid)) {\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_TRUE);\n\t\t\tif (ctx->opid)\n\t\t\t\tgf_filter_pid_set_eos(ctx->opid);\n\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\tctx->src_pck = NULL;\n\t\t\treturn GF_EOS;\n\t\t}\n\t\treturn GF_OK;\n\t}\n\n\tdata = (char *) gf_filter_pck_get_data(pck, &pck_size);\n\tbyte_offset = gf_filter_pck_get_byte_offset(pck);\n\n\tstart = data;\n\tremain = pck_size;\n\n\t//input pid sets some timescale - we flushed pending data , update cts\n\tif (!ctx->resume_from && ctx->timescale) {\n\t\tu64 ts = gf_filter_pck_get_cts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->cts || !ctx->recompute_cts)\n\t\t\t\tctx->cts = ts;\n\t\t}\n\t\tts = gf_filter_pck_get_dts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->dts || !ctx->recompute_cts)\n\t\t\t\tctx->dts = ts;\n\n\t\t\tif (!ctx->prev_dts) ctx->prev_dts = ts;\n\t\t\telse if (ctx->prev_dts != ts) {\n\t\t\t\tu64 diff = ts;\n\t\t\t\tdiff -= ctx->prev_dts;\n\t\t\t\tif (!ctx->cur_fps.den) ctx->cur_fps.den = (u32) diff;\n\t\t\t\telse if (ctx->cur_fps.den > diff)\n\t\t\t\t\tctx->cur_fps.den = (u32) diff;\n\t\t\t}\n\t\t}\n\t\tgf_filter_pck_get_framing(pck, &ctx->input_is_au_start, &ctx->input_is_au_end);\n\t\t//this will force CTS recomput of each frame\n\t\tif (ctx->recompute_cts) ctx->input_is_au_start = GF_FALSE;\n\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\tctx->src_pck = pck;\n\t\tgf_filter_pck_ref_props(&ctx->src_pck);\n\t}\n\n\t//we stored some data to find the complete vosh, aggregate this packet with current one\n\tif (!ctx->resume_from && ctx->hdr_store_size) {\n\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size) {\n\t\t\tctx->hdr_store_alloc = ctx->hdr_store_size + pck_size;\n\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t}\n\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data, sizeof(char)*pck_size);\n\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\tif (byte_offset >= ctx->hdr_store_size)\n\t\t\t\tbyte_offset -= ctx->hdr_store_size;\n\t\t\telse\n\t\t\t\tbyte_offset = GF_FILTER_NO_BO;\n\t\t}\n\t\tctx->hdr_store_size += pck_size;\n\t\tstart = data = ctx->hdr_store;\n\t\tremain = pck_size = ctx->hdr_store_size;\n\t}\n\n\tif (ctx->resume_from) {\n\t\tif (gf_filter_pid_would_block(ctx->opid))\n\t\t\treturn GF_OK;\n\n\t\t//resume from data copied internally\n\t\tif (ctx->hdr_store_size) {\n\t\t\tassert(ctx->resume_from <= ctx->hdr_store_size);\n\t\t\tstart = data = ctx->hdr_store + ctx->resume_from;\n\t\t\tremain = pck_size = ctx->hdr_store_size - ctx->resume_from;\n\t\t} else {\n\t\t\tassert(remain >= (s32) ctx->resume_from);\n\t\t\tstart += ctx->resume_from;\n\t\t\tremain -= ctx->resume_from;\n\t\t}\n\t\tctx->resume_from = 0;\n\t}\n\n\tif (!ctx->bs) {\n\t\tctx->bs = gf_bs_new(start, remain, GF_BITSTREAM_READ);\n\t} else {\n\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t}\n\tif (!ctx->vparser) {\n\t\tctx->vparser = gf_m4v_parser_bs_new(ctx->bs, ctx->is_mpg12);\n\t}\n\n\n\twhile (remain) {\n\t\tBool full_frame;\n\t\tu8 *pck_data;\n\t\ts32 current;\n\t\tu8 sc_type, forced_sc_type=0;\n\t\tBool sc_type_forced = GF_FALSE;\n\t\tBool skip_pck = GF_FALSE;\n\t\tu8 ftype;\n\t\tu32 tinc;\n\t\tu64 size=0;\n\t\tu64 fstart;\n\t\tBool is_coded;\n\t\tu32 bytes_from_store = 0;\n\t\tu32 hdr_offset = 0;\n\t\tBool copy_last_bytes = GF_FALSE;\n\n\t\t//not enough bytes to parse start code\n\t\tif (remain<5) {\n\t\t\tmemcpy(ctx->hdr_store, start, remain);\n\t\t\tctx->bytes_in_header = remain;\n\t\t\tbreak;\n\t\t}\n\t\tcurrent = -1;\n\n\t\t//we have some potential bytes of a start code in the store, copy some more bytes and check if valid start code.\n\t\t//if not, dispatch these bytes as continuation of the data\n\t\tif (ctx->bytes_in_header) {\n\n\t\t\tmemcpy(ctx->hdr_store + ctx->bytes_in_header, start, 8 - ctx->bytes_in_header);\n\t\t\tcurrent = mpgviddmx_next_start_code(ctx->hdr_store, 8);\n\n\t\t\t//no start code in stored buffer\n\t\t\tif ((current<0) || (current >= (s32) ctx->bytes_in_header) )  {\n\t\t\t\tif (ctx->opid) {\n\t\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, ctx->bytes_in_header, &pck_data);\n\t\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tmemcpy(pck_data, ctx->hdr_store, ctx->bytes_in_header);\n\t\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\n\t\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - ctx->bytes_in_header);\n\t\t\t\t\t}\n\n\t\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\t}\n\n\t\t\t\tif (current<0) current = -1;\n\t\t\t\telse current -= ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t} else {\n\t\t\t\t//we have a valid start code, check which byte in our store or in the packet payload is the start code type\n\t\t\t\t//and remember its location to reinit the parser from there\n\t\t\t\thdr_offset = 4 - ctx->bytes_in_header + current;\n\t\t\t\t//bytes still to dispatch\n\t\t\t\tbytes_from_store = ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t\tif (!hdr_offset) {\n\t\t\t\t\tforced_sc_type = ctx->hdr_store[current+3];\n\t\t\t\t} else {\n\t\t\t\t\tforced_sc_type = start[hdr_offset-1];\n\t\t\t\t}\n\t\t\t\tsc_type_forced = GF_TRUE;\n\t\t\t}\n\t\t}\n\t\t//no starcode in store, look for startcode in packet\n\t\tif (current == -1) {\n\t\t\t//locate next start code\n\t\t\tcurrent = mpgviddmx_next_start_code(start, remain);\n\t\t\t//no start code, dispatch the block\n\t\t\tif (current<0) {\n\t\t\t\tu8 b3, b2, b1;\n\t\t\t\tif (! ctx->frame_started) {\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MPGVid] no start code in block and no frame started, discarding data\\n\" ));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsize = remain;\n\t\t\t\tb3 = start[remain-3];\n\t\t\t\tb2 = start[remain-2];\n\t\t\t\tb1 = start[remain-1];\n\t\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\t\tassert(size >= 3);\n\t\t\t\t\tsize -= 3;\n\t\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t\t}\n\n\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\n\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tif (copy_last_bytes) {\n\t\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tassert(current>=0);\n\n\t\t//if we are in the middle of parsing the vosh, skip over bytes remaining from previous obj not parsed\n\t\tif ((vosh_start>=0) && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//also skip if no output pid\n\t\tif (!ctx->opid && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//dispatch remaining bytes\n\t\tif (current>0) {\n\t\t\t//flush remaining\n\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, current, &pck_data);\n\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_TRUE);\n\t\t\t//bytes were partly in store, partly in packet\n\t\t\tif (bytes_from_store) {\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t\t}\n\t\t\t\tassert(bytes_from_store>=(u32) current);\n\t\t\t\tbytes_from_store -= current;\n\t\t\t\tmemcpy(pck_data, ctx->hdr_store, current);\n\t\t\t} else {\n\t\t\t\t//bytes were only in packet\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\t\t\t\tmemcpy(pck_data, start, current);\n\t\t\t\tassert(remain>=current);\n\t\t\t\tstart += current;\n\t\t\t\tremain -= current;\n\t\t\t\tcurrent = 0;\n\t\t\t}\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t}\n\n\t\t//parse headers\n\n\t\t//we have a start code loaded, eg the data packet does not have a full start code at the beginning\n\t\tif (sc_type_forced) {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start + hdr_offset, remain - hdr_offset);\n\t\t\tsc_type = forced_sc_type;\n\t\t} else {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\tgf_bs_read_int(ctx->bs, 24);\n\t\t\tsc_type = gf_bs_read_int(ctx->bs, 8);\n\t\t}\n\n\t\tif (ctx->is_mpg12) {\n\t\t\tswitch (sc_type) {\n\t\t\tcase M2V_SEQ_START_CODE:\n\t\t\tcase M2V_EXT_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx, 0, NULL);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M2V_PIC_START_CODE:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else {\n\t\t\tu8 PL;\n\t\t\tswitch (sc_type) {\n\t\t\tcase M4V_VOS_START_CODE:\n\t\t\t\tctx->dsi.VideoPL = (u8) gf_bs_read_u8(ctx->bs);\n\t\t\t\tvosh_start = start - (u8 *)data;\n\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\tassert(remain>=5);\n\t\t\t\tstart += 5;\n\t\t\t\tremain -= 5;\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOL_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\tPL = ctx->dsi.VideoPL;\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\tctx->dsi.VideoPL = PL;\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - (u32) vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tu32 obj_size = (u32) gf_m4v_get_object_start(ctx->vparser);\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tvosh_end = start - (u8 *)data + obj_size;\n\t\t\t\t\tvosh_end -= vosh_start;\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx,(u32)  vosh_end, data+vosh_start);\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=(s32) obj_size);\n\t\t\t\t\tstart += obj_size;\n\t\t\t\t\tremain -= obj_size;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOP_START_CODE:\n\t\t\tcase M4V_GOV_START_CODE:\n\t\t\t\tbreak;\n\n\t\t\tcase M4V_VO_START_CODE:\n\t\t\tcase M4V_VISOBJ_START_CODE:\n\t\t\tdefault:\n\t\t\t\tif (vosh_start>=0) {\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=4);\n\t\t\t\t\tstart += 4;\n\t\t\t\t\tremain -= 4;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (skip_pck) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->opid) {\n\t\t\tassert(remain>=4);\n\t\t\tstart += 4;\n\t\t\tremain -= 4;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->is_playing) {\n\t\t\tctx->resume_from = (u32) ((char *)start -  (char *)data);\n\t\t\treturn GF_OK;\n\t\t}\n\t\t//at this point, we no longer reaggregate packets\n\t\tctx->hdr_store_size = 0;\n\n\t\tif (ctx->in_seek) {\n\t\t\tu64 nb_frames_at_seek = (u64) (ctx->start_range * ctx->cur_fps.num);\n\t\t\tif (ctx->cts + ctx->cur_fps.den >= nb_frames_at_seek) {\n\t\t\t\t//u32 samples_to_discard = (ctx->cts + ctx->dts_inc) - nb_samples_at_seek;\n\t\t\t\tctx->in_seek = GF_FALSE;\n\t\t\t}\n\t\t}\n\t\t//may happen that after all our checks, only 4 bytes are left, continue to store these 4 bytes\n\t\tif (remain<5)\n\t\t\tcontinue;\n\n\t\t//good to go\n\t\tgf_m4v_parser_reset(ctx->vparser, sc_type_forced ? forced_sc_type + 1 : 0);\n\t\tsize = 0;\n\t\te = gf_m4v_parse_frame(ctx->vparser, &ctx->dsi, &ftype, &tinc, &size, &fstart, &is_coded);\n\t\t//true if we strip VO and VISOBJ assert(!fstart);\n\n\t\t//we skipped bytes already in store + end of start code present in packet, so the size of the first object\n\t\t//needs adjustement\n\t\tif (bytes_from_store) {\n\t\t\tsize += bytes_from_store + hdr_offset;\n\t\t}\n\n\t\tif ((e == GF_EOS) && !ctx->input_is_au_end) {\n\t\t\tu8 b3 = start[remain-3];\n\t\t\tu8 b2 = start[remain-2];\n\t\t\tu8 b1 = start[remain-1];\n\n\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\tassert(size >= 3);\n\t\t\t\tsize -= 3;\n\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t}\n\t\t\tfull_frame = GF_FALSE;\n\t\t} else {\n\t\t\tfull_frame = GF_TRUE;\n\t\t}\n\n\t\tif (!is_coded) {\n\t\t\t/*if prev is B and we're parsing a packed bitstream discard n-vop*/\n\t\t\tif (ctx->forced_packed && ctx->b_frames) {\n\t\t\t\tctx->is_packed = GF_TRUE;\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to import at variable frame rate, skip*/\n\t\t\tif (ctx->vfr) {\n\t\t\t\tctx->is_vfr = GF_TRUE;\n\t\t\t\tmpgviddmx_update_time(ctx);\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to keep non coded frame (constant frame rate), add*/\n\t\t}\n\n\t\tif (ftype==2) {\n\t\t\t//count number of B-frames since last ref\n\t\t\tctx->b_frames++;\n\t\t\tctx->nb_b++;\n\t\t} else {\n\t\t\t//flush all pending packets\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_FALSE);\n\t\t\t//remeber the CTS of the last ref\n\t\t\tctx->last_ref_cts = ctx->cts;\n\t\t\tif (ctx->max_b < ctx->b_frames) ctx->max_b = ctx->b_frames;\n\t\t\t\n\t\t\tctx->b_frames = 0;\n\t\t\tif (ftype)\n\t\t\t\tctx->nb_p++;\n\t\t\telse\n\t\t\t\tctx->nb_i++;\n\t\t}\n\t\tctx->nb_frames++;\n\n\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t//bytes come from both our store and the data packet\n\t\tif (bytes_from_store) {\n\t\t\tmemcpy(pck_data, ctx->hdr_store+current, bytes_from_store);\n\t\t\tassert(size >= bytes_from_store);\n\t\t\tsize -= bytes_from_store;\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t}\n\t\t\tmemcpy(pck_data + bytes_from_store, start, (size_t) size);\n\t\t} else {\n\t\t\t//bytes only come the data packet\n\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset + start - (u8 *) data);\n\t\t\t}\n\t\t}\n\t\tassert(pck_data[0] == 0);\n\t\tassert(pck_data[1] == 0);\n\t\tassert(pck_data[2] == 0x01);\n\n\t\tgf_filter_pck_set_framing(dst_pck, GF_TRUE, (full_frame || ctx->input_is_au_end) ? GF_TRUE : GF_FALSE);\n\t\tgf_filter_pck_set_cts(dst_pck, ctx->cts);\n\t\tgf_filter_pck_set_dts(dst_pck, ctx->dts);\n\t\tif (ctx->input_is_au_start) {\n\t\t\tctx->input_is_au_start = GF_FALSE;\n\t\t} else {\n\t\t\t//we use the carousel flag temporarly to indicate the cts must be recomputed\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\t\t}\n\t\tgf_filter_pck_set_sap(dst_pck, ftype ? GF_FILTER_SAP_NONE : GF_FILTER_SAP_1);\n\t\tgf_filter_pck_set_duration(dst_pck, ctx->cur_fps.den);\n\t\tif (ctx->in_seek) gf_filter_pck_set_seek_flag(dst_pck, GF_TRUE);\n\t\tctx->frame_started = GF_TRUE;\n\n\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\n\t\tmpgviddmx_update_time(ctx);\n\n\t\tif (!full_frame) {\n\t\t\tif (copy_last_bytes) {\n\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tassert(remain>=size);\n\t\tstart += size;\n\t\tremain -= (s32) size;\n\t}\n\tgf_filter_pid_drop_packet(ctx->ipid);\n\n\treturn GF_OK;\n}",
        "post_patch": "GF_Err mpgviddmx_process(GF_Filter *filter)\n{\n\tGF_MPGVidDmxCtx *ctx = gf_filter_get_udta(filter);\n\tGF_FilterPacket *pck, *dst_pck;\n\tu64 byte_offset;\n\ts64 vosh_start = -1;\n\ts64 vosh_end = -1;\n\tGF_Err e;\n\tchar *data;\n\tu8 *start;\n\tu32 pck_size;\n\ts32 remain;\n\n\t//always reparse duration\n\tif (!ctx->duration.num)\n\t\tmpgviddmx_check_dur(filter, ctx);\n\n\tpck = gf_filter_pid_get_packet(ctx->ipid);\n\tif (!pck) {\n\t\tif (gf_filter_pid_is_eos(ctx->ipid)) {\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_TRUE);\n\t\t\tif (ctx->opid)\n\t\t\t\tgf_filter_pid_set_eos(ctx->opid);\n\t\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\t\tctx->src_pck = NULL;\n\t\t\treturn GF_EOS;\n\t\t}\n\t\treturn GF_OK;\n\t}\n\n\tdata = (char *) gf_filter_pck_get_data(pck, &pck_size);\n\tbyte_offset = gf_filter_pck_get_byte_offset(pck);\n\n\tstart = data;\n\tremain = pck_size;\n\n\t//input pid sets some timescale - we flushed pending data , update cts\n\tif (!ctx->resume_from && ctx->timescale) {\n\t\tu64 ts = gf_filter_pck_get_cts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->cts || !ctx->recompute_cts)\n\t\t\t\tctx->cts = ts;\n\t\t}\n\t\tts = gf_filter_pck_get_dts(pck);\n\t\tif (ts != GF_FILTER_NO_TS) {\n\t\t\tif (!ctx->dts || !ctx->recompute_cts)\n\t\t\t\tctx->dts = ts;\n\n\t\t\tif (!ctx->prev_dts) ctx->prev_dts = ts;\n\t\t\telse if (ctx->prev_dts != ts) {\n\t\t\t\tu64 diff = ts;\n\t\t\t\tdiff -= ctx->prev_dts;\n\t\t\t\tif (!ctx->cur_fps.den) ctx->cur_fps.den = (u32) diff;\n\t\t\t\telse if (ctx->cur_fps.den > diff)\n\t\t\t\t\tctx->cur_fps.den = (u32) diff;\n\t\t\t}\n\t\t}\n\t\tgf_filter_pck_get_framing(pck, &ctx->input_is_au_start, &ctx->input_is_au_end);\n\t\t//this will force CTS recomput of each frame\n\t\tif (ctx->recompute_cts) ctx->input_is_au_start = GF_FALSE;\n\t\tif (ctx->src_pck) gf_filter_pck_unref(ctx->src_pck);\n\t\tctx->src_pck = pck;\n\t\tgf_filter_pck_ref_props(&ctx->src_pck);\n\t}\n\n\t//we stored some data to find the complete vosh, aggregate this packet with current one\n\tif (!ctx->resume_from && ctx->hdr_store_size) {\n\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size) {\n\t\t\tctx->hdr_store_alloc = ctx->hdr_store_size + pck_size;\n\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t}\n\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data, sizeof(char)*pck_size);\n\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\tif (byte_offset >= ctx->hdr_store_size)\n\t\t\t\tbyte_offset -= ctx->hdr_store_size;\n\t\t\telse\n\t\t\t\tbyte_offset = GF_FILTER_NO_BO;\n\t\t}\n\t\tctx->hdr_store_size += pck_size;\n\t\tstart = data = ctx->hdr_store;\n\t\tremain = pck_size = ctx->hdr_store_size;\n\t}\n\n\tif (ctx->resume_from) {\n\t\tif (gf_filter_pid_would_block(ctx->opid))\n\t\t\treturn GF_OK;\n\n\t\t//resume from data copied internally\n\t\tif (ctx->hdr_store_size) {\n\t\t\tassert(ctx->resume_from <= ctx->hdr_store_size);\n\t\t\tstart = data = ctx->hdr_store + ctx->resume_from;\n\t\t\tremain = pck_size = ctx->hdr_store_size - ctx->resume_from;\n\t\t} else {\n\t\t\tassert(remain >= (s32) ctx->resume_from);\n\t\t\tstart += ctx->resume_from;\n\t\t\tremain -= ctx->resume_from;\n\t\t}\n\t\tctx->resume_from = 0;\n\t}\n\n\tif (!ctx->bs) {\n\t\tctx->bs = gf_bs_new(start, remain, GF_BITSTREAM_READ);\n\t} else {\n\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t}\n\tif (!ctx->vparser) {\n\t\tctx->vparser = gf_m4v_parser_bs_new(ctx->bs, ctx->is_mpg12);\n\t}\n\n\n\twhile (remain) {\n\t\tBool full_frame;\n\t\tu8 *pck_data;\n\t\ts32 current;\n\t\tu8 sc_type, forced_sc_type=0;\n\t\tBool sc_type_forced = GF_FALSE;\n\t\tBool skip_pck = GF_FALSE;\n\t\tu8 ftype;\n\t\tu32 tinc;\n\t\tu64 size=0;\n\t\tu64 fstart;\n\t\tBool is_coded;\n\t\tu32 bytes_from_store = 0;\n\t\tu32 hdr_offset = 0;\n\t\tBool copy_last_bytes = GF_FALSE;\n\n\t\t//not enough bytes to parse start code\n\t\tif (remain<5) {\n\t\t\tmemcpy(ctx->hdr_store, start, remain);\n\t\t\tctx->bytes_in_header = remain;\n\t\t\tbreak;\n\t\t}\n\t\tcurrent = -1;\n\n\t\t//we have some potential bytes of a start code in the store, copy some more bytes and check if valid start code.\n\t\t//if not, dispatch these bytes as continuation of the data\n\t\tif (ctx->bytes_in_header) {\n\n\t\t\tmemcpy(ctx->hdr_store + ctx->bytes_in_header, start, 8 - ctx->bytes_in_header);\n\t\t\tcurrent = mpgviddmx_next_start_code(ctx->hdr_store, 8);\n\n\t\t\t//no start code in stored buffer\n\t\t\tif ((current<0) || (current >= (s32) ctx->bytes_in_header) )  {\n\t\t\t\tif (ctx->opid) {\n\t\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, ctx->bytes_in_header, &pck_data);\n\t\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\t\tmemcpy(pck_data, ctx->hdr_store, ctx->bytes_in_header);\n\t\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\n\t\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - ctx->bytes_in_header);\n\t\t\t\t\t}\n\n\t\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\t}\n\n\t\t\t\tif (current<0) current = -1;\n\t\t\t\telse current -= ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t} else {\n\t\t\t\t//we have a valid start code, check which byte in our store or in the packet payload is the start code type\n\t\t\t\t//and remember its location to reinit the parser from there\n\t\t\t\thdr_offset = 4 - ctx->bytes_in_header + current;\n\t\t\t\t//bytes still to dispatch\n\t\t\t\tbytes_from_store = ctx->bytes_in_header;\n\t\t\t\tctx->bytes_in_header = 0;\n\t\t\t\tif (!hdr_offset) {\n\t\t\t\t\tforced_sc_type = ctx->hdr_store[current+3];\n\t\t\t\t} else {\n\t\t\t\t\tforced_sc_type = start[hdr_offset-1];\n\t\t\t\t}\n\t\t\t\tsc_type_forced = GF_TRUE;\n\t\t\t}\n\t\t}\n\t\t//no starcode in store, look for startcode in packet\n\t\tif (current == -1) {\n\t\t\t//locate next start code\n\t\t\tcurrent = mpgviddmx_next_start_code(start, remain);\n\t\t\t//no start code, dispatch the block\n\t\t\tif (current<0) {\n\t\t\t\tu8 b3, b2, b1;\n\t\t\t\tif (! ctx->frame_started) {\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_MEDIA, (\"[MPGVid] no start code in block and no frame started, discarding data\\n\" ));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tsize = remain;\n\t\t\t\tb3 = start[remain-3];\n\t\t\t\tb2 = start[remain-2];\n\t\t\t\tb1 = start[remain-1];\n\t\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\t\tassert(size >= 3);\n\t\t\t\t\tsize -= 3;\n\t\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t\t}\n\n\t\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\n\t\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t\t\tif (copy_last_bytes) {\n\t\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tassert(current>=0);\n\n\t\t//if we are in the middle of parsing the vosh, skip over bytes remaining from previous obj not parsed\n\t\tif ((vosh_start>=0) && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//also skip if no output pid\n\t\tif (!ctx->opid && current) {\n\t\t\tassert(remain>=current);\n\t\t\tstart += current;\n\t\t\tremain -= current;\n\t\t\tcurrent = 0;\n\t\t}\n\t\t//dispatch remaining bytes\n\t\tif (current>0) {\n\t\t\t//flush remaining\n\t\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, current, &pck_data);\n\t\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t\tgf_filter_pck_set_cts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_dts(dst_pck, GF_FILTER_NO_TS);\n\t\t\tgf_filter_pck_set_framing(dst_pck, GF_FALSE, GF_TRUE);\n\t\t\t//bytes were partly in store, partly in packet\n\t\t\tif (bytes_from_store) {\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t\t}\n\t\t\t\tassert(bytes_from_store>=(u32) current);\n\t\t\t\tbytes_from_store -= current;\n\t\t\t\tmemcpy(pck_data, ctx->hdr_store, current);\n\t\t\t} else {\n\t\t\t\t//bytes were only in packet\n\t\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset);\n\t\t\t\t}\n\t\t\t\tmemcpy(pck_data, start, current);\n\t\t\t\tassert(remain>=current);\n\t\t\t\tstart += current;\n\t\t\t\tremain -= current;\n\t\t\t\tcurrent = 0;\n\t\t\t}\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\t\t}\n\n\t\t//not enough bytes to parse start code\n\t\tif (remain<5) {\n\t\t\tmemcpy(ctx->hdr_store, start, remain);\n\t\t\tctx->bytes_in_header = remain;\n\t\t\tbreak;\n\t\t}\n\n\t\t//parse headers\n\t\t//we have a start code loaded, eg the data packet does not have a full start code at the beginning\n\t\tif (sc_type_forced) {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start + hdr_offset, remain - hdr_offset);\n\t\t\tsc_type = forced_sc_type;\n\t\t} else {\n\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\tgf_bs_read_int(ctx->bs, 24);\n\t\t\tsc_type = gf_bs_read_int(ctx->bs, 8);\n\t\t}\n\n\t\tif (ctx->is_mpg12) {\n\t\t\tswitch (sc_type) {\n\t\t\tcase M2V_SEQ_START_CODE:\n\t\t\tcase M2V_EXT_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx, 0, NULL);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M2V_PIC_START_CODE:\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else {\n\t\t\tu8 PL;\n\t\t\tswitch (sc_type) {\n\t\t\tcase M4V_VOS_START_CODE:\n\t\t\t\tctx->dsi.VideoPL = (u8) gf_bs_read_u8(ctx->bs);\n\t\t\t\tvosh_start = start - (u8 *)data;\n\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\tassert(remain>=5);\n\t\t\t\tstart += 5;\n\t\t\t\tremain -= 5;\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOL_START_CODE:\n\t\t\t\tgf_bs_reassign_buffer(ctx->bs, start, remain);\n\t\t\t\tPL = ctx->dsi.VideoPL;\n\t\t\t\te = gf_m4v_parse_config(ctx->vparser, &ctx->dsi);\n\t\t\t\tctx->dsi.VideoPL = PL;\n\t\t\t\t//not enough data, accumulate until we can parse the full header\n\t\t\t\tif (e==GF_EOS) {\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tif (data == ctx->hdr_store) {\n\t\t\t\t\t\tmemmove(ctx->hdr_store, start, remain);\n\t\t\t\t\t\tctx->hdr_store_size = remain;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif (ctx->hdr_store_alloc < ctx->hdr_store_size + pck_size - vosh_start) {\n\t\t\t\t\t\t\tctx->hdr_store_alloc = (u32) (ctx->hdr_store_size + pck_size - (u32) vosh_start);\n\t\t\t\t\t\t\tctx->hdr_store = gf_realloc(ctx->hdr_store, sizeof(char)*ctx->hdr_store_alloc);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tmemcpy(ctx->hdr_store + ctx->hdr_store_size, data + vosh_start, (size_t) (pck_size - vosh_start) );\n\t\t\t\t\t\tctx->hdr_store_size += pck_size - (u32) vosh_start;\n\t\t\t\t\t}\n\t\t\t\t\tgf_filter_pid_drop_packet(ctx->ipid);\n\t\t\t\t\treturn GF_OK;\n\t\t\t\t} else if (e != GF_OK) {\n\t\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_MEDIA, (\"[MPGVid] Failed to parse VOS header: %s\\n\", gf_error_to_string(e) ));\n\t\t\t\t} else {\n\t\t\t\t\tu32 obj_size = (u32) gf_m4v_get_object_start(ctx->vparser);\n\t\t\t\t\tif (vosh_start<0) vosh_start = 0;\n\t\t\t\t\tvosh_end = start - (u8 *)data + obj_size;\n\t\t\t\t\tvosh_end -= vosh_start;\n\t\t\t\t\tmpgviddmx_check_pid(filter, ctx,(u32)  vosh_end, data+vosh_start);\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=(s32) obj_size);\n\t\t\t\t\tstart += obj_size;\n\t\t\t\t\tremain -= obj_size;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase M4V_VOP_START_CODE:\n\t\t\tcase M4V_GOV_START_CODE:\n\t\t\t\tbreak;\n\n\t\t\tcase M4V_VO_START_CODE:\n\t\t\tcase M4V_VISOBJ_START_CODE:\n\t\t\tdefault:\n\t\t\t\tif (vosh_start>=0) {\n\t\t\t\t\tskip_pck = GF_TRUE;\n\t\t\t\t\tassert(remain>=4);\n\t\t\t\t\tstart += 4;\n\t\t\t\t\tremain -= 4;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (skip_pck) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->opid) {\n\t\t\tassert(remain>=4);\n\t\t\tstart += 4;\n\t\t\tremain -= 4;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!ctx->is_playing) {\n\t\t\tctx->resume_from = (u32) ((char *)start -  (char *)data);\n\t\t\treturn GF_OK;\n\t\t}\n\t\t//at this point, we no longer reaggregate packets\n\t\tctx->hdr_store_size = 0;\n\n\t\tif (ctx->in_seek) {\n\t\t\tu64 nb_frames_at_seek = (u64) (ctx->start_range * ctx->cur_fps.num);\n\t\t\tif (ctx->cts + ctx->cur_fps.den >= nb_frames_at_seek) {\n\t\t\t\t//u32 samples_to_discard = (ctx->cts + ctx->dts_inc) - nb_samples_at_seek;\n\t\t\t\tctx->in_seek = GF_FALSE;\n\t\t\t}\n\t\t}\n\t\t//may happen that after all our checks, only 4 bytes are left, continue to store these 4 bytes\n\t\tif (remain<5)\n\t\t\tcontinue;\n\n\t\t//good to go\n\t\tgf_m4v_parser_reset(ctx->vparser, sc_type_forced ? forced_sc_type + 1 : 0);\n\t\tsize = 0;\n\t\te = gf_m4v_parse_frame(ctx->vparser, &ctx->dsi, &ftype, &tinc, &size, &fstart, &is_coded);\n\t\t//true if we strip VO and VISOBJ assert(!fstart);\n\n\t\t//we skipped bytes already in store + end of start code present in packet, so the size of the first object\n\t\t//needs adjustement\n\t\tif (bytes_from_store) {\n\t\t\tsize += bytes_from_store + hdr_offset;\n\t\t}\n\n\t\tif ((e == GF_EOS) && !ctx->input_is_au_end) {\n\t\t\tu8 b3 = start[remain-3];\n\t\t\tu8 b2 = start[remain-2];\n\t\t\tu8 b1 = start[remain-1];\n\n\t\t\t//we may have a startcode at the end of the packet, store it and don't dispatch the last 3 bytes !\n\t\t\tif (!b1 || !b2 || !b3) {\n\t\t\t\tcopy_last_bytes = GF_TRUE;\n\t\t\t\tassert(size >= 3);\n\t\t\t\tsize -= 3;\n\t\t\t\tctx->bytes_in_header = 3;\n\t\t\t}\n\t\t\tfull_frame = GF_FALSE;\n\t\t} else {\n\t\t\tfull_frame = GF_TRUE;\n\t\t}\n\n\t\tif (!is_coded) {\n\t\t\t/*if prev is B and we're parsing a packed bitstream discard n-vop*/\n\t\t\tif (ctx->forced_packed && ctx->b_frames) {\n\t\t\t\tctx->is_packed = GF_TRUE;\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to import at variable frame rate, skip*/\n\t\t\tif (ctx->vfr) {\n\t\t\t\tctx->is_vfr = GF_TRUE;\n\t\t\t\tmpgviddmx_update_time(ctx);\n\t\t\t\tassert(remain>=size);\n\t\t\t\tstart += size;\n\t\t\t\tremain -= (s32) size;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/*policy is to keep non coded frame (constant frame rate), add*/\n\t\t}\n\n\t\tif (ftype==2) {\n\t\t\t//count number of B-frames since last ref\n\t\t\tctx->b_frames++;\n\t\t\tctx->nb_b++;\n\t\t} else {\n\t\t\t//flush all pending packets\n\t\t\tmpgviddmx_enqueue_or_dispatch(ctx, NULL, GF_TRUE, GF_FALSE);\n\t\t\t//remeber the CTS of the last ref\n\t\t\tctx->last_ref_cts = ctx->cts;\n\t\t\tif (ctx->max_b < ctx->b_frames) ctx->max_b = ctx->b_frames;\n\t\t\t\n\t\t\tctx->b_frames = 0;\n\t\t\tif (ftype)\n\t\t\t\tctx->nb_p++;\n\t\t\telse\n\t\t\t\tctx->nb_i++;\n\t\t}\n\t\tctx->nb_frames++;\n\n\t\tdst_pck = gf_filter_pck_new_alloc(ctx->opid, (u32) size, &pck_data);\n\t\tif (!dst_pck) return GF_OUT_OF_MEM;\n\n\t\tif (ctx->src_pck) gf_filter_pck_merge_properties(ctx->src_pck, dst_pck);\n\t\t//bytes come from both our store and the data packet\n\t\tif (bytes_from_store) {\n\t\t\tmemcpy(pck_data, ctx->hdr_store+current, bytes_from_store);\n\t\t\tassert(size >= bytes_from_store);\n\t\t\tsize -= bytes_from_store;\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset - bytes_from_store);\n\t\t\t}\n\t\t\tmemcpy(pck_data + bytes_from_store, start, (size_t) size);\n\t\t} else {\n\t\t\t//bytes only come the data packet\n\t\t\tmemcpy(pck_data, start, (size_t) size);\n\t\t\tif (byte_offset != GF_FILTER_NO_BO) {\n\t\t\t\tgf_filter_pck_set_byte_offset(dst_pck, byte_offset + start - (u8 *) data);\n\t\t\t}\n\t\t}\n\t\tassert(pck_data[0] == 0);\n\t\tassert(pck_data[1] == 0);\n\t\tassert(pck_data[2] == 0x01);\n\n\t\tgf_filter_pck_set_framing(dst_pck, GF_TRUE, (full_frame || ctx->input_is_au_end) ? GF_TRUE : GF_FALSE);\n\t\tgf_filter_pck_set_cts(dst_pck, ctx->cts);\n\t\tgf_filter_pck_set_dts(dst_pck, ctx->dts);\n\t\tif (ctx->input_is_au_start) {\n\t\t\tctx->input_is_au_start = GF_FALSE;\n\t\t} else {\n\t\t\t//we use the carousel flag temporarly to indicate the cts must be recomputed\n\t\t\tgf_filter_pck_set_carousel_version(dst_pck, 1);\n\t\t}\n\t\tgf_filter_pck_set_sap(dst_pck, ftype ? GF_FILTER_SAP_NONE : GF_FILTER_SAP_1);\n\t\tgf_filter_pck_set_duration(dst_pck, ctx->cur_fps.den);\n\t\tif (ctx->in_seek) gf_filter_pck_set_seek_flag(dst_pck, GF_TRUE);\n\t\tctx->frame_started = GF_TRUE;\n\n\t\tmpgviddmx_enqueue_or_dispatch(ctx, dst_pck, GF_FALSE, GF_FALSE);\n\n\t\tmpgviddmx_update_time(ctx);\n\n\t\tif (!full_frame) {\n\t\t\tif (copy_last_bytes) {\n\t\t\t\tmemcpy(ctx->hdr_store, start+remain-3, 3);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tassert(remain>=size);\n\t\tstart += size;\n\t\tremain -= (s32) size;\n\t}\n\tgf_filter_pid_drop_packet(ctx->ipid);\n\n\treturn GF_OK;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "static s32 svc_parse_slice(GF_BitStream *bs, AVCState *avc, AVCSliceInfo *si)\n{\n\ts32 pps_id;\n\n\t/*s->current_picture.reference= h->nal_ref_idc != 0;*/\n\tgf_bs_read_ue_log(bs, \"first_mb_in_slice\");\n\tsi->slice_type = gf_bs_read_ue_log(bs, \"slice_type\");\n\tif (si->slice_type > 9) return -1;\n\n\tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n\tif (pps_id > 255)\n\t\treturn -1;\n\tsi->pps = &avc->pps[pps_id];\n\tsi->pps->id = pps_id;\n\tif (!si->pps->slice_group_count)\n\t\treturn -2;\n\tsi->sps = &avc->sps[si->pps->sps_id + GF_SVC_SSPS_ID_SHIFT];\n\tif (!si->sps->log2_max_frame_num)\n\t\treturn -2;\n\n\tsi->frame_num = gf_bs_read_int_log(bs, si->sps->log2_max_frame_num, \"frame_num\");\n\n\tsi->field_pic_flag = 0;\n\tif (si->sps->frame_mbs_only_flag) {\n\t\t/*s->picture_structure= PICT_FRAME;*/\n\t}\n\telse {\n\t\tsi->field_pic_flag = gf_bs_read_int_log(bs, 1, \"field_pic_flag\");\n\t\tif (si->field_pic_flag) si->bottom_field_flag = gf_bs_read_int_log(bs, 1, \"bottom_field_flag\");\n\t}\n\tif (si->nal_unit_type == GF_AVC_NALU_IDR_SLICE || si->NalHeader.idr_pic_flag)\n\t\tsi->idr_pic_id = gf_bs_read_ue_log(bs, \"idr_pic_id\");\n\n\tif (si->sps->poc_type == 0) {\n\t\tsi->poc_lsb = gf_bs_read_int_log(bs, si->sps->log2_max_poc_lsb, \"poc_lsb\");\n\t\tif (si->pps->pic_order_present && !si->field_pic_flag) {\n\t\t\tsi->delta_poc_bottom = gf_bs_read_se_log(bs, \"delta_poc_bottom\");\n\t\t}\n\t}\n\telse if ((si->sps->poc_type == 1) && !si->sps->delta_pic_order_always_zero_flag) {\n\t\tsi->delta_poc[0] = gf_bs_read_se_log(bs, \"delta_poc0\");\n\t\tif ((si->pps->pic_order_present == 1) && !si->field_pic_flag)\n\t\t\tsi->delta_poc[1] = gf_bs_read_se_log(bs, \"delta_poc1\");\n\t}\n\tif (si->pps->redundant_pic_cnt_present) {\n\t\tsi->redundant_pic_cnt = gf_bs_read_ue_log(bs, \"redundant_pic_cnt\");\n\t}\n\treturn 0;\n}",
        "post_patch": "static s32 svc_parse_slice(GF_BitStream *bs, AVCState *avc, AVCSliceInfo *si)\n{\n\ts32 pps_id;\n\n\t/*s->current_picture.reference= h->nal_ref_idc != 0;*/\n\tgf_bs_read_ue_log(bs, \"first_mb_in_slice\");\n\tsi->slice_type = gf_bs_read_ue_log(bs, \"slice_type\");\n\tif (si->slice_type > 9) return -1;\n\n\tpps_id = gf_bs_read_ue_log(bs, \"pps_id\");\n\tif ((pps_id<0) || (pps_id > 255))\n\t\treturn -1;\n\tsi->pps = &avc->pps[pps_id];\n\tsi->pps->id = pps_id;\n\tif (!si->pps->slice_group_count)\n\t\treturn -2;\n\tsi->sps = &avc->sps[si->pps->sps_id + GF_SVC_SSPS_ID_SHIFT];\n\tif (!si->sps->log2_max_frame_num)\n\t\treturn -2;\n\n\tsi->frame_num = gf_bs_read_int_log(bs, si->sps->log2_max_frame_num, \"frame_num\");\n\n\tsi->field_pic_flag = 0;\n\tif (si->sps->frame_mbs_only_flag) {\n\t\t/*s->picture_structure= PICT_FRAME;*/\n\t}\n\telse {\n\t\tsi->field_pic_flag = gf_bs_read_int_log(bs, 1, \"field_pic_flag\");\n\t\tif (si->field_pic_flag) si->bottom_field_flag = gf_bs_read_int_log(bs, 1, \"bottom_field_flag\");\n\t}\n\tif (si->nal_unit_type == GF_AVC_NALU_IDR_SLICE || si->NalHeader.idr_pic_flag)\n\t\tsi->idr_pic_id = gf_bs_read_ue_log(bs, \"idr_pic_id\");\n\n\tif (si->sps->poc_type == 0) {\n\t\tsi->poc_lsb = gf_bs_read_int_log(bs, si->sps->log2_max_poc_lsb, \"poc_lsb\");\n\t\tif (si->pps->pic_order_present && !si->field_pic_flag) {\n\t\t\tsi->delta_poc_bottom = gf_bs_read_se_log(bs, \"delta_poc_bottom\");\n\t\t}\n\t}\n\telse if ((si->sps->poc_type == 1) && !si->sps->delta_pic_order_always_zero_flag) {\n\t\tsi->delta_poc[0] = gf_bs_read_se_log(bs, \"delta_poc0\");\n\t\tif ((si->pps->pic_order_present == 1) && !si->field_pic_flag)\n\t\t\tsi->delta_poc[1] = gf_bs_read_se_log(bs, \"delta_poc1\");\n\t}\n\tif (si->pps->redundant_pic_cnt_present) {\n\t\tsi->redundant_pic_cnt = gf_bs_read_ue_log(bs, \"redundant_pic_cnt\");\n\t}\n\treturn 0;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      png::CommonFreeDecode(&decode);\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    Status status;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      status = context->allocate_output(\n          0, TensorShape({1, height, width, decode.channels}), &output);\n    } else {\n      status = context->allocate_output(\n          0, TensorShape({height, width, decode.channels}), &output);\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (!status.ok()) png::CommonFreeDecode(&decode);\n    OP_REQUIRES_OK(context, status);\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "post_patch": "  void DecodePngV2(OpKernelContext* context, StringPiece input) {\n    int channel_bits = (data_type_ == DataType::DT_UINT8) ? 8 : 16;\n    png::DecodeContext decode;\n    OP_REQUIRES(\n        context, png::CommonInitDecode(input, channels_, channel_bits, &decode),\n        errors::InvalidArgument(\"Invalid PNG. Failed to initialize decoder.\"));\n\n    // Verify that width and height are not too large:\n    // - verify width and height don't overflow int.\n    // - width can later be multiplied by channels_ and sizeof(uint16), so\n    //   verify single dimension is not too large.\n    // - verify when width and height are multiplied together, there are a few\n    //   bits to spare as well.\n    const int width = static_cast<int>(decode.width);\n    const int height = static_cast<int>(decode.height);\n    const int64_t total_size =\n        static_cast<int64_t>(width) * static_cast<int64_t>(height);\n    if (width != static_cast<int64_t>(decode.width) || width <= 0 ||\n        width >= (1LL << 27) || height != static_cast<int64_t>(decode.height) ||\n        height <= 0 || height >= (1LL << 27) || total_size >= (1LL << 29)) {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\"PNG size too large for int: \",\n                                          decode.width, \" by \", decode.height));\n    }\n\n    Tensor* output = nullptr;\n    Status status;\n    // By the existing API, we support decoding PNG with `DecodeGif` op.\n    // We need to make sure to return 4-D shapes when using `DecodeGif`.\n    if (op_type_ == \"DecodeGif\") {\n      status = context->allocate_output(\n          0, TensorShape({1, height, width, decode.channels}), &output);\n    } else {\n      status = context->allocate_output(\n          0, TensorShape({height, width, decode.channels}), &output);\n    }\n\n    if (op_type_ == \"DecodeBmp\") {\n      // TODO(b/171060723): Only DecodeBmp as op_type_ is not acceptable here\n      // because currently `decode_(jpeg|png|gif)` ops can decode any one of\n      // jpeg, png or gif but not bmp. Similarly, `decode_bmp` cannot decode\n      // anything but bmp formats. This behavior needs to be revisited. For more\n      // details, please refer to the bug.\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"Trying to decode PNG format using DecodeBmp op. Use \"\n                      \"`decode_png` or `decode_image` instead.\"));\n    } else if (op_type_ == \"DecodeAndCropJpeg\") {\n      OP_REQUIRES(context, false,\n                  errors::InvalidArgument(\n                      \"DecodeAndCropJpeg operation can run on JPEG only, but \"\n                      \"detected PNG.\"));\n    }\n\n    if (!status.ok()) png::CommonFreeDecode(&decode);\n    OP_REQUIRES_OK(context, status);\n\n    if (data_type_ == DataType::DT_UINT8) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n              decode.channels * width * sizeof(uint8), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_UINT16) {\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(\n              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n              decode.channels * width * sizeof(uint16), &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n    } else if (data_type_ == DataType::DT_FLOAT) {\n      // `png::CommonFinishDecode` does not support `float`. First allocate\n      // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n      // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n      std::unique_ptr<uint16[]> buffer(\n          new uint16[height * width * decode.channels]);\n      OP_REQUIRES(\n          context,\n          png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n                                  decode.channels * width * sizeof(uint16),\n                                  &decode),\n          errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n\n      // Convert uint16 image data to desired data type.\n      // Use eigen threadpooling to speed up the copy operation.\n      const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n                                                  decode.channels);\n      float scale = 1. / std::numeric_limits<uint16>::max();\n      // Fill output tensor with desired dtype.\n      output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n    }\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "GF_AV1Config *gf_odf_av1_cfg_read_bs_size(GF_BitStream *bs, u32 size)\n{\n#ifndef GPAC_DISABLE_AV_PARSERS\n\tAV1State state;\n\tu8 reserved;\n\tGF_AV1Config *cfg;\n\n\tif (!size) size = (u32) gf_bs_available(bs);\n\tif (!size) return NULL;\n\n\tcfg = gf_odf_av1_cfg_new();\n\tgf_av1_init_state(&state);\n\tstate.config = cfg;\n\n\tcfg->marker = gf_bs_read_int(bs, 1);\n\tcfg->version = gf_bs_read_int(bs, 7);\n\tcfg->seq_profile = gf_bs_read_int(bs, 3);\n\tcfg->seq_level_idx_0 = gf_bs_read_int(bs, 5);\n\tcfg->seq_tier_0 = gf_bs_read_int(bs, 1);\n\tcfg->high_bitdepth = gf_bs_read_int(bs, 1);\n\tcfg->twelve_bit = gf_bs_read_int(bs, 1);\n\tcfg->monochrome = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_x = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_y = gf_bs_read_int(bs, 1);\n\tcfg->chroma_sample_position = gf_bs_read_int(bs, 2);\n\n\treserved = gf_bs_read_int(bs, 3);\n\tif (reserved != 0 || cfg->marker != 1 || cfg->version != 1) {\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] wrong avcC reserved %d / marker %d / version %d expecting 0 1 1\\n\", reserved, cfg->marker, cfg->version));\n\t\tgf_odf_av1_cfg_del(cfg);\n\t\treturn NULL;\n\t}\n\tcfg->initial_presentation_delay_present = gf_bs_read_int(bs, 1);\n\tif (cfg->initial_presentation_delay_present) {\n\t\tcfg->initial_presentation_delay_minus_one = gf_bs_read_int(bs, 4);\n\t} else {\n\t\t/*reserved = */gf_bs_read_int(bs, 4);\n\t\tcfg->initial_presentation_delay_minus_one = 0;\n\t}\n\tsize -= 4;\n\n\twhile (size) {\n\t\tu64 pos, obu_size;\n\t\tObuType obu_type;\n\t\tGF_AV1_OBUArrayEntry *a;\n\n\t\tpos = gf_bs_get_position(bs);\n\t\tobu_size = 0;\n\t\tif (gf_av1_parse_obu(bs, &obu_type, &obu_size, NULL, &state) != GF_OK) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AV1] could not parse AV1 OBU at position \"LLU\". Leaving parsing.\\n\", pos));\n\t\t\tbreak;\n\t\t}\n\t\tassert(obu_size == gf_bs_get_position(bs) - pos);\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] parsed AV1 OBU type=%u size=\"LLU\" at position \"LLU\".\\n\", obu_type, obu_size, pos));\n\n\t\tif (!av1_is_obu_header(obu_type)) {\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] AV1 unexpected OBU type=%u size=\"LLU\" found at position \"LLU\". Forwarding.\\n\", pos));\n\t\t}\n\t\tGF_SAFEALLOC(a, GF_AV1_OBUArrayEntry);\n\t\tif (!a) break;\n\t\ta->obu = gf_malloc((size_t)obu_size);\n\t\tif (!a->obu) {\n\t\t\tgf_free(a);\n\t\t\tbreak;\n\t\t}\n\t\tgf_bs_seek(bs, pos);\n\t\tgf_bs_read_data(bs, (char *) a->obu, (u32)obu_size);\n\t\ta->obu_length = obu_size;\n\t\ta->obu_type = obu_type;\n\t\tgf_list_add(cfg->obu_array, a);\n\n\t\tif (size<obu_size) {\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[AV1] AV1 config misses %d bytes to fit the entire OBU\\n\", obu_size - size));\n\t\t\tbreak;\n\t\t}\n\t\tsize -= (u32) obu_size;\n\t}\n\tgf_av1_reset_state(& state, GF_TRUE);\n\treturn cfg;\n#else\n\treturn NULL;\n#endif\n}",
        "post_patch": "GF_AV1Config *gf_odf_av1_cfg_read_bs_size(GF_BitStream *bs, u32 size)\n{\n#ifndef GPAC_DISABLE_AV_PARSERS\n\tAV1State state;\n\tu8 reserved;\n\tGF_AV1Config *cfg;\n\n\tif (!size) size = (u32) gf_bs_available(bs);\n\tif (!size) return NULL;\n\n\tcfg = gf_odf_av1_cfg_new();\n\tgf_av1_init_state(&state);\n\tstate.config = cfg;\n\n\tcfg->marker = gf_bs_read_int(bs, 1);\n\tcfg->version = gf_bs_read_int(bs, 7);\n\tcfg->seq_profile = gf_bs_read_int(bs, 3);\n\tcfg->seq_level_idx_0 = gf_bs_read_int(bs, 5);\n\tcfg->seq_tier_0 = gf_bs_read_int(bs, 1);\n\tcfg->high_bitdepth = gf_bs_read_int(bs, 1);\n\tcfg->twelve_bit = gf_bs_read_int(bs, 1);\n\tcfg->monochrome = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_x = gf_bs_read_int(bs, 1);\n\tcfg->chroma_subsampling_y = gf_bs_read_int(bs, 1);\n\tcfg->chroma_sample_position = gf_bs_read_int(bs, 2);\n\n\treserved = gf_bs_read_int(bs, 3);\n\tif (reserved != 0 || cfg->marker != 1 || cfg->version != 1) {\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] wrong avcC reserved %d / marker %d / version %d expecting 0 1 1\\n\", reserved, cfg->marker, cfg->version));\n\t\tgf_odf_av1_cfg_del(cfg);\n\t\treturn NULL;\n\t}\n\tcfg->initial_presentation_delay_present = gf_bs_read_int(bs, 1);\n\tif (cfg->initial_presentation_delay_present) {\n\t\tcfg->initial_presentation_delay_minus_one = gf_bs_read_int(bs, 4);\n\t} else {\n\t\t/*reserved = */gf_bs_read_int(bs, 4);\n\t\tcfg->initial_presentation_delay_minus_one = 0;\n\t}\n\tsize -= 4;\n\n\twhile (size) {\n\t\tu64 pos, obu_size;\n\t\tObuType obu_type;\n\t\tGF_AV1_OBUArrayEntry *a;\n\n\t\tpos = gf_bs_get_position(bs);\n\t\tobu_size = 0;\n\t\tif (gf_av1_parse_obu(bs, &obu_type, &obu_size, NULL, &state) != GF_OK) {\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[AV1] could not parse AV1 OBU at position \"LLU\". Leaving parsing.\\n\", pos));\n\t\t\tbreak;\n\t\t}\n\t\tassert(obu_size == gf_bs_get_position(bs) - pos);\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] parsed AV1 OBU type=%u size=\"LLU\" at position \"LLU\".\\n\", obu_type, obu_size, pos));\n\n\t\tif (!av1_is_obu_header(obu_type)) {\n\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[AV1] AV1 unexpected OBU type=%u size=\"LLU\" found at position \"LLU\". Forwarding.\\n\", pos));\n\t\t}\n\t\tGF_SAFEALLOC(a, GF_AV1_OBUArrayEntry);\n\t\tif (!a) break;\n\t\ta->obu = gf_malloc((size_t)obu_size);\n\t\tif (!a->obu) {\n\t\t\tgf_free(a);\n\t\t\tbreak;\n\t\t}\n\t\tgf_bs_seek(bs, pos);\n\t\tgf_bs_read_data(bs, (char *) a->obu, (u32)obu_size);\n\t\ta->obu_length = obu_size;\n\t\ta->obu_type = obu_type;\n\t\tgf_list_add(cfg->obu_array, a);\n\n\t\tif (size<obu_size) {\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[AV1] AV1 config misses %d bytes to fit the entire OBU\\n\", obu_size - size));\n\t\t\tbreak;\n\t\t}\n\t\tsize -= (u32) obu_size;\n\t}\n\tgf_av1_reset_state(& state, GF_TRUE);\n\tgf_bs_align(bs);\n\treturn cfg;\n#else\n\treturn NULL;\n#endif\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "void recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h, *g;\n\tunsigned int i;\n\n\tvmcb_mark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->vmcb01.ptr->control;\n\tg = &svm->nested.ctl;\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] = h->intercepts[i];\n\n\tif (g->int_ctl & V_INTR_MASKING_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_READ);\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tvmcb_clr_intercept(c, INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tvmcb_clr_intercept(c, INTERCEPT_VMMCALL);\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] |= g->intercepts[i];\n\n\t/* If SMI is not intercepted, ignore guest SMI intercept as well  */\n\tif (!intercept_smi)\n\t\tvmcb_clr_intercept(c, INTERCEPT_SMI);\n}",
        "post_patch": "void recalc_intercepts(struct vcpu_svm *svm)\n{\n\tstruct vmcb_control_area *c, *h, *g;\n\tunsigned int i;\n\n\tvmcb_mark_dirty(svm->vmcb, VMCB_INTERCEPTS);\n\n\tif (!is_guest_mode(&svm->vcpu))\n\t\treturn;\n\n\tc = &svm->vmcb->control;\n\th = &svm->vmcb01.ptr->control;\n\tg = &svm->nested.ctl;\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] = h->intercepts[i];\n\n\tif (g->int_ctl & V_INTR_MASKING_MASK) {\n\t\t/* We only want the cr8 intercept bits of L1 */\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_READ);\n\t\tvmcb_clr_intercept(c, INTERCEPT_CR8_WRITE);\n\n\t\t/*\n\t\t * Once running L2 with HF_VINTR_MASK, EFLAGS.IF does not\n\t\t * affect any interrupt we may want to inject; therefore,\n\t\t * interrupt window vmexits are irrelevant to L0.\n\t\t */\n\t\tvmcb_clr_intercept(c, INTERCEPT_VINTR);\n\t}\n\n\t/* We don't want to see VMMCALLs from a nested guest */\n\tvmcb_clr_intercept(c, INTERCEPT_VMMCALL);\n\n\tfor (i = 0; i < MAX_INTERCEPT; i++)\n\t\tc->intercepts[i] |= g->intercepts[i];\n\n\t/* If SMI is not intercepted, ignore guest SMI intercept as well  */\n\tif (!intercept_smi)\n\t\tvmcb_clr_intercept(c, INTERCEPT_SMI);\n\n\tvmcb_set_intercept(c, INTERCEPT_VMLOAD);\n\tvmcb_set_intercept(c, INTERCEPT_VMSAVE);\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}",
        "post_patch": "bool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  } else {\n    // Handle the case of empty tensors (N = 0) or tensors with incomplete shape\n    // (N = -1). All other values of `shape.num_elements()` should be invalid by\n    // construction.\n    // Here, we just need to validate that the `proto.dtype()` value is valid.\n    bool dtype_error = false;\n    CASES_WITH_DEFAULT(proto.dtype(), break, dtype_error = true,\n                       dtype_error = true);\n    if (dtype_error) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis,\n                                        ValueRange shapes, Location loc,\n                                        OpBuilder* builder) {\n  // First find the input shape with the largest rank.\n  SmallVector<ArrayRef<ShapeComponentAnalysis::SymbolicExpr>> shapes_found;\n  size_t maxRank = 0;\n  for (const auto &shape : llvm::enumerate(shapes)) {\n    auto found_shape = analysis.GetValueInfo(shape.value());\n    if (!found_shape) return {};\n    shapes_found.push_back(*found_shape);\n    maxRank = std::max(maxRank, found_shape->size());\n  }\n\n  SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions(\n      maxRank);\n  SmallVector<std::pair<Value, int64_t>> shape_and_rank_for_dim(maxRank);\n  for (const auto &shape : llvm::enumerate(shapes_found)) {\n    for (const auto &dim : llvm::enumerate(llvm::reverse(shape.value()))) {\n      // 1 dimensions don't contribute to the final result.\n      if (dim.value().isConstant(1)) continue;\n      // If it's not a 1 dimension it will be present in the result. Remember\n      // where it came from.\n      auto index = maxRank - dim.index() - 1;\n      if (!joined_dimensions[index]) {\n        joined_dimensions[index] = &dim.value();\n        shape_and_rank_for_dim[index] =\n            std::make_pair(shapes[shape.index()], shape.value().size());\n        continue;\n      }\n      // Bail if the dimensions are neither equal nor 1.\n      if (*joined_dimensions[index] != dim.value()) return {};\n    }\n  }\n  // If the output is the same as one of the inputs just return that.\n  if (llvm::is_splat(shape_and_rank_for_dim) &&\n      shape_and_rank_for_dim[0].first) {\n    return shape_and_rank_for_dim[0].first;\n  }\n  // Otherwise rematerialize the shape from the pieces we have.\n  SmallVector<Value> elements;\n  for (int i = 0; i != maxRank; ++i) {\n    // 1 dimensions are filtered above, recreate the constant.\n    if (!shape_and_rank_for_dim[i].first) {\n      auto one = builder->getIntegerAttr(\n          shapes[0].getType().cast<RankedTensorType>().getElementType(), 1);\n      elements.push_back(builder->create<ConstantOp>(loc, one));\n      continue;\n    }\n    // Extract from one of the shapes, accounting for the reverse indexing\n    // performed by broadcast.\n    Value index = builder->create<ConstantIndexOp>(\n        loc, i - maxRank + shape_and_rank_for_dim[i].second);\n    elements.push_back(builder->create<tensor::ExtractOp>(\n        loc, shape_and_rank_for_dim[i].first, index));\n  }\n  return Value(builder->create<tensor::FromElementsOp>(loc, elements));\n}",
        "post_patch": "llvm::Optional<Value> simplifyBroadcast(ShapeComponentAnalysis& analysis,\n                                        ValueRange shapes, Location loc,\n                                        OpBuilder* builder) {\n  // First find the input shape with the largest rank.\n  SmallVector<ArrayRef<ShapeComponentAnalysis::SymbolicExpr>> shapes_found;\n  size_t maxRank = 0;\n  for (const auto &shape : llvm::enumerate(shapes)) {\n    auto found_shape = analysis.GetValueInfo(shape.value());\n    if (!found_shape) return {};\n    shapes_found.push_back(*found_shape);\n    maxRank = std::max(maxRank, found_shape->size());\n  }\n  if (maxRank == 0) {\n    return Value(builder->create<tensor::FromElementsOp>(\n        loc, shapes[0].getType(), SmallVector<Value>()));\n  }\n\n  SmallVector<const ShapeComponentAnalysis::SymbolicExpr*> joined_dimensions(\n      maxRank);\n  SmallVector<std::pair<Value, int64_t>> shape_and_rank_for_dim(maxRank);\n  for (const auto &shape : llvm::enumerate(shapes_found)) {\n    for (const auto &dim : llvm::enumerate(llvm::reverse(shape.value()))) {\n      // 1 dimensions don't contribute to the final result.\n      if (dim.value().isConstant(1)) continue;\n      // If it's not a 1 dimension it will be present in the result. Remember\n      // where it came from.\n      auto index = maxRank - dim.index() - 1;\n      if (!joined_dimensions[index]) {\n        joined_dimensions[index] = &dim.value();\n        shape_and_rank_for_dim[index] =\n            std::make_pair(shapes[shape.index()], shape.value().size());\n        continue;\n      }\n      // Bail if the dimensions are neither equal nor 1.\n      if (*joined_dimensions[index] != dim.value()) return {};\n    }\n  }\n  // If the output is the same as one of the inputs just return that.\n  if (llvm::is_splat(shape_and_rank_for_dim) &&\n      shape_and_rank_for_dim[0].first) {\n    return shape_and_rank_for_dim[0].first;\n  }\n  // Otherwise rematerialize the shape from the pieces we have.\n  SmallVector<Value> elements;\n  for (int i = 0; i != maxRank; ++i) {\n    // 1 dimensions are filtered above, recreate the constant.\n    if (!shape_and_rank_for_dim[i].first) {\n      auto one = builder->getIntegerAttr(\n          shapes[0].getType().cast<RankedTensorType>().getElementType(), 1);\n      elements.push_back(builder->create<ConstantOp>(loc, one));\n      continue;\n    }\n    // Extract from one of the shapes, accounting for the reverse indexing\n    // performed by broadcast.\n    Value index = builder->create<ConstantIndexOp>(\n        loc, i - maxRank + shape_and_rank_for_dim[i].second);\n    elements.push_back(builder->create<tensor::ExtractOp>(\n        loc, shape_and_rank_for_dim[i].first, index));\n  }\n  return Value(builder->create<tensor::FromElementsOp>(loc, elements));\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "Literal *hermes::evalUnaryOperator(\n    UnaryOperatorInst::OpKind kind,\n    IRBuilder &builder,\n    Literal *operand) {\n  switch (kind) {\n    case UnaryOperatorInst::OpKind::MinusKind:\n      // Negate constant integers.\n      switch (operand->getKind()) {\n        case ValueKind::LiteralNumberKind:\n          if (auto *literalNum = llvh::dyn_cast<LiteralNumber>(operand)) {\n            auto V = -literalNum->getValue();\n            return builder.getLiteralNumber(V);\n          }\n          break;\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralNaN();\n        case ValueKind::LiteralBoolKind:\n          if (evalIsTrue(builder, operand)) {\n            return builder.getLiteralNumber(-1);\n          } else { // evalIsFalse(operand)\n            return builder.getLiteralNegativeZero();\n          }\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralNegativeZero();\n        default:\n          break;\n      }\n      break;\n    case UnaryOperatorInst::OpKind::TypeofKind:\n      switch (operand->getKind()) {\n        case ValueKind::GlobalObjectKind:\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralString(\"object\");\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralString(\"undefined\");\n        case ValueKind::LiteralBoolKind:\n          return builder.getLiteralString(\"boolean\");\n        case ValueKind::LiteralNumberKind:\n          return builder.getLiteralString(\"number\");\n        case ValueKind::LiteralStringKind:\n          return builder.getLiteralString(\"string\");\n        default:\n          llvm_unreachable(\"Invalid literal kind.\");\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::BangKind:\n      if (evalIsTrue(builder, operand)) {\n        return builder.getLiteralBool(false);\n      }\n      if (evalIsFalse(builder, operand)) {\n        return builder.getLiteralBool(true);\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::VoidKind:\n      return builder.getLiteralUndefined();\n\n    default:\n      break;\n  }\n\n  return nullptr;\n}",
        "post_patch": "Literal *hermes::evalUnaryOperator(\n    UnaryOperatorInst::OpKind kind,\n    IRBuilder &builder,\n    Literal *operand) {\n  switch (kind) {\n    case UnaryOperatorInst::OpKind::MinusKind:\n      // Negate constant integers.\n      switch (operand->getKind()) {\n        case ValueKind::LiteralNumberKind:\n          if (auto *literalNum = llvh::dyn_cast<LiteralNumber>(operand)) {\n            auto V = -literalNum->getValue();\n            return builder.getLiteralNumber(V);\n          }\n          break;\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralNaN();\n        case ValueKind::LiteralBoolKind:\n          if (evalIsTrue(builder, operand)) {\n            return builder.getLiteralNumber(-1);\n          } else { // evalIsFalse(operand)\n            return builder.getLiteralNegativeZero();\n          }\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralNegativeZero();\n        default:\n          break;\n      }\n      break;\n    case UnaryOperatorInst::OpKind::TypeofKind:\n      switch (operand->getKind()) {\n        case ValueKind::GlobalObjectKind:\n        case ValueKind::LiteralNullKind:\n          return builder.getLiteralString(\"object\");\n        case ValueKind::LiteralUndefinedKind:\n          return builder.getLiteralString(\"undefined\");\n        case ValueKind::LiteralBoolKind:\n          return builder.getLiteralString(\"boolean\");\n        case ValueKind::LiteralNumberKind:\n          return builder.getLiteralString(\"number\");\n        case ValueKind::LiteralStringKind:\n          return builder.getLiteralString(\"string\");\n        default:\n          break;\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::BangKind:\n      if (evalIsTrue(builder, operand)) {\n        return builder.getLiteralBool(false);\n      }\n      if (evalIsFalse(builder, operand)) {\n        return builder.getLiteralBool(true);\n      }\n      break;\n\n    case UnaryOperatorInst::OpKind::VoidKind:\n      return builder.getLiteralUndefined();\n\n    default:\n      break;\n  }\n\n  return nullptr;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "int Socket::startSslClient(const std::string &certificate_path, String hostname)\n{\n    if (isssl) {\n        stopSsl();\n    }\n\n    ERR_clear_error();\n#if OPENSSL_VERSION_NUMBER < 0x10100000L\n    ctx = SSL_CTX_new(SSLv23_client_method());\n#else\n    ctx = SSL_CTX_new(TLS_client_method());\n#endif\n\n    if (ctx == NULL) {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"Error ssl context is null (check that openssl has been inited)\" << std::endl;\n#endif\n        log_ssl_errors(\"Error ssl context is null for %s\", hostname.c_str());\n        return -1;\n    }\n\n    //set the timeout for the ssl session\n    if (SSL_CTX_set_timeout(ctx, 130l) < 1) {\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -1;\n    }\n\n    //load certs\n    ERR_clear_error();\n    if (certificate_path.length()) {\n        if (!SSL_CTX_load_verify_locations(ctx, NULL, certificate_path.c_str())) {\n#ifdef NETDEBUG\n            std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load certificates from %s\", certificate_path.c_str());\n            //tidy up\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n            return -2;\n        }\n    } else if (!SSL_CTX_set_default_verify_paths(ctx)) //use default if no certPpath given\n    {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load default certificates for %s\", hostname.c_str());\n        //tidy up\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -2;\n    }\n\n    // add validation params\n    ERR_clear_error();\n    X509_VERIFY_PARAM *x509_param = X509_VERIFY_PARAM_new();\n    if (!x509_param) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        //X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!X509_VERIFY_PARAM_set_flags(x509_param, X509_V_FLAG_TRUSTED_FIRST)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!SSL_CTX_set1_param(ctx, x509_param)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    X509_VERIFY_PARAM_free(x509_param);     // try not freeing this as SSL_CTX_free seems to be ring to free it\n\n    //hand socket over to ssl lib\n    ERR_clear_error();\n    ssl = SSL_new(ctx);\n    SSL_set_options(ssl, SSL_OP_ALL);\n    SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);\n    SSL_set_connect_state(ssl);\n\n    //fcntl(this->getFD() ,F_SETFL, O_NONBLOCK); // blocking mode used currently\n    SSL_set_fd(ssl, this->getFD());\n    SSL_set_tlsext_host_name(ssl, hostname.c_str());\n\n    //make io non blocking as select wont tell us if we can do a read without blocking\n    //BIO_set_nbio(SSL_get_rbio(ssl),1l);  // blocking mode used currently\n    //BIO_set_nbio(SSL_get_wbio(ssl),1l); // blocking mode used currently\n    ERR_clear_error();\n    int rc = SSL_connect(ssl);\n    if (rc < 0) {\n        log_ssl_errors(\"ssl_connect failed to %s\", hostname.c_str());\n#ifdef NETDEBUG\n        std::cout << thread_id << \"ssl_connect failed with error \" << SSL_get_error(ssl, rc) << std::endl;\n#endif\n        // tidy up\n        SSL_free(ssl);\n        ssl = NULL;\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -3;\n    }\n\n    //should be safer to do this last as nothing will ever try to use a ssl socket that isnt fully setup\n    isssl = true;\n    issslserver = false;\n    return 0;\n}",
        "post_patch": "int Socket::startSslClient(const std::string &certificate_path, String hostname)\n{\n    if (isssl) {\n        stopSsl();\n    }\n\n    ERR_clear_error();\n#if OPENSSL_VERSION_NUMBER < 0x10100000L\n    ctx = SSL_CTX_new(SSLv23_client_method());\n#else\n    ctx = SSL_CTX_new(TLS_client_method());\n#endif\n\n    if (ctx == NULL) {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"Error ssl context is null (check that openssl has been inited)\" << std::endl;\n#endif\n        log_ssl_errors(\"Error ssl context is null for %s\", hostname.c_str());\n        return -1;\n    }\n\n    //set the timeout for the ssl session\n    if (SSL_CTX_set_timeout(ctx, 130l) < 1) {\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -1;\n    }\n\n    //load certs\n    ERR_clear_error();\n    if (certificate_path.length()) {\n        if (!SSL_CTX_load_verify_locations(ctx, NULL, certificate_path.c_str())) {\n#ifdef NETDEBUG\n            std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load certificates from %s\", certificate_path.c_str());\n            //tidy up\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n            return -2;\n        }\n    } else if (!SSL_CTX_set_default_verify_paths(ctx)) //use default if no certPpath given\n    {\n#ifdef NETDEBUG\n        std::cout << thread_id << \"couldnt load certificates\" << std::endl;\n#endif\n            log_ssl_errors(\"couldnt load default certificates for %s\", hostname.c_str());\n        //tidy up\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -2;\n    }\n\n    // add validation params\n    ERR_clear_error();\n    X509_VERIFY_PARAM *x509_param = X509_VERIFY_PARAM_new();\n    if (!x509_param) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        //X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!X509_VERIFY_PARAM_set_flags(x509_param, X509_V_FLAG_TRUSTED_FIRST)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    ERR_clear_error();\n    if (!SSL_CTX_set1_param(ctx, x509_param)) {\n        log_ssl_errors(\"couldnt add validation params for %s\", hostname.c_str());\n        X509_VERIFY_PARAM_free(x509_param);\n            SSL_CTX_free(ctx);\n            ctx = NULL;\n        return -2;\n    }\n\n    X509_VERIFY_PARAM_free(x509_param);     // try not freeing this as SSL_CTX_free seems to be ring to free it\n\n    //hand socket over to ssl lib\n    ERR_clear_error();\n    ssl = SSL_new(ctx);\n    SSL_set_options(ssl, SSL_OP_ALL);\n    SSL_set_mode(ssl, SSL_MODE_AUTO_RETRY);\n    SSL_set_connect_state(ssl);\n\n    //fcntl(this->getFD() ,F_SETFL, O_NONBLOCK); // blocking mode used currently\n    SSL_set_fd(ssl, this->getFD());\n    SSL_set_tlsext_host_name(ssl, hostname.c_str());\n#if OPENSSL_VERSION_NUMBER < 0x10100000L\n#else\n  X509_VERIFY_PARAM_set1_host(SSL_get0_param(ssl),hostname.c_str(),0);\n#endif\n\n    //make io non blocking as select wont tell us if we can do a read without blocking\n    //BIO_set_nbio(SSL_get_rbio(ssl),1l);  // blocking mode used currently\n    //BIO_set_nbio(SSL_get_wbio(ssl),1l); // blocking mode used currently\n    ERR_clear_error();\n    int rc = SSL_connect(ssl);\n    if (rc < 0) {\n        log_ssl_errors(\"ssl_connect failed to %s\", hostname.c_str());\n#ifdef NETDEBUG\n        std::cout << thread_id << \"ssl_connect failed with error \" << SSL_get_error(ssl, rc) << std::endl;\n#endif\n        // tidy up\n        SSL_free(ssl);\n        ssl = NULL;\n        SSL_CTX_free(ctx);\n        ctx = NULL;\n        return -3;\n    }\n\n    //should be safer to do this last as nothing will ever try to use a ssl socket that isnt fully setup\n    isssl = true;\n    issslserver = false;\n    return 0;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "int main(int argc, char **argv, char **envp)\n{\n\tint opt;\n\n\twhile ((opt = getopt(argc, argv, \"b:h:k:p:q:w:z:xv\")) != -1) {\n\t\tswitch (opt) {\n\t\tcase 'b':\n\t\t\ttmate_settings->bind_addr = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\ttmate_settings->tmate_host = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'k':\n\t\t\ttmate_settings->keys_dir = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'p':\n\t\t\ttmate_settings->ssh_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'q':\n\t\t\ttmate_settings->ssh_port_advertized = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'w':\n\t\t\ttmate_settings->websocket_hostname = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'z':\n\t\t\ttmate_settings->websocket_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'x':\n\t\t\ttmate_settings->use_proxy_protocol = true;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\ttmate_settings->log_level++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage();\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tinit_logging(tmate_settings->log_level);\n\n\tsetup_locale();\n\n\tif (!tmate_settings->tmate_host)\n\t\ttmate_settings->tmate_host = get_full_hostname();\n\n\tcmdline = *argv;\n\tcmdline_end = *envp;\n\n\ttmate_preload_trace_lib();\n\ttmate_catch_sigsegv();\n\ttmate_init_rand();\n\n\tif ((mkdir(TMATE_WORKDIR, 0701)             < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0703) < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/jail\", 0700)     < 0 && errno != EEXIST))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\t/* The websocket server needs to access the /session dir to rename sockets */\n\tif ((chmod(TMATE_WORKDIR, 0701)             < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/sessions\", 0703) < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/jail\", 0700)     < 0))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\ttmate_ssh_server_main(tmate_session,\n\t\t\t      tmate_settings->keys_dir, tmate_settings->bind_addr, tmate_settings->ssh_port);\n\treturn 0;\n}",
        "post_patch": "int main(int argc, char **argv, char **envp)\n{\n\tint opt;\n\n\twhile ((opt = getopt(argc, argv, \"b:h:k:p:q:w:z:xv\")) != -1) {\n\t\tswitch (opt) {\n\t\tcase 'b':\n\t\t\ttmate_settings->bind_addr = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\ttmate_settings->tmate_host = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'k':\n\t\t\ttmate_settings->keys_dir = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'p':\n\t\t\ttmate_settings->ssh_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'q':\n\t\t\ttmate_settings->ssh_port_advertized = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'w':\n\t\t\ttmate_settings->websocket_hostname = xstrdup(optarg);\n\t\t\tbreak;\n\t\tcase 'z':\n\t\t\ttmate_settings->websocket_port = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'x':\n\t\t\ttmate_settings->use_proxy_protocol = true;\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\ttmate_settings->log_level++;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusage();\n\t\t\treturn 1;\n\t\t}\n\t}\n\n\tinit_logging(tmate_settings->log_level);\n\n\tsetup_locale();\n\n\tif (!tmate_settings->tmate_host)\n\t\ttmate_settings->tmate_host = get_full_hostname();\n\n\tcmdline = *argv;\n\tcmdline_end = *envp;\n\n\ttmate_preload_trace_lib();\n\ttmate_catch_sigsegv();\n\ttmate_init_rand();\n\n\tif ((mkdir(TMATE_WORKDIR, 0700)             < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/sessions\", 0700) < 0 && errno != EEXIST) ||\n\t    (mkdir(TMATE_WORKDIR \"/jail\", 0700)     < 0 && errno != EEXIST))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\tif ((chmod(TMATE_WORKDIR, 0700)             < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/sessions\", 0700) < 0) ||\n\t    (chmod(TMATE_WORKDIR \"/jail\", 0700)     < 0))\n\t\ttmate_fatal(\"Cannot prepare session in \" TMATE_WORKDIR);\n\n\tif (check_owned_directory_mode(TMATE_WORKDIR, 0700) ||\n\t    check_owned_directory_mode(TMATE_WORKDIR \"/sessions\", 0700) ||\n\t    check_owned_directory_mode(TMATE_WORKDIR \"/jail\", 0700))\n\t\ttmate_fatal(TMATE_WORKDIR \" and subdirectories has incorrect ownership/mode. \"\n\t\t\t    \"Try deleting \" TMATE_WORKDIR \" and try again\");\n\n\ttmate_ssh_server_main(tmate_session,\n\t\t\t      tmate_settings->keys_dir, tmate_settings->bind_addr, tmate_settings->ssh_port);\n\treturn 0;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "void pjmedia_rtcp_xr_rx_rtcp_xr( pjmedia_rtcp_xr_session *sess,\n\t\t\t\t const void *pkt,\n\t\t\t\t pj_size_t size)\n{\n    const pjmedia_rtcp_xr_pkt\t      *rtcp_xr = (pjmedia_rtcp_xr_pkt*) pkt;\n    const pjmedia_rtcp_xr_rb_rr_time  *rb_rr_time = NULL;\n    const pjmedia_rtcp_xr_rb_dlrr     *rb_dlrr = NULL;\n    const pjmedia_rtcp_xr_rb_stats    *rb_stats = NULL;\n    const pjmedia_rtcp_xr_rb_voip_mtc *rb_voip_mtc = NULL;\n    const pjmedia_rtcp_xr_rb_header   *rb_hdr = (pjmedia_rtcp_xr_rb_header*) \n\t\t\t\t\t\trtcp_xr->buf;\n    unsigned pkt_len, rb_len;\n\n    if (rtcp_xr->common.pt != RTCP_XR)\n\treturn;\n\n    pkt_len = pj_ntohs((pj_uint16_t)rtcp_xr->common.length);\n\n    if ((pkt_len + 1) > (size / 4))\n\treturn;\n\n    /* Parse report rpt_types */\n    while ((pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len)\n    {\t\n\trb_len = pj_ntohs((pj_uint16_t)rb_hdr->length);\n\n\t/* Just skip any block with length == 0 (no report content) */\n\tif (rb_len) {\n\t    switch (rb_hdr->bt) {\n\t\tcase BT_RR_TIME:\n\t\t    rb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*) rb_hdr;\n\t\t    break;\n\t\tcase BT_DLRR:\n\t\t    rb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*) rb_hdr;\n\t\t    break;\n\t\tcase BT_STATS:\n\t\t    rb_stats = (pjmedia_rtcp_xr_rb_stats*) rb_hdr;\n\t\t    break;\n\t\tcase BT_VOIP_METRICS:\n\t\t    rb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*) rb_hdr;\n\t\t    break;\n\t\tdefault:\n\t\t    break;\n\t    }\n\t}\n\trb_hdr = (pjmedia_rtcp_xr_rb_header*)\n\t\t ((pj_int32_t*)rb_hdr + rb_len + 1);\n    }\n\n    /* Receiving RR Time */\n    if (rb_rr_time) {\n\t/* Save LRR from NTP timestamp of the RR time block report */\n\tsess->rx_lrr = ((pj_ntohl(rb_rr_time->ntp_sec) & 0x0000FFFF) << 16) | \n\t\t       ((pj_ntohl(rb_rr_time->ntp_frac) >> 16) & 0xFFFF);\n\n\t/* Calculate RR arrival time for DLRR */\n\tpj_get_timestamp(&sess->rx_lrr_time);\n\n\tTRACE_((sess->name, \"Rx RTCP SR: ntp_ts=%p\", sess->rx_lrr,\n\t       (pj_uint32_t)(sess->rx_lrr_time.u64*65536/\n\t\t\t     sess->rtcp_session->ts_freq.u64)));\n    }\n\n    /* Receiving DLRR */\n    if (rb_dlrr) {\n\tpj_uint32_t lrr, now, dlrr;\n\tpj_uint64_t eedelay;\n\tpjmedia_rtcp_ntp_rec ntp;\n\n\t/* LRR is the middle 32bit of NTP. It has 1/65536 second \n\t * resolution \n\t */\n\tlrr = pj_ntohl(rb_dlrr->item.lrr);\n\n\t/* DLRR is delay since LRR, also in 1/65536 resolution */\n\tdlrr = pj_ntohl(rb_dlrr->item.dlrr);\n\n\t/* Get current time, and convert to 1/65536 resolution */\n\tpjmedia_rtcp_get_ntp_time(sess->rtcp_session, &ntp);\n\tnow = ((ntp.hi & 0xFFFF) << 16) + (ntp.lo >> 16);\n\n\t/* End-to-end delay is (now-lrr-dlrr) */\n\teedelay = now - lrr - dlrr;\n\n\t/* Convert end to end delay to usec (keeping the calculation in\n         * 64bit space)::\n\t *   sess->ee_delay = (eedelay * 1000) / 65536;\n\t */\n\tif (eedelay < 4294) {\n\t    eedelay = (eedelay * 1000000) >> 16;\n\t} else {\n\t    eedelay = (eedelay * 1000) >> 16;\n\t    eedelay *= 1000;\n\t}\n\n\tTRACE_((sess->name, \"Rx RTCP XR DLRR: lrr=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t   \"now=%p, rtt=%p\",\n\t\tlrr, dlrr, dlrr/65536, (dlrr%65536)*1000/65536,\n\t\tnow, (pj_uint32_t)eedelay));\n\t\n\t/* Only save calculation if \"now\" is greater than lrr, or\n\t * otherwise rtt will be invalid \n\t */\n\tif (now-dlrr >= lrr) {\n\t    unsigned rtt = (pj_uint32_t)eedelay;\n\t    \n\t    /* Check that eedelay value really makes sense. \n\t     * We allow up to 30 seconds RTT!\n\t     */\n\t    if (eedelay <= 30 * 1000 * 1000UL) {\n\t\t/* \"Normalize\" rtt value that is exceptionally high.\n\t\t * For such values, \"normalize\" the rtt to be three times\n\t\t * the average value.\n\t\t */\n\t\tif (rtt>((unsigned)sess->stat.rtt.mean*3) && sess->stat.rtt.n!=0)\n\t\t{\n\t\t    unsigned orig_rtt = rtt;\n\t\t    rtt = (unsigned)sess->stat.rtt.mean*3;\n\t\t    PJ_LOG(5,(sess->name, \n\t\t\t      \"RTT value %d usec is normalized to %d usec\",\n\t\t\t      orig_rtt, rtt));\n\t\t}\n    \t\n\t\tTRACE_((sess->name, \"RTCP RTT is set to %d usec\", rtt));\n\t\tpj_math_stat_update(&sess->stat.rtt, rtt);\n\t    }\n\t} else {\n\t    PJ_LOG(5, (sess->name, \"Internal RTCP NTP clock skew detected: \"\n\t\t\t\t   \"lrr=%p, now=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t\t   \"diff=%d\",\n\t\t\t\t   lrr, now, dlrr, dlrr/65536,\n\t\t\t\t   (dlrr%65536)*1000/65536,\n\t\t\t\t   dlrr-(now-lrr)));\n\t}\n    }\n\n    /* Receiving Statistics Summary */\n    if (rb_stats) {\n\tpj_uint8_t flags = rb_stats->header.specific;\n\n\tpj_bzero(&sess->stat.tx.stat_sum, sizeof(sess->stat.tx.stat_sum));\n\n\t/* Range of packets sequence reported in this blocks */\n\tsess->stat.tx.stat_sum.begin_seq = pj_ntohs(rb_stats->begin_seq);\n\tsess->stat.tx.stat_sum.end_seq   = pj_ntohs(rb_stats->end_seq);\n\n\t/* Get flags of valid fields */\n\tsess->stat.tx.stat_sum.l = (flags & (1 << 7)) != 0;\n\tsess->stat.tx.stat_sum.d = (flags & (1 << 6)) != 0;\n\tsess->stat.tx.stat_sum.j = (flags & (1 << 5)) != 0;\n\tsess->stat.tx.stat_sum.t = (flags & (3 << 3)) != 0;\n\n\t/* Fetch the reports info */\n\tif (sess->stat.tx.stat_sum.l) {\n\t    sess->stat.tx.stat_sum.lost = pj_ntohl(rb_stats->lost);\n\t}\n\n\tif (sess->stat.tx.stat_sum.d) {\n\t    sess->stat.tx.stat_sum.dup = pj_ntohl(rb_stats->dup);\n\t}\n\n\tif (sess->stat.tx.stat_sum.j) {\n\t    sess->stat.tx.stat_sum.jitter.min = pj_ntohl(rb_stats->jitter_min);\n\t    sess->stat.tx.stat_sum.jitter.max = pj_ntohl(rb_stats->jitter_max);\n\t    sess->stat.tx.stat_sum.jitter.mean= pj_ntohl(rb_stats->jitter_mean);\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.jitter, \n\t\t\t\t    pj_ntohl(rb_stats->jitter_dev));\n\t}\n\n\tif (sess->stat.tx.stat_sum.t) {\n\t    sess->stat.tx.stat_sum.toh.min = rb_stats->toh_min;\n\t    sess->stat.tx.stat_sum.toh.max = rb_stats->toh_max;\n\t    sess->stat.tx.stat_sum.toh.mean= rb_stats->toh_mean;\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.toh, \n\t\t\t\t    pj_ntohl(rb_stats->toh_dev));\n\t}\n\n\tpj_gettimeofday(&sess->stat.tx.stat_sum.update);\n    }\n\n    /* Receiving VoIP Metrics */\n    if (rb_voip_mtc) {\n\tsess->stat.tx.voip_mtc.loss_rate = rb_voip_mtc->loss_rate;\n\tsess->stat.tx.voip_mtc.discard_rate = rb_voip_mtc->discard_rate;\n\tsess->stat.tx.voip_mtc.burst_den = rb_voip_mtc->burst_den;\n\tsess->stat.tx.voip_mtc.gap_den = rb_voip_mtc->gap_den;\n\tsess->stat.tx.voip_mtc.burst_dur = pj_ntohs(rb_voip_mtc->burst_dur);\n\tsess->stat.tx.voip_mtc.gap_dur = pj_ntohs(rb_voip_mtc->gap_dur);\n\tsess->stat.tx.voip_mtc.rnd_trip_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->rnd_trip_delay);\n\tsess->stat.tx.voip_mtc.end_sys_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->end_sys_delay);\n\t/* signal & noise level encoded in two's complement form */\n\tsess->stat.tx.voip_mtc.signal_lvl = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->signal_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->signal_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->signal_lvl);\n\tsess->stat.tx.voip_mtc.noise_lvl  = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->noise_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->noise_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->noise_lvl);\n\tsess->stat.tx.voip_mtc.rerl = rb_voip_mtc->rerl;\n\tsess->stat.tx.voip_mtc.gmin = rb_voip_mtc->gmin;\n\tsess->stat.tx.voip_mtc.r_factor = rb_voip_mtc->r_factor;\n\tsess->stat.tx.voip_mtc.ext_r_factor = rb_voip_mtc->ext_r_factor;\n\tsess->stat.tx.voip_mtc.mos_lq = rb_voip_mtc->mos_lq;\n\tsess->stat.tx.voip_mtc.mos_cq = rb_voip_mtc->mos_cq;\n\tsess->stat.tx.voip_mtc.rx_config = rb_voip_mtc->rx_config;\n\tsess->stat.tx.voip_mtc.jb_nom = pj_ntohs(rb_voip_mtc->jb_nom);\n\tsess->stat.tx.voip_mtc.jb_max = pj_ntohs(rb_voip_mtc->jb_max);\n\tsess->stat.tx.voip_mtc.jb_abs_max = pj_ntohs(rb_voip_mtc->jb_abs_max);\n\n\tpj_gettimeofday(&sess->stat.tx.voip_mtc.update);\n    }\n}",
        "post_patch": "void pjmedia_rtcp_xr_rx_rtcp_xr( pjmedia_rtcp_xr_session *sess,\n\t\t\t\t const void *pkt,\n\t\t\t\t pj_size_t size)\n{\n    const pjmedia_rtcp_xr_pkt\t      *rtcp_xr = (pjmedia_rtcp_xr_pkt*) pkt;\n    const pjmedia_rtcp_xr_rb_rr_time  *rb_rr_time = NULL;\n    const pjmedia_rtcp_xr_rb_dlrr     *rb_dlrr = NULL;\n    const pjmedia_rtcp_xr_rb_stats    *rb_stats = NULL;\n    const pjmedia_rtcp_xr_rb_voip_mtc *rb_voip_mtc = NULL;\n    const pjmedia_rtcp_xr_rb_header   *rb_hdr = (pjmedia_rtcp_xr_rb_header*) \n\t\t\t\t\t\trtcp_xr->buf;\n    unsigned pkt_len, rb_len;\n\n    if (rtcp_xr->common.pt != RTCP_XR)\n\treturn;\n\n    pkt_len = pj_ntohs((pj_uint16_t)rtcp_xr->common.length);\n\n    if ((pkt_len + 1) > (size / 4))\n\treturn;\n\n    /* Parse report rpt_types */\n    while ((pj_int32_t*)rb_hdr < (pj_int32_t*)pkt + pkt_len)\n    {\t\n\trb_len = pj_ntohs((pj_uint16_t)rb_hdr->length);\n\n\t/* Just skip any block with length == 0 (no report content) */\n\tif (rb_len) {\n\t    switch (rb_hdr->bt) {\n\t\tcase BT_RR_TIME:\n\t\t    if ((char*)rb_hdr + sizeof(*rb_rr_time) <=\n\t\t\t(char*)pkt + size) \n\t\t    {\n\t\t\trb_rr_time = (pjmedia_rtcp_xr_rb_rr_time*)rb_hdr;\n\t\t    }\n\t\t    break;\n\t\tcase BT_DLRR:\n\t\t    if ((char*)rb_hdr + sizeof(*rb_dlrr) <=\n\t\t\t(char*)pkt + size)\n\t\t    {\n\t\t\trb_dlrr = (pjmedia_rtcp_xr_rb_dlrr*)rb_hdr;\n\t\t    }\n\t\t    break;\n\t\tcase BT_STATS:\n\t\t    if ((char*)rb_hdr + sizeof(*rb_stats) <=\n\t\t\t(char*)pkt + size)\n\t\t    {\n\t\t\trb_stats = (pjmedia_rtcp_xr_rb_stats*)rb_hdr;\n\t\t    }\n\t\t    break;\n\t\tcase BT_VOIP_METRICS:\n\t\t    if ((char*)rb_hdr + sizeof(*rb_voip_mtc) <=\n\t\t\t(char*)pkt + size)\n\t\t    {\n\t\t\trb_voip_mtc = (pjmedia_rtcp_xr_rb_voip_mtc*)rb_hdr;\n\t\t    }\n\t\t    break;\n\t\tdefault:\n\t\t    break;\n\t    }\n\t}\n\trb_hdr = (pjmedia_rtcp_xr_rb_header*)\n\t\t ((pj_int32_t*)rb_hdr + rb_len + 1);\n    }\n\n    /* Receiving RR Time */\n    if (rb_rr_time) {\n\t/* Save LRR from NTP timestamp of the RR time block report */\n\tsess->rx_lrr = ((pj_ntohl(rb_rr_time->ntp_sec) & 0x0000FFFF) << 16) | \n\t\t       ((pj_ntohl(rb_rr_time->ntp_frac) >> 16) & 0xFFFF);\n\n\t/* Calculate RR arrival time for DLRR */\n\tpj_get_timestamp(&sess->rx_lrr_time);\n\n\tTRACE_((sess->name, \"Rx RTCP SR: ntp_ts=%p\", sess->rx_lrr,\n\t       (pj_uint32_t)(sess->rx_lrr_time.u64*65536/\n\t\t\t     sess->rtcp_session->ts_freq.u64)));\n    }\n\n    /* Receiving DLRR */\n    if (rb_dlrr) {\n\tpj_uint32_t lrr, now, dlrr;\n\tpj_uint64_t eedelay;\n\tpjmedia_rtcp_ntp_rec ntp;\n\n\t/* LRR is the middle 32bit of NTP. It has 1/65536 second \n\t * resolution \n\t */\n\tlrr = pj_ntohl(rb_dlrr->item.lrr);\n\n\t/* DLRR is delay since LRR, also in 1/65536 resolution */\n\tdlrr = pj_ntohl(rb_dlrr->item.dlrr);\n\n\t/* Get current time, and convert to 1/65536 resolution */\n\tpjmedia_rtcp_get_ntp_time(sess->rtcp_session, &ntp);\n\tnow = ((ntp.hi & 0xFFFF) << 16) + (ntp.lo >> 16);\n\n\t/* End-to-end delay is (now-lrr-dlrr) */\n\teedelay = now - lrr - dlrr;\n\n\t/* Convert end to end delay to usec (keeping the calculation in\n         * 64bit space)::\n\t *   sess->ee_delay = (eedelay * 1000) / 65536;\n\t */\n\tif (eedelay < 4294) {\n\t    eedelay = (eedelay * 1000000) >> 16;\n\t} else {\n\t    eedelay = (eedelay * 1000) >> 16;\n\t    eedelay *= 1000;\n\t}\n\n\tTRACE_((sess->name, \"Rx RTCP XR DLRR: lrr=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t   \"now=%p, rtt=%p\",\n\t\tlrr, dlrr, dlrr/65536, (dlrr%65536)*1000/65536,\n\t\tnow, (pj_uint32_t)eedelay));\n\t\n\t/* Only save calculation if \"now\" is greater than lrr, or\n\t * otherwise rtt will be invalid \n\t */\n\tif (now-dlrr >= lrr) {\n\t    unsigned rtt = (pj_uint32_t)eedelay;\n\t    \n\t    /* Check that eedelay value really makes sense. \n\t     * We allow up to 30 seconds RTT!\n\t     */\n\t    if (eedelay <= 30 * 1000 * 1000UL) {\n\t\t/* \"Normalize\" rtt value that is exceptionally high.\n\t\t * For such values, \"normalize\" the rtt to be three times\n\t\t * the average value.\n\t\t */\n\t\tif (rtt>((unsigned)sess->stat.rtt.mean*3) && sess->stat.rtt.n!=0)\n\t\t{\n\t\t    unsigned orig_rtt = rtt;\n\t\t    rtt = (unsigned)sess->stat.rtt.mean*3;\n\t\t    PJ_LOG(5,(sess->name, \n\t\t\t      \"RTT value %d usec is normalized to %d usec\",\n\t\t\t      orig_rtt, rtt));\n\t\t}\n    \t\n\t\tTRACE_((sess->name, \"RTCP RTT is set to %d usec\", rtt));\n\t\tpj_math_stat_update(&sess->stat.rtt, rtt);\n\t    }\n\t} else {\n\t    PJ_LOG(5, (sess->name, \"Internal RTCP NTP clock skew detected: \"\n\t\t\t\t   \"lrr=%p, now=%p, dlrr=%p (%d:%03dms), \"\n\t\t\t\t   \"diff=%d\",\n\t\t\t\t   lrr, now, dlrr, dlrr/65536,\n\t\t\t\t   (dlrr%65536)*1000/65536,\n\t\t\t\t   dlrr-(now-lrr)));\n\t}\n    }\n\n    /* Receiving Statistics Summary */\n    if (rb_stats) {\n\tpj_uint8_t flags = rb_stats->header.specific;\n\n\tpj_bzero(&sess->stat.tx.stat_sum, sizeof(sess->stat.tx.stat_sum));\n\n\t/* Range of packets sequence reported in this blocks */\n\tsess->stat.tx.stat_sum.begin_seq = pj_ntohs(rb_stats->begin_seq);\n\tsess->stat.tx.stat_sum.end_seq   = pj_ntohs(rb_stats->end_seq);\n\n\t/* Get flags of valid fields */\n\tsess->stat.tx.stat_sum.l = (flags & (1 << 7)) != 0;\n\tsess->stat.tx.stat_sum.d = (flags & (1 << 6)) != 0;\n\tsess->stat.tx.stat_sum.j = (flags & (1 << 5)) != 0;\n\tsess->stat.tx.stat_sum.t = (flags & (3 << 3)) != 0;\n\n\t/* Fetch the reports info */\n\tif (sess->stat.tx.stat_sum.l) {\n\t    sess->stat.tx.stat_sum.lost = pj_ntohl(rb_stats->lost);\n\t}\n\n\tif (sess->stat.tx.stat_sum.d) {\n\t    sess->stat.tx.stat_sum.dup = pj_ntohl(rb_stats->dup);\n\t}\n\n\tif (sess->stat.tx.stat_sum.j) {\n\t    sess->stat.tx.stat_sum.jitter.min = pj_ntohl(rb_stats->jitter_min);\n\t    sess->stat.tx.stat_sum.jitter.max = pj_ntohl(rb_stats->jitter_max);\n\t    sess->stat.tx.stat_sum.jitter.mean= pj_ntohl(rb_stats->jitter_mean);\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.jitter, \n\t\t\t\t    pj_ntohl(rb_stats->jitter_dev));\n\t}\n\n\tif (sess->stat.tx.stat_sum.t) {\n\t    sess->stat.tx.stat_sum.toh.min = rb_stats->toh_min;\n\t    sess->stat.tx.stat_sum.toh.max = rb_stats->toh_max;\n\t    sess->stat.tx.stat_sum.toh.mean= rb_stats->toh_mean;\n\t    pj_math_stat_set_stddev(&sess->stat.tx.stat_sum.toh, \n\t\t\t\t    pj_ntohl(rb_stats->toh_dev));\n\t}\n\n\tpj_gettimeofday(&sess->stat.tx.stat_sum.update);\n    }\n\n    /* Receiving VoIP Metrics */\n    if (rb_voip_mtc) {\n\tsess->stat.tx.voip_mtc.loss_rate = rb_voip_mtc->loss_rate;\n\tsess->stat.tx.voip_mtc.discard_rate = rb_voip_mtc->discard_rate;\n\tsess->stat.tx.voip_mtc.burst_den = rb_voip_mtc->burst_den;\n\tsess->stat.tx.voip_mtc.gap_den = rb_voip_mtc->gap_den;\n\tsess->stat.tx.voip_mtc.burst_dur = pj_ntohs(rb_voip_mtc->burst_dur);\n\tsess->stat.tx.voip_mtc.gap_dur = pj_ntohs(rb_voip_mtc->gap_dur);\n\tsess->stat.tx.voip_mtc.rnd_trip_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->rnd_trip_delay);\n\tsess->stat.tx.voip_mtc.end_sys_delay = \n\t\t\t\t\tpj_ntohs(rb_voip_mtc->end_sys_delay);\n\t/* signal & noise level encoded in two's complement form */\n\tsess->stat.tx.voip_mtc.signal_lvl = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->signal_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->signal_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->signal_lvl);\n\tsess->stat.tx.voip_mtc.noise_lvl  = (pj_int8_t)\n\t\t\t\t    ((rb_voip_mtc->noise_lvl > 127)?\n\t\t\t\t     ((int)rb_voip_mtc->noise_lvl - 256) : \n\t\t\t\t     rb_voip_mtc->noise_lvl);\n\tsess->stat.tx.voip_mtc.rerl = rb_voip_mtc->rerl;\n\tsess->stat.tx.voip_mtc.gmin = rb_voip_mtc->gmin;\n\tsess->stat.tx.voip_mtc.r_factor = rb_voip_mtc->r_factor;\n\tsess->stat.tx.voip_mtc.ext_r_factor = rb_voip_mtc->ext_r_factor;\n\tsess->stat.tx.voip_mtc.mos_lq = rb_voip_mtc->mos_lq;\n\tsess->stat.tx.voip_mtc.mos_cq = rb_voip_mtc->mos_cq;\n\tsess->stat.tx.voip_mtc.rx_config = rb_voip_mtc->rx_config;\n\tsess->stat.tx.voip_mtc.jb_nom = pj_ntohs(rb_voip_mtc->jb_nom);\n\tsess->stat.tx.voip_mtc.jb_max = pj_ntohs(rb_voip_mtc->jb_max);\n\tsess->stat.tx.voip_mtc.jb_abs_max = pj_ntohs(rb_voip_mtc->jb_abs_max);\n\n\tpj_gettimeofday(&sess->stat.tx.voip_mtc.update);\n    }\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "s32 gf_avc_parse_nalu(GF_BitStream *bs, AVCState *avc)\n{\n\tu8 idr_flag;\n\ts32 slice, ret;\n\tu32 nal_hdr;\n\tAVCSliceInfo n_state;\n\n\tgf_bs_enable_emulation_byte_removal(bs, GF_TRUE);\n\n\tnal_hdr = gf_bs_read_u8(bs);\n\n\tslice = 0;\n\tmemcpy(&n_state, &avc->s_info, sizeof(AVCSliceInfo));\n\tavc->last_nal_type_parsed = n_state.nal_unit_type = nal_hdr & 0x1F;\n\tn_state.nal_ref_idc = (nal_hdr >> 5) & 0x3;\n\n\tidr_flag = 0;\n\n\tswitch (n_state.nal_unit_type) {\n\tcase GF_AVC_NALU_ACCESS_UNIT:\n\tcase GF_AVC_NALU_END_OF_SEQ:\n\tcase GF_AVC_NALU_END_OF_STREAM:\n\t\tret = 1;\n\t\tbreak;\n\n\tcase GF_AVC_NALU_SVC_SLICE:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\t// slice buffer - read the info and compare.\n\t\t/*ret = */svc_parse_slice(bs, avc, &n_state);\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t\tavc_compute_poc(&n_state);\n\n\t\tif (avc->s_info.poc != n_state.poc) {\n\t\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\t\treturn 1;\n\t\t}\n\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SVC_PREFIX_NALU:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_IDR_SLICE:\n\tcase GF_AVC_NALU_NON_IDR_SLICE:\n\tcase GF_AVC_NALU_DP_A_SLICE:\n\tcase GF_AVC_NALU_DP_B_SLICE:\n\tcase GF_AVC_NALU_DP_C_SLICE:\n\t\tslice = 1;\n\t\t/* slice buffer - read the info and compare.*/\n\t\tret = avc_parse_slice(bs, avc, idr_flag, &n_state);\n\t\tif (ret < 0) return ret;\n\t\tret = 0;\n\t\tif (\n\t\t\t((avc->s_info.nal_unit_type > GF_AVC_NALU_IDR_SLICE) || (avc->s_info.nal_unit_type < GF_AVC_NALU_NON_IDR_SLICE))\n\t\t\t&& (avc->s_info.nal_unit_type != GF_AVC_NALU_SVC_SLICE)\n\t\t\t) {\n\t\t\tbreak;\n\t\t}\n\t\tif (avc->s_info.frame_num != n_state.frame_num) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (avc->s_info.field_pic_flag != n_state.field_pic_flag) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif ((avc->s_info.nal_ref_idc != n_state.nal_ref_idc) &&\n\t\t\t(!avc->s_info.nal_ref_idc || !n_state.nal_ref_idc)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tassert(avc->s_info.sps);\n\n\t\tif (avc->s_info.sps->poc_type == n_state.sps->poc_type) {\n\t\t\tif (!avc->s_info.sps->poc_type) {\n\t\t\t\tif (!n_state.bottom_field_flag && (avc->s_info.poc_lsb != n_state.poc_lsb)) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc_bottom != n_state.delta_poc_bottom) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (avc->s_info.sps->poc_type == 1) {\n\t\t\t\tif (avc->s_info.delta_poc[0] != n_state.delta_poc[0]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc[1] != n_state.delta_poc[1]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (n_state.nal_unit_type == GF_AVC_NALU_IDR_SLICE) {\n\t\t\tif (avc->s_info.nal_unit_type != GF_AVC_NALU_IDR_SLICE) { /*IdrPicFlag differs in value*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (avc->s_info.idr_pic_id != n_state.idr_pic_id) { /*both IDR and idr_pic_id differs*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 0, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_PIC_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_pps_bs_internal(bs, avc, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 1, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\tavc->last_ps_idx = (s32) gf_bs_read_ue(bs);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SEI:\n\tcase GF_AVC_NALU_FILLER_DATA:\n\t\treturn 0;\n\n\tdefault:\n\t\tif (avc->s_info.nal_unit_type <= GF_AVC_NALU_IDR_SLICE) ret = 1;\n\t\t//To detect change of AU when multiple sps and pps in stream\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEI && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEQ_PARAM && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t\tbreak;\n\t}\n\n\t/* save _prev values */\n\tif (ret && avc->s_info.sps) {\n\t\tn_state.frame_num_offset_prev = avc->s_info.frame_num_offset;\n\t\tif ((avc->s_info.sps->poc_type != 2) || (avc->s_info.nal_ref_idc != 0))\n\t\t\tn_state.frame_num_prev = avc->s_info.frame_num;\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t}\n\tif (slice)\n\t\tavc_compute_poc(&n_state);\n\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\treturn ret;\n}",
        "post_patch": "s32 gf_avc_parse_nalu(GF_BitStream *bs, AVCState *avc)\n{\n\tu8 idr_flag;\n\ts32 slice, ret;\n\tu32 nal_hdr;\n\tAVCSliceInfo n_state;\n\n\tgf_bs_enable_emulation_byte_removal(bs, GF_TRUE);\n\n\tnal_hdr = gf_bs_read_u8(bs);\n\n\tslice = 0;\n\tmemcpy(&n_state, &avc->s_info, sizeof(AVCSliceInfo));\n\tavc->last_nal_type_parsed = n_state.nal_unit_type = nal_hdr & 0x1F;\n\tn_state.nal_ref_idc = (nal_hdr >> 5) & 0x3;\n\n\tidr_flag = 0;\n\n\tswitch (n_state.nal_unit_type) {\n\tcase GF_AVC_NALU_ACCESS_UNIT:\n\tcase GF_AVC_NALU_END_OF_SEQ:\n\tcase GF_AVC_NALU_END_OF_STREAM:\n\t\tret = 1;\n\t\tbreak;\n\n\tcase GF_AVC_NALU_SVC_SLICE:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\t// slice buffer - read the info and compare.\n\t\t/*ret = */svc_parse_slice(bs, avc, &n_state);\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t\tavc_compute_poc(&n_state);\n\n\t\tif (avc->s_info.poc != n_state.poc) {\n\t\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\t\treturn 1;\n\t\t}\n\t\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SVC_PREFIX_NALU:\n\t\tSVC_ReadNal_header_extension(bs, &n_state.NalHeader);\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_IDR_SLICE:\n\tcase GF_AVC_NALU_NON_IDR_SLICE:\n\tcase GF_AVC_NALU_DP_A_SLICE:\n\tcase GF_AVC_NALU_DP_B_SLICE:\n\tcase GF_AVC_NALU_DP_C_SLICE:\n\t\tslice = 1;\n\t\t/* slice buffer - read the info and compare.*/\n\t\tret = avc_parse_slice(bs, avc, idr_flag, &n_state);\n\t\tif (ret < 0) return ret;\n\t\tret = 0;\n\t\tif (\n\t\t\t((avc->s_info.nal_unit_type > GF_AVC_NALU_IDR_SLICE) || (avc->s_info.nal_unit_type < GF_AVC_NALU_NON_IDR_SLICE))\n\t\t\t&& (avc->s_info.nal_unit_type != GF_AVC_NALU_SVC_SLICE)\n\t\t\t) {\n\t\t\tbreak;\n\t\t}\n\t\tif (avc->s_info.frame_num != n_state.frame_num) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (avc->s_info.field_pic_flag != n_state.field_pic_flag) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif ((avc->s_info.nal_ref_idc != n_state.nal_ref_idc) &&\n\t\t\t(!avc->s_info.nal_ref_idc || !n_state.nal_ref_idc)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (!avc->s_info.sps)\n\t\t\treturn -1;\n\n\t\tif (avc->s_info.sps->poc_type == n_state.sps->poc_type) {\n\t\t\tif (!avc->s_info.sps->poc_type) {\n\t\t\t\tif (!n_state.bottom_field_flag && (avc->s_info.poc_lsb != n_state.poc_lsb)) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc_bottom != n_state.delta_poc_bottom) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (avc->s_info.sps->poc_type == 1) {\n\t\t\t\tif (avc->s_info.delta_poc[0] != n_state.delta_poc[0]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (avc->s_info.delta_poc[1] != n_state.delta_poc[1]) {\n\t\t\t\t\tret = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (n_state.nal_unit_type == GF_AVC_NALU_IDR_SLICE) {\n\t\t\tif (avc->s_info.nal_unit_type != GF_AVC_NALU_IDR_SLICE) { /*IdrPicFlag differs in value*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (avc->s_info.idr_pic_id != n_state.idr_pic_id) { /*both IDR and idr_pic_id differs*/\n\t\t\t\tret = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase GF_AVC_NALU_SEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 0, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_PIC_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_pps_bs_internal(bs, avc, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SVC_SUBSEQ_PARAM:\n\t\tavc->last_ps_idx = gf_avc_read_sps_bs_internal(bs, avc, 1, NULL, nal_hdr);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\tcase GF_AVC_NALU_SEQ_PARAM_EXT:\n\t\tavc->last_ps_idx = (s32) gf_bs_read_ue(bs);\n\t\tif (avc->last_ps_idx < 0) return -1;\n\t\treturn 0;\n\n\tcase GF_AVC_NALU_SEI:\n\tcase GF_AVC_NALU_FILLER_DATA:\n\t\treturn 0;\n\n\tdefault:\n\t\tif (avc->s_info.nal_unit_type <= GF_AVC_NALU_IDR_SLICE) ret = 1;\n\t\t//To detect change of AU when multiple sps and pps in stream\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEI && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse if ((nal_hdr & 0x1F) == GF_AVC_NALU_SEQ_PARAM && avc->s_info.nal_unit_type == GF_AVC_NALU_SVC_SLICE)\n\t\t\tret = 1;\n\t\telse\n\t\t\tret = 0;\n\t\tbreak;\n\t}\n\n\t/* save _prev values */\n\tif (ret && avc->s_info.sps) {\n\t\tn_state.frame_num_offset_prev = avc->s_info.frame_num_offset;\n\t\tif ((avc->s_info.sps->poc_type != 2) || (avc->s_info.nal_ref_idc != 0))\n\t\t\tn_state.frame_num_prev = avc->s_info.frame_num;\n\t\tif (avc->s_info.nal_ref_idc) {\n\t\t\tn_state.poc_lsb_prev = avc->s_info.poc_lsb;\n\t\t\tn_state.poc_msb_prev = avc->s_info.poc_msb;\n\t\t}\n\t}\n\tif (slice)\n\t\tavc_compute_poc(&n_state);\n\tmemcpy(&avc->s_info, &n_state, sizeof(AVCSliceInfo));\n\treturn ret;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  Status SetUnknownShape(const NodeDef* node, int output_port) {\n    shape_inference::ShapeHandle shape =\n        GetUnknownOutputShape(node, output_port);\n    InferenceContext* ctx = GetContext(node);\n    if (ctx == nullptr) {\n      return errors::InvalidArgument(\"Missing context\");\n    }\n    ctx->set_output(output_port, shape);\n    return Status::OK();\n  }",
        "post_patch": "  Status SetUnknownShape(const NodeDef* node, int output_port) {\n    shape_inference::ShapeHandle shape =\n        GetUnknownOutputShape(node, output_port);\n    InferenceContext* ctx = GetContext(node);\n    if (ctx == nullptr) {\n      return errors::InvalidArgument(\"SetUnknownShape: Missing context\");\n    }\n    if (output_port < 0 || output_port >= ctx->num_outputs()) {\n      return errors::InvalidArgument(\n          \"SetUnknownShape: output_port must be in [0, \", ctx->num_outputs(),\n          \") but was \", output_port);\n    }\n    ctx->set_output(output_port, shape);\n    return Status::OK();\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      DCHECK_EQ(arg_index, result_.nodes.size());\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "post_patch": "  Status BuildInputArgIndex(const OpDef::ArgDef& arg_def, AttrSlice attr_values,\n                            const FunctionDef::ArgAttrs* arg_attrs,\n                            bool ints_on_device,\n                            int64_t resource_arg_unique_id) {\n    bool is_type_list;\n    DataTypeVector dtypes;\n    TF_RETURN_IF_ERROR(\n        ArgNumType(attr_values, arg_def, &is_type_list, &dtypes));\n    if (dtypes.size() < size_t{1}) {\n      return errors::Internal(\"Expected a list of at least one dtype\");\n    }\n    int arg_index = result_.nodes.size();\n    TF_RETURN_IF_ERROR(\n        AddItem(arg_def.name(), {true, arg_index, 0, is_type_list, dtypes}));\n    // Creates dtypes.size() nodes in the graph.\n    for (size_t i = 0; i < dtypes.size(); ++i) {\n      TF_RETURN_IF_ERROR(AddItem(strings::StrCat(arg_def.name(), \":\", i),\n                                 {true, arg_index, 0, false, {dtypes[i]}}));\n      if (arg_index != result_.nodes.size()) {\n        return errors::Internal(\n            \"Expected arg_index to be equal to the number of nodes in result.\",\n            \" Got \", arg_index, \" and \", result_.nodes.size());\n      }\n      string name = arg_def.name();\n      if (dtypes.size() > 1) {\n        strings::StrAppend(&name, \"_\", i);\n      }\n      NodeDef* gnode = AddNode(name);\n      if (ints_on_device && dtypes[i] == DataType::DT_INT32) {\n        gnode->set_op(FunctionLibraryDefinition::kDeviceArgOp);\n      } else {\n        gnode->set_op(FunctionLibraryDefinition::kArgOp);\n      }\n      DataType dtype = arg_def.is_ref() ? MakeRefType(dtypes[i]) : dtypes[i];\n      AddAttr(\"T\", dtype, gnode);\n      AddAttr(\"index\", arg_index, gnode);\n      if (resource_arg_unique_id >= 0) {\n        AddAttr(\"_resource_arg_unique_id\", resource_arg_unique_id, gnode);\n      }\n      if (arg_attrs) {\n        for (const auto& arg_attr : arg_attrs->attr()) {\n          AddAttr(arg_attr.first, arg_attr.second, gnode->mutable_attr());\n        }\n      }\n      result_.arg_types.push_back(dtypes[i]);\n      ++arg_index;\n    }\n    return Status::OK();\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MagickPathExtent],\n    *density,\n    filename[MagickPathExtent],\n    geometry[MagickPathExtent],\n    *options,\n    input_filename[MagickPathExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  ssize_t\n    c;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->resolution.x == 0.0) || (image->resolution.y == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->resolution.x=geometry_info.rho;\n      image->resolution.y=image->resolution.x;\n      if ((flags & SigmaValue) != 0)\n        image->resolution.y=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MagickPathExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t) floor(bounds.x2-bounds.x1+0.5);\n    height=(size_t) floor(bounds.y2-bounds.y1+0.5);\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MagickPathExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MagickPathExtent,\"%gx%g\",\n    image->resolution.x,image->resolution.y);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor(page.width*image->resolution.x/delta.x+0.5);\n  page.height=(size_t) floor(page.height*image->resolution.y/delta.y+0.5);\n  (void) FormatLocaleString(options,MagickPathExtent,\"-g%.20gx%.20g \",(double)\n    page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MagickPathExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MagickPathExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MagickPathExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MagickPathExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MagickPathExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->resolution.x/2.0;\n        image->magick_rows*=image->resolution.y/2.0;\n        image->columns*=image->resolution.x/2.0;\n        image->rows*=image->resolution.y/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}",
        "post_patch": "static Image *ReadPCLImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define CropBox  \"CropBox\"\n#define DeviceCMYK  \"DeviceCMYK\"\n#define MediaBox  \"MediaBox\"\n#define RenderPCLText  \"  Rendering PCL...  \"\n\n  char\n    command[MagickPathExtent],\n    *density,\n    filename[MagickPathExtent],\n    geometry[MagickPathExtent],\n    *options,\n    input_filename[MagickPathExtent];\n\n  const DelegateInfo\n    *delegate_info;\n\n  Image\n    *image,\n    *next_image;\n\n  ImageInfo\n    *read_info;\n\n  MagickBooleanType\n    cmyk,\n    status;\n\n  PointInfo\n    delta;\n\n  RectangleInfo\n    bounding_box,\n    page;\n\n  char\n    *p;\n\n  ssize_t\n    c;\n\n  SegmentInfo\n    bounds;\n\n  size_t\n    height,\n    width;\n\n  ssize_t\n    count;\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  /*\n    Open image file.\n  */\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  status=AcquireUniqueSymbolicLink(image_info->filename,input_filename);\n  if (status == MagickFalse)\n    {\n      ThrowFileException(exception,FileOpenError,\"UnableToCreateTemporaryFile\",\n        image_info->filename);\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Set the page density.\n  */\n  delta.x=DefaultResolution;\n  delta.y=DefaultResolution;\n  if ((image->resolution.x == 0.0) || (image->resolution.y == 0.0))\n    {\n      GeometryInfo\n        geometry_info;\n\n      MagickStatusType\n        flags;\n\n      flags=ParseGeometry(PSDensityGeometry,&geometry_info);\n      if ((flags & RhoValue) != 0)\n        image->resolution.x=geometry_info.rho;\n      image->resolution.y=image->resolution.x;\n      if ((flags & SigmaValue) != 0)\n        image->resolution.y=geometry_info.sigma;\n    }\n  /*\n    Determine page geometry from the PCL media box.\n  */\n  cmyk=image->colorspace == CMYKColorspace ? MagickTrue : MagickFalse;\n  count=0;\n  (void) memset(&bounding_box,0,sizeof(bounding_box));\n  (void) memset(&bounds,0,sizeof(bounds));\n  (void) memset(&page,0,sizeof(page));\n  (void) memset(command,0,sizeof(command));\n  p=command;\n  for (c=ReadBlobByte(image); c != EOF; c=ReadBlobByte(image))\n  {\n    if (image_info->page != (char *) NULL)\n      continue;\n    /*\n      Note PCL elements.\n    */\n    *p++=(char) c;\n    if ((c != (int) '/') && (c != '\\n') &&\n        ((size_t) (p-command) < (MagickPathExtent-1)))\n      continue;\n    *p='\\0';\n    p=command;\n    /*\n      Is this a CMYK document?\n    */\n    if (LocaleNCompare(DeviceCMYK,command,strlen(DeviceCMYK)) == 0)\n      cmyk=MagickTrue;\n    if (LocaleNCompare(CropBox,command,strlen(CropBox)) == 0)\n      {\n        /*\n          Note region defined by crop box.\n        */\n        count=(ssize_t) sscanf(command,\"CropBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"CropBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (LocaleNCompare(MediaBox,command,strlen(MediaBox)) == 0)\n      {\n        /*\n          Note region defined by media box.\n        */\n        count=(ssize_t) sscanf(command,\"MediaBox [%lf %lf %lf %lf\",\n          &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n        if (count != 4)\n          count=(ssize_t) sscanf(command,\"MediaBox[%lf %lf %lf %lf\",\n            &bounds.x1,&bounds.y1,&bounds.x2,&bounds.y2);\n      }\n    if (count != 4)\n      continue;\n    /*\n      Set PCL render geometry.\n    */\n    width=(size_t)CastDoubleToLong(floor(bounds.x2-bounds.x1+0.5));\n    height=(size_t)CastDoubleToLong(floor(bounds.y2-bounds.y1+0.5));\n    if (width > page.width)\n      page.width=width;\n    if (height > page.height)\n      page.height=height;\n  }\n  (void) CloseBlob(image);\n  /*\n    Render PCL with the GhostPCL delegate.\n  */\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  (void) FormatLocaleString(geometry,MagickPathExtent,\"%.20gx%.20g\",(double)\n    page.width,(double) page.height);\n  if (image_info->monochrome != MagickFalse)\n    delegate_info=GetDelegateInfo(\"pcl:mono\",(char *) NULL,exception);\n  else\n     if (cmyk != MagickFalse)\n       delegate_info=GetDelegateInfo(\"pcl:cmyk\",(char *) NULL,exception);\n     else\n       delegate_info=GetDelegateInfo(\"pcl:color\",(char *) NULL,exception);\n  if (delegate_info == (const DelegateInfo *) NULL)\n    {\n      image=DestroyImage(image);\n      return((Image *) NULL);\n    }\n  if ((page.width == 0) || (page.height == 0))\n    (void) ParseAbsoluteGeometry(PSPageGeometry,&page);\n  if (image_info->page != (char *) NULL)\n    (void) ParseAbsoluteGeometry(image_info->page,&page);\n  density=AcquireString(\"\");\n  options=AcquireString(\"\");\n  (void) FormatLocaleString(density,MagickPathExtent,\"%gx%g\",\n    image->resolution.x,image->resolution.y);\n  if (image_info->ping != MagickFalse)\n    (void) FormatLocaleString(density,MagickPathExtent,\"2.0x2.0\");\n  page.width=(size_t) floor(page.width*image->resolution.x/delta.x+0.5);\n  page.height=(size_t) floor(page.height*image->resolution.y/delta.y+0.5);\n  (void) FormatLocaleString(options,MagickPathExtent,\"-g%.20gx%.20g \",(double)\n    page.width,(double) page.height);\n  image=DestroyImage(image);\n  read_info=CloneImageInfo(image_info);\n  *read_info->magick='\\0';\n  if (read_info->number_scenes != 0)\n    {\n      if (read_info->number_scenes != 1)\n        (void) FormatLocaleString(options,MagickPathExtent,\"-dLastPage=%.20g\",\n          (double) (read_info->scene+read_info->number_scenes));\n      else\n        (void) FormatLocaleString(options,MagickPathExtent,\n          \"-dFirstPage=%.20g -dLastPage=%.20g\",(double) read_info->scene+1,\n          (double) (read_info->scene+read_info->number_scenes));\n      read_info->number_scenes=0;\n      if (read_info->scenes != (char *) NULL)\n        *read_info->scenes='\\0';\n    }\n  (void) CopyMagickString(filename,read_info->filename,MagickPathExtent);\n  (void) AcquireUniqueFilename(read_info->filename);\n  (void) FormatLocaleString(command,MagickPathExtent,\n    GetDelegateCommands(delegate_info),\n    read_info->antialias != MagickFalse ? 4 : 1,\n    read_info->antialias != MagickFalse ? 4 : 1,density,options,\n    read_info->filename,input_filename);\n  options=DestroyString(options);\n  density=DestroyString(density);\n  status=ExternalDelegateCommand(MagickFalse,read_info->verbose,command,\n    (char *) NULL,exception) != 0 ? MagickTrue : MagickFalse;\n  image=ReadImage(read_info,exception);\n  (void) RelinquishUniqueFileResource(read_info->filename);\n  (void) RelinquishUniqueFileResource(input_filename);\n  read_info=DestroyImageInfo(read_info);\n  if (image == (Image *) NULL)\n    ThrowReaderException(DelegateError,\"PCLDelegateFailed\");\n  if (LocaleCompare(image->magick,\"BMP\") == 0)\n    {\n      Image\n        *cmyk_image;\n\n      cmyk_image=ConsolidateCMYKImages(image,exception);\n      if (cmyk_image != (Image *) NULL)\n        {\n          image=DestroyImageList(image);\n          image=cmyk_image;\n        }\n    }\n  do\n  {\n    (void) CopyMagickString(image->filename,filename,MagickPathExtent);\n    image->page=page;\n    if (image_info->ping != MagickFalse)\n      {\n        image->magick_columns*=image->resolution.x/2.0;\n        image->magick_rows*=image->resolution.y/2.0;\n        image->columns*=image->resolution.x/2.0;\n        image->rows*=image->resolution.y/2.0;\n      }\n    next_image=SyncNextImageInList(image);\n    if (next_image != (Image *) NULL)\n      image=next_image;\n  } while (next_image != (Image *) NULL);\n  return(GetFirstImageInList(image));\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "static void compile_xclass_matchingpath(compiler_common *common, PCRE2_SPTR cc, jump_list **backtracks)\n{\nDEFINE_COMPILER;\njump_list *found = NULL;\njump_list **list = (cc[0] & XCL_NOT) == 0 ? &found : backtracks;\nsljit_uw c, charoffset, max = 256, min = READ_CHAR_MAX;\nstruct sljit_jump *jump = NULL;\nPCRE2_SPTR ccbegin;\nint compares, invertcmp, numberofcmps;\n#if defined SUPPORT_UNICODE && (PCRE2_CODE_UNIT_WIDTH == 8 || PCRE2_CODE_UNIT_WIDTH == 16)\nBOOL utf = common->utf;\n#endif /* SUPPORT_UNICODE && PCRE2_CODE_UNIT_WIDTH == [8|16] */\n\n#ifdef SUPPORT_UNICODE\nsljit_u32 unicode_status = 0;\nint typereg = TMP1;\nconst sljit_u32 *other_cases;\nsljit_uw typeoffset;\n#endif /* SUPPORT_UNICODE */\n\n/* Scanning the necessary info. */\ncc++;\nccbegin = cc;\ncompares = 0;\n\nif (cc[-1] & XCL_MAP)\n  {\n  min = 0;\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\nwhile (*cc != XCL_END)\n  {\n  compares++;\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n    if (c < min) min = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c < min) min = c;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    cc++;\n    if (*cc == PT_CLIST && *cc == XCL_PROP)\n      {\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n      while (*other_cases != NOTACHAR)\n        {\n        if (*other_cases > max) max = *other_cases;\n        if (*other_cases < min) min = *other_cases;\n        other_cases++;\n        }\n      }\n    else\n      {\n      max = READ_CHAR_MAX;\n      min = 0;\n      }\n\n    switch(*cc)\n      {\n      case PT_ANY:\n      /* Any either accepts everything or ignored. */\n      if (cc[-1] == XCL_PROP)\n        {\n        compile_char1_matchingpath(common, OP_ALLANY, cc, backtracks, FALSE);\n        if (list == backtracks)\n          add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n        return;\n        }\n      break;\n\n      case PT_LAMP:\n      case PT_GC:\n      case PT_PC:\n      case PT_ALNUM:\n      unicode_status |= XCLASS_HAS_TYPE;\n      break;\n\n      case PT_SCX:\n      unicode_status |= XCLASS_HAS_SCRIPT_EXTENSION;\n      if (cc[-1] == XCL_NOTPROP)\n        {\n        unicode_status |= XCLASS_SCRIPT_EXTENSION_NOTPROP;\n        break;\n        }\n      compares++;\n      /* Fall through */ \n\n      case PT_SC:\n      unicode_status |= XCLASS_HAS_SCRIPT;\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      case PT_WORD:\n      case PT_PXGRAPH:\n      case PT_PXPRINT:\n      case PT_PXPUNCT:\n      unicode_status |= XCLASS_SAVE_CHAR | XCLASS_HAS_TYPE;\n      break;\n\n      case PT_CLIST:\n      case PT_UCNC:\n      unicode_status |= XCLASS_SAVE_CHAR;\n      break;\n\n      case PT_BOOL:\n      unicode_status |= XCLASS_HAS_BOOL;\n      break;\n\n      case PT_BIDICL:\n      unicode_status |= XCLASS_HAS_BIDICL;\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n  }\nSLJIT_ASSERT(compares > 0);\n\n/* We are not necessary in utf mode even in 8 bit mode. */\ncc = ccbegin;\nif ((cc[-1] & XCL_NOT) != 0)\n  read_char(common, min, max, backtracks, READ_CHAR_UPDATE_STR_PTR);\nelse\n  {\n#ifdef SUPPORT_UNICODE\n  read_char(common, min, max, (unicode_status & XCLASS_NEEDS_UCD) ? backtracks : NULL, 0);\n#else /* !SUPPORT_UNICODE */\n  read_char(common, min, max, NULL, 0);\n#endif /* SUPPORT_UNICODE */\n  }\n\nif ((cc[-1] & XCL_HASPROP) == 0)\n  {\n  if ((cc[-1] & XCL_MAP) != 0)\n    {\n    jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n    if (!optimize_class(common, (const sljit_u8 *)cc, (((const sljit_u8 *)cc)[31] & 0x80) != 0, TRUE, &found))\n      {\n      OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n      OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n      OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n      OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n      OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n      add_jump(compiler, &found, JUMP(SLJIT_NOT_ZERO));\n      }\n\n    add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n    JUMPHERE(jump);\n\n    cc += 32 / sizeof(PCRE2_UCHAR);\n    }\n  else\n    {\n    OP2(SLJIT_SUB, TMP2, 0, TMP1, 0, SLJIT_IMM, min);\n    add_jump(compiler, (cc[-1] & XCL_NOT) == 0 ? backtracks : &found, CMP(SLJIT_GREATER, TMP2, 0, SLJIT_IMM, max - min));\n    }\n  }\nelse if ((cc[-1] & XCL_MAP) != 0)\n  {\n  OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n#ifdef SUPPORT_UNICODE\n  unicode_status |= XCLASS_CHAR_SAVED;\n#endif /* SUPPORT_UNICODE */\n  if (!optimize_class(common, (const sljit_u8 *)cc, FALSE, TRUE, list))\n    {\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    jump = NULL;\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n\n    OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n    OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n    OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n    add_jump(compiler, list, JUMP(SLJIT_NOT_ZERO));\n\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      JUMPHERE(jump);\n    }\n\n  OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\n#ifdef SUPPORT_UNICODE\nif (unicode_status & XCLASS_NEEDS_UCD)\n  {\n  if ((unicode_status & (XCLASS_SAVE_CHAR | XCLASS_CHAR_SAVED)) == XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n\n#if PCRE2_CODE_UNIT_WIDTH == 32\n  if (!common->utf)\n    {\n    jump = CMP(SLJIT_LESS, TMP1, 0, SLJIT_IMM, MAX_UTF_CODE_POINT + 1);\n    OP1(SLJIT_MOV, TMP1, 0, SLJIT_IMM, UNASSIGNED_UTF_CHAR);\n    JUMPHERE(jump);\n    }\n#endif /* PCRE2_CODE_UNIT_WIDTH == 32 */\n\n  OP2(SLJIT_LSHR, TMP2, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 1);\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_stage1));\n  OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_MASK);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_ADD, TMP1, 0, TMP1, 0, TMP2, 0);\n  OP1(SLJIT_MOV, TMP2, 0, SLJIT_IMM, (sljit_sw)PRIV(ucd_stage2));\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM2(TMP2, TMP1), 1);\n  OP2(SLJIT_SHL, TMP1, 0, TMP2, 0, SLJIT_IMM, 3);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 2);\n  OP2(SLJIT_ADD, TMP2, 0, TMP2, 0, TMP1, 0);\n\n  ccbegin = cc;\n\n  if (unicode_status & XCLASS_HAS_BIDICL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BIDICLASS_SHIFT);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BIDICL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n          jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]);\n          add_jump(compiler, compares > 0 ? list : backtracks, jump);\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_BOOL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, bprops));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BPROPS_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BOOL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_boolprop_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT)\n    {\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        switch (*cc)\n          {\n          case PT_SCX:\n          if (cc[-1] == XCL_NOTPROP)\n            break;\n          /* Fall through */ \n\n          case PT_SC:\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          add_jump(compiler, compares > 0 ? list : backtracks, CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT_EXTENSION)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_SCRIPTX_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_NOTPROP)\n      {\n      if (unicode_status & XCLASS_HAS_TYPE)\n        {\n        if (unicode_status & XCLASS_SAVE_CHAR)\n          {\n          OP1(SLJIT_MOV, SLJIT_MEM1(SLJIT_SP), LOCALS0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0;\n          }\n        else\n          {\n          OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR;\n          }\n        }\n      OP1(SLJIT_MOV_U8, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n      }\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_SCX)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n\n          jump = NULL;\n          if (cc[-1] == XCL_NOTPROP)\n            {\n            jump = CMP(SLJIT_EQUAL, TMP2, 0, SLJIT_IMM, (int)cc[1]);\n            if (invertcmp)\n              {\n              add_jump(compiler, backtracks, jump);\n              jump = NULL;\n              }\n            invertcmp ^= 0x1;\n            }\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_script_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n\n          if (jump != NULL)\n            JUMPHERE(jump);\n          }\n        cc += 2;\n        }\n      }\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0)\n      OP1(SLJIT_MOV, TMP2, 0, SLJIT_MEM1(SLJIT_SP), LOCALS0);\n    else if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR)\n      OP1(SLJIT_MOV, TMP2, 0, RETURN_ADDR, 0);\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n\n  if (unicode_status & XCLASS_HAS_TYPE)\n    {\n    if (unicode_status & XCLASS_SAVE_CHAR)\n      typereg = RETURN_ADDR;\n\n    OP1(SLJIT_MOV_U8, typereg, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, chartype));\n    }\n  }\n#endif /* SUPPORT_UNICODE */\n\n/* Generating code. */\ncharoffset = 0;\nnumberofcmps = 0;\n#ifdef SUPPORT_UNICODE\ntypeoffset = 0;\n#endif /* SUPPORT_UNICODE */\n\nwhile (*cc != XCL_END)\n  {\n  compares--;\n  invertcmp = (compares == 0 && list != backtracks);\n  jump = NULL;\n\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    SET_CHAR_OFFSET(c);\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    if (*cc == XCL_NOTPROP)\n      invertcmp ^= 0x1;\n    cc++;\n    switch(*cc)\n      {\n      case PT_ANY:\n      if (!invertcmp)\n        jump = JUMP(SLJIT_JUMP);\n      break;\n\n      case PT_LAMP:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lu - typeoffset);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Ll - typeoffset);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lt - typeoffset);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_GC:\n      c = PRIV(ucp_typerange)[(int)cc[1] * 2];\n      SET_TYPE_OFFSET(c);\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, PRIV(ucp_typerange)[(int)cc[1] * 2 + 1] - c);\n      break;\n\n      case PT_PC:\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, (int)cc[1] - typeoffset);\n      break;\n\n      case PT_SC:\n      case PT_SCX:\n      case PT_BOOL:\n      case PT_BIDICL:\n      compares++;\n      /* Do nothing. */\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      SET_CHAR_OFFSET(9);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0xd - 0x9);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x85 - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Zl);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Zl);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_WORD:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_UNDERSCORE - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      /* Fall through. */\n\n      case PT_ALNUM:\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Lu - ucp_Ll);\n      OP_FLAGS((*cc == PT_ALNUM) ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_TYPE_OFFSET(ucp_Nd);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_No - ucp_Nd);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_CLIST:\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n\n      /* At least three characters are required.\n         Otherwise this case would be handled by the normal code path. */\n      SLJIT_ASSERT(other_cases[0] != NOTACHAR && other_cases[1] != NOTACHAR && other_cases[2] != NOTACHAR);\n      SLJIT_ASSERT(other_cases[0] < other_cases[1] && other_cases[1] < other_cases[2]);\n\n      /* Optimizing character pairs, if their difference is power of 2. */\n      if (is_powerof2(other_cases[1] ^ other_cases[0]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[1]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        other_cases += 2;\n        }\n      else if (is_powerof2(other_cases[2] ^ other_cases[1]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[2] ^ other_cases[1]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[2]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(other_cases[0] - charoffset));\n        OP_FLAGS(SLJIT_OR | ((other_cases[3] == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n\n        other_cases += 3;\n        }\n      else\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        }\n\n      while (*other_cases != NOTACHAR)\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_OR | ((*other_cases == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n        }\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_UCNC:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_DOLLAR_SIGN - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_COMMERCIAL_AT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_GRAVE_ACCENT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_CHAR_OFFSET(0xa0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(0xd7ff - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER_EQUAL, TMP1, 0, SLJIT_IMM, 0xe000 - 0);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_GREATER_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_PXGRAPH:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPRINT:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Ll);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_NOT_EQUAL);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPUNCT:\n      SET_TYPE_OFFSET(ucp_Sc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_So - ucp_Sc);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x7f);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Pc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Ps - ucp_Pc);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n\n  if (jump != NULL)\n    add_jump(compiler, compares > 0 ? list : backtracks, jump);\n  }\n\nif (found != NULL)\n  set_jumps(found, LABEL());\n}",
        "post_patch": "static void compile_xclass_matchingpath(compiler_common *common, PCRE2_SPTR cc, jump_list **backtracks)\n{\nDEFINE_COMPILER;\njump_list *found = NULL;\njump_list **list = (cc[0] & XCL_NOT) == 0 ? &found : backtracks;\nsljit_uw c, charoffset, max = 256, min = READ_CHAR_MAX;\nstruct sljit_jump *jump = NULL;\nPCRE2_SPTR ccbegin;\nint compares, invertcmp, numberofcmps;\n#if defined SUPPORT_UNICODE && (PCRE2_CODE_UNIT_WIDTH == 8 || PCRE2_CODE_UNIT_WIDTH == 16)\nBOOL utf = common->utf;\n#endif /* SUPPORT_UNICODE && PCRE2_CODE_UNIT_WIDTH == [8|16] */\n\n#ifdef SUPPORT_UNICODE\nsljit_u32 unicode_status = 0;\nint typereg = TMP1;\nconst sljit_u32 *other_cases;\nsljit_uw typeoffset;\n#endif /* SUPPORT_UNICODE */\n\n/* Scanning the necessary info. */\ncc++;\nccbegin = cc;\ncompares = 0;\n\nif (cc[-1] & XCL_MAP)\n  {\n  min = 0;\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\nwhile (*cc != XCL_END)\n  {\n  compares++;\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n    if (c < min) min = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    if (c < min) min = c;\n    GETCHARINCTEST(c, cc);\n    if (c > max) max = c;\n#ifdef SUPPORT_UNICODE\n    unicode_status |= XCLASS_SAVE_CHAR;\n#endif /* SUPPORT_UNICODE */\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    cc++;\n    if (*cc == PT_CLIST && cc[-1] == XCL_PROP)\n      {\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n      while (*other_cases != NOTACHAR)\n        {\n        if (*other_cases > max) max = *other_cases;\n        if (*other_cases < min) min = *other_cases;\n        other_cases++;\n        }\n      }\n    else\n      {\n      max = READ_CHAR_MAX;\n      min = 0;\n      }\n\n    switch(*cc)\n      {\n      case PT_ANY:\n      /* Any either accepts everything or ignored. */\n      if (cc[-1] == XCL_PROP)\n        {\n        compile_char1_matchingpath(common, OP_ALLANY, cc, backtracks, FALSE);\n        if (list == backtracks)\n          add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n        return;\n        }\n      break;\n\n      case PT_LAMP:\n      case PT_GC:\n      case PT_PC:\n      case PT_ALNUM:\n      unicode_status |= XCLASS_HAS_TYPE;\n      break;\n\n      case PT_SCX:\n      unicode_status |= XCLASS_HAS_SCRIPT_EXTENSION;\n      if (cc[-1] == XCL_NOTPROP)\n        {\n        unicode_status |= XCLASS_SCRIPT_EXTENSION_NOTPROP;\n        break;\n        }\n      compares++;\n      /* Fall through */ \n\n      case PT_SC:\n      unicode_status |= XCLASS_HAS_SCRIPT;\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      case PT_WORD:\n      case PT_PXGRAPH:\n      case PT_PXPRINT:\n      case PT_PXPUNCT:\n      unicode_status |= XCLASS_SAVE_CHAR | XCLASS_HAS_TYPE;\n      break;\n\n      case PT_CLIST:\n      case PT_UCNC:\n      unicode_status |= XCLASS_SAVE_CHAR;\n      break;\n\n      case PT_BOOL:\n      unicode_status |= XCLASS_HAS_BOOL;\n      break;\n\n      case PT_BIDICL:\n      unicode_status |= XCLASS_HAS_BIDICL;\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n  }\nSLJIT_ASSERT(compares > 0);\n\n/* We are not necessary in utf mode even in 8 bit mode. */\ncc = ccbegin;\nif ((cc[-1] & XCL_NOT) != 0)\n  read_char(common, min, max, backtracks, READ_CHAR_UPDATE_STR_PTR);\nelse\n  {\n#ifdef SUPPORT_UNICODE\n  read_char(common, min, max, (unicode_status & XCLASS_NEEDS_UCD) ? backtracks : NULL, 0);\n#else /* !SUPPORT_UNICODE */\n  read_char(common, min, max, NULL, 0);\n#endif /* SUPPORT_UNICODE */\n  }\n\nif ((cc[-1] & XCL_HASPROP) == 0)\n  {\n  if ((cc[-1] & XCL_MAP) != 0)\n    {\n    jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n    if (!optimize_class(common, (const sljit_u8 *)cc, (((const sljit_u8 *)cc)[31] & 0x80) != 0, TRUE, &found))\n      {\n      OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n      OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n      OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n      OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n      OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n      add_jump(compiler, &found, JUMP(SLJIT_NOT_ZERO));\n      }\n\n    add_jump(compiler, backtracks, JUMP(SLJIT_JUMP));\n    JUMPHERE(jump);\n\n    cc += 32 / sizeof(PCRE2_UCHAR);\n    }\n  else\n    {\n    OP2(SLJIT_SUB, TMP2, 0, TMP1, 0, SLJIT_IMM, min);\n    add_jump(compiler, (cc[-1] & XCL_NOT) == 0 ? backtracks : &found, CMP(SLJIT_GREATER, TMP2, 0, SLJIT_IMM, max - min));\n    }\n  }\nelse if ((cc[-1] & XCL_MAP) != 0)\n  {\n  OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n#ifdef SUPPORT_UNICODE\n  unicode_status |= XCLASS_CHAR_SAVED;\n#endif /* SUPPORT_UNICODE */\n  if (!optimize_class(common, (const sljit_u8 *)cc, FALSE, TRUE, list))\n    {\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    jump = NULL;\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      jump = CMP(SLJIT_GREATER, TMP1, 0, SLJIT_IMM, 255);\n\n    OP2(SLJIT_AND, TMP2, 0, TMP1, 0, SLJIT_IMM, 0x7);\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, 3);\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP1), (sljit_sw)cc);\n    OP2(SLJIT_SHL, TMP2, 0, SLJIT_IMM, 1, TMP2, 0);\n    OP2U(SLJIT_AND | SLJIT_SET_Z, TMP1, 0, TMP2, 0);\n    add_jump(compiler, list, JUMP(SLJIT_NOT_ZERO));\n\n#if PCRE2_CODE_UNIT_WIDTH == 8\n    if (common->utf)\n#endif /* PCRE2_CODE_UNIT_WIDTH == 8 */\n      JUMPHERE(jump);\n    }\n\n  OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n  cc += 32 / sizeof(PCRE2_UCHAR);\n  }\n\n#ifdef SUPPORT_UNICODE\nif (unicode_status & XCLASS_NEEDS_UCD)\n  {\n  if ((unicode_status & (XCLASS_SAVE_CHAR | XCLASS_CHAR_SAVED)) == XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP1, 0);\n\n#if PCRE2_CODE_UNIT_WIDTH == 32\n  if (!common->utf)\n    {\n    jump = CMP(SLJIT_LESS, TMP1, 0, SLJIT_IMM, MAX_UTF_CODE_POINT + 1);\n    OP1(SLJIT_MOV, TMP1, 0, SLJIT_IMM, UNASSIGNED_UTF_CHAR);\n    JUMPHERE(jump);\n    }\n#endif /* PCRE2_CODE_UNIT_WIDTH == 32 */\n\n  OP2(SLJIT_LSHR, TMP2, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 1);\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_stage1));\n  OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BLOCK_MASK);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, UCD_BLOCK_SHIFT);\n  OP2(SLJIT_ADD, TMP1, 0, TMP1, 0, TMP2, 0);\n  OP1(SLJIT_MOV, TMP2, 0, SLJIT_IMM, (sljit_sw)PRIV(ucd_stage2));\n  OP1(SLJIT_MOV_U16, TMP2, 0, SLJIT_MEM2(TMP2, TMP1), 1);\n  OP2(SLJIT_SHL, TMP1, 0, TMP2, 0, SLJIT_IMM, 3);\n  OP2(SLJIT_SHL, TMP2, 0, TMP2, 0, SLJIT_IMM, 2);\n  OP2(SLJIT_ADD, TMP2, 0, TMP2, 0, TMP1, 0);\n\n  ccbegin = cc;\n\n  if (unicode_status & XCLASS_HAS_BIDICL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_LSHR, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BIDICLASS_SHIFT);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BIDICL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n          jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]);\n          add_jump(compiler, compares > 0 ? list : backtracks, jump);\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_BOOL)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, bprops));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_BPROPS_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_BOOL)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_boolprop_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT)\n    {\n    OP1(SLJIT_MOV_U8, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        switch (*cc)\n          {\n          case PT_SCX:\n          if (cc[-1] == XCL_NOTPROP)\n            break;\n          /* Fall through */ \n\n          case PT_SC:\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n          if (cc[-1] == XCL_NOTPROP)\n            invertcmp ^= 0x1;\n\n          add_jump(compiler, compares > 0 ? list : backtracks, CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (int)cc[1]));\n          }\n        cc += 2;\n        }\n      }\n\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_HAS_SCRIPT_EXTENSION)\n    {\n    OP1(SLJIT_MOV_U16, TMP1, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, scriptx_bidiclass));\n    OP2(SLJIT_AND, TMP1, 0, TMP1, 0, SLJIT_IMM, UCD_SCRIPTX_MASK);\n    OP2(SLJIT_SHL, TMP1, 0, TMP1, 0, SLJIT_IMM, 2);\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_NOTPROP)\n      {\n      if (unicode_status & XCLASS_HAS_TYPE)\n        {\n        if (unicode_status & XCLASS_SAVE_CHAR)\n          {\n          OP1(SLJIT_MOV, SLJIT_MEM1(SLJIT_SP), LOCALS0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0;\n          }\n        else\n          {\n          OP1(SLJIT_MOV, RETURN_ADDR, 0, TMP2, 0);\n          unicode_status |= XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR;\n          }\n        }\n      OP1(SLJIT_MOV_U8, TMP2, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, script));\n      }\n\n    while (*cc != XCL_END)\n      {\n      if (*cc == XCL_SINGLE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        }\n      else if (*cc == XCL_RANGE)\n        {\n        cc ++;\n        GETCHARINCTEST(c, cc);\n        GETCHARINCTEST(c, cc);\n        }\n      else\n        {\n        SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n        cc++;\n        if (*cc == PT_SCX)\n          {\n          compares--;\n          invertcmp = (compares == 0 && list != backtracks);\n\n          jump = NULL;\n          if (cc[-1] == XCL_NOTPROP)\n            {\n            jump = CMP(SLJIT_EQUAL, TMP2, 0, SLJIT_IMM, (int)cc[1]);\n            if (invertcmp)\n              {\n              add_jump(compiler, backtracks, jump);\n              jump = NULL;\n              }\n            invertcmp ^= 0x1;\n            }\n\n          OP2U(SLJIT_AND32 | SLJIT_SET_Z, SLJIT_MEM1(TMP1), (sljit_sw)(PRIV(ucd_script_sets) + (cc[1] >> 5)), SLJIT_IMM, (sljit_sw)1 << (cc[1] & 0x1f));\n          add_jump(compiler, compares > 0 ? list : backtracks, JUMP(SLJIT_NOT_ZERO ^ invertcmp));\n\n          if (jump != NULL)\n            JUMPHERE(jump);\n          }\n        cc += 2;\n        }\n      }\n\n    if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_LOCALS0)\n      OP1(SLJIT_MOV, TMP2, 0, SLJIT_MEM1(SLJIT_SP), LOCALS0);\n    else if (unicode_status & XCLASS_SCRIPT_EXTENSION_RESTORE_RETURN_ADDR)\n      OP1(SLJIT_MOV, TMP2, 0, RETURN_ADDR, 0);\n    cc = ccbegin;\n    }\n\n  if (unicode_status & XCLASS_SAVE_CHAR)\n    OP1(SLJIT_MOV, TMP1, 0, RETURN_ADDR, 0);\n\n  if (unicode_status & XCLASS_HAS_TYPE)\n    {\n    if (unicode_status & XCLASS_SAVE_CHAR)\n      typereg = RETURN_ADDR;\n\n    OP1(SLJIT_MOV_U8, typereg, 0, SLJIT_MEM1(TMP2), (sljit_sw)PRIV(ucd_records) + SLJIT_OFFSETOF(ucd_record, chartype));\n    }\n  }\n#endif /* SUPPORT_UNICODE */\n\n/* Generating code. */\ncharoffset = 0;\nnumberofcmps = 0;\n#ifdef SUPPORT_UNICODE\ntypeoffset = 0;\n#endif /* SUPPORT_UNICODE */\n\nwhile (*cc != XCL_END)\n  {\n  compares--;\n  invertcmp = (compares == 0 && list != backtracks);\n  jump = NULL;\n\n  if (*cc == XCL_SINGLE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n  else if (*cc == XCL_RANGE)\n    {\n    cc ++;\n    GETCHARINCTEST(c, cc);\n    SET_CHAR_OFFSET(c);\n    GETCHARINCTEST(c, cc);\n\n    if (numberofcmps < 3 && (*cc == XCL_SINGLE || *cc == XCL_RANGE))\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(numberofcmps == 0 ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      numberofcmps++;\n      }\n    else if (numberofcmps > 0)\n      {\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      numberofcmps = 0;\n      }\n    else\n      {\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, TMP1, 0, SLJIT_IMM, (sljit_sw)(c - charoffset));\n      numberofcmps = 0;\n      }\n    }\n#ifdef SUPPORT_UNICODE\n  else\n    {\n    SLJIT_ASSERT(*cc == XCL_PROP || *cc == XCL_NOTPROP);\n    if (*cc == XCL_NOTPROP)\n      invertcmp ^= 0x1;\n    cc++;\n    switch(*cc)\n      {\n      case PT_ANY:\n      if (!invertcmp)\n        jump = JUMP(SLJIT_JUMP);\n      break;\n\n      case PT_LAMP:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lu - typeoffset);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Ll - typeoffset);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Lt - typeoffset);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_GC:\n      c = PRIV(ucp_typerange)[(int)cc[1] * 2];\n      SET_TYPE_OFFSET(c);\n      jump = CMP(SLJIT_LESS_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, PRIV(ucp_typerange)[(int)cc[1] * 2 + 1] - c);\n      break;\n\n      case PT_PC:\n      jump = CMP(SLJIT_EQUAL ^ invertcmp, typereg, 0, SLJIT_IMM, (int)cc[1] - typeoffset);\n      break;\n\n      case PT_SC:\n      case PT_SCX:\n      case PT_BOOL:\n      case PT_BIDICL:\n      compares++;\n      /* Do nothing. */\n      break;\n\n      case PT_SPACE:\n      case PT_PXSPACE:\n      SET_CHAR_OFFSET(9);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0xd - 0x9);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x85 - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x9);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Zl);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Zl);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_WORD:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_UNDERSCORE - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      /* Fall through. */\n\n      case PT_ALNUM:\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Lu - ucp_Ll);\n      OP_FLAGS((*cc == PT_ALNUM) ? SLJIT_MOV : SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_TYPE_OFFSET(ucp_Nd);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_No - ucp_Nd);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_CLIST:\n      other_cases = PRIV(ucd_caseless_sets) + cc[1];\n\n      /* At least three characters are required.\n         Otherwise this case would be handled by the normal code path. */\n      SLJIT_ASSERT(other_cases[0] != NOTACHAR && other_cases[1] != NOTACHAR && other_cases[2] != NOTACHAR);\n      SLJIT_ASSERT(other_cases[0] < other_cases[1] && other_cases[1] < other_cases[2]);\n\n      /* Optimizing character pairs, if their difference is power of 2. */\n      if (is_powerof2(other_cases[1] ^ other_cases[0]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[1]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        other_cases += 2;\n        }\n      else if (is_powerof2(other_cases[2] ^ other_cases[1]))\n        {\n        if (charoffset == 0)\n          OP2(SLJIT_OR, TMP2, 0, TMP1, 0, SLJIT_IMM, other_cases[2] ^ other_cases[1]);\n        else\n          {\n          OP2(SLJIT_ADD, TMP2, 0, TMP1, 0, SLJIT_IMM, (sljit_sw)charoffset);\n          OP2(SLJIT_OR, TMP2, 0, TMP2, 0, SLJIT_IMM, other_cases[1] ^ other_cases[0]);\n          }\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP2, 0, SLJIT_IMM, other_cases[2]);\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(other_cases[0] - charoffset));\n        OP_FLAGS(SLJIT_OR | ((other_cases[3] == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n\n        other_cases += 3;\n        }\n      else\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n        }\n\n      while (*other_cases != NOTACHAR)\n        {\n        OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(*other_cases++ - charoffset));\n        OP_FLAGS(SLJIT_OR | ((*other_cases == NOTACHAR) ? SLJIT_SET_Z : 0), TMP2, 0, SLJIT_EQUAL);\n        }\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_UCNC:\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_DOLLAR_SIGN - charoffset));\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_COMMERCIAL_AT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, (sljit_sw)(CHAR_GRAVE_ACCENT - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      SET_CHAR_OFFSET(0xa0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, (sljit_sw)(0xd7ff - charoffset));\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_LESS_EQUAL);\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER_EQUAL, TMP1, 0, SLJIT_IMM, 0xe000 - 0);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_GREATER_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      case PT_PXGRAPH:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x180e - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPRINT:\n      /* C and Z groups are the farthest two groups. */\n      SET_TYPE_OFFSET(ucp_Ll);\n      OP2U(SLJIT_SUB | SLJIT_SET_GREATER, typereg, 0, SLJIT_IMM, ucp_So - ucp_Ll);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_GREATER);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, typereg, 0, SLJIT_IMM, ucp_Zs - ucp_Ll);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_NOT_EQUAL);\n\n      jump = CMP(SLJIT_NOT_EQUAL, typereg, 0, SLJIT_IMM, ucp_Cf - ucp_Ll);\n\n      /* In case of ucp_Cf, we overwrite the result. */\n      SET_CHAR_OFFSET(0x2066);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x2069 - 0x2066);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      OP2U(SLJIT_SUB | SLJIT_SET_Z, TMP1, 0, SLJIT_IMM, 0x061c - 0x2066);\n      OP_FLAGS(SLJIT_OR, TMP2, 0, SLJIT_EQUAL);\n\n      JUMPHERE(jump);\n      jump = CMP(SLJIT_ZERO ^ invertcmp, TMP2, 0, SLJIT_IMM, 0);\n      break;\n\n      case PT_PXPUNCT:\n      SET_TYPE_OFFSET(ucp_Sc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_So - ucp_Sc);\n      OP_FLAGS(SLJIT_MOV, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_CHAR_OFFSET(0);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, TMP1, 0, SLJIT_IMM, 0x7f);\n      OP_FLAGS(SLJIT_AND, TMP2, 0, SLJIT_LESS_EQUAL);\n\n      SET_TYPE_OFFSET(ucp_Pc);\n      OP2U(SLJIT_SUB | SLJIT_SET_LESS_EQUAL, typereg, 0, SLJIT_IMM, ucp_Ps - ucp_Pc);\n      OP_FLAGS(SLJIT_OR | SLJIT_SET_Z, TMP2, 0, SLJIT_LESS_EQUAL);\n      jump = JUMP(SLJIT_NOT_ZERO ^ invertcmp);\n      break;\n\n      default:\n      SLJIT_UNREACHABLE();\n      break;\n      }\n    cc += 2;\n    }\n#endif /* SUPPORT_UNICODE */\n\n  if (jump != NULL)\n    add_jump(compiler, compares > 0 ? list : backtracks, jump);\n  }\n\nif (found != NULL)\n  set_jumps(found, LABEL());\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n                                      const GraphProperties& properties) {\n  // Push down multiplication on ConvND.\n  //                       *                  ConvND\n  //                     /   \\                /    \\\n  //                 ConvND  C2    -- >      X      *\n  //                  / \\                          / \\\n  //                 X  C1                       C1  C2\n  //\n  // where C1 and C2 are constants and X is non-constant.\n  //\n  // TODO(rmlarsen): Use PrepareConstantPushDown() to simplify this code.\n\n  if (!IsAnyMul(*node) || NumNonControlInputs(*node) != 2) return false;\n\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n  if (!left_child_is_constant && !right_child_is_constant) {\n    return false;\n  }\n  NodeDef* conv_node =\n      left_child_is_constant ? mul_right_child : mul_left_child;\n  if (!IsConv2D(*conv_node) && !IsConv3D(*conv_node)) {\n    return false;\n  }\n  if (node->device() != mul_left_child->device() ||\n      node->device() != mul_right_child->device()) {\n    return false;\n  }\n\n  // Make sure that it is safe to change the value of the convolution\n  // output.\n  if (conv_node->input_size() < 2 ||\n      NumNonControlOutputs(*conv_node, *node_map_) > 1 ||\n      nodes_to_preserve_.find(conv_node->name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n\n  // Identify the nodes to swap.\n  NodeDef* conv_left_child = node_map_->GetNode(conv_node->input(0));\n  NodeDef* conv_right_child = node_map_->GetNode(conv_node->input(1));\n  const bool conv_left_is_constant = IsReallyConstant(*conv_left_child);\n  const bool conv_right_is_constant = IsReallyConstant(*conv_right_child);\n  if (!conv_left_is_constant && !conv_right_is_constant) {\n    // At least one of the convolution inputs should be constant.\n    return false;\n  }\n  if (conv_left_is_constant && conv_right_is_constant) {\n    // Leverage regular constant folding to handle this.\n    return false;\n  }\n  const auto& mul_props = properties.GetOutputProperties(node->name());\n  const auto& conv_props = properties.GetOutputProperties(conv_node->name());\n  if (mul_props.empty() || conv_props.empty()) {\n    return false;\n  }\n  const auto& mul_shape = mul_props[0].shape();\n  const auto& conv_shape = conv_props[0].shape();\n  if (!ShapesSymbolicallyEqual(mul_shape, conv_shape)) {\n    return false;\n  }\n\n  const auto& input_props = properties.GetInputProperties(conv_node->name());\n  if (input_props.size() < 2) {\n    return false;\n  }\n  const auto& filter_shape = input_props[1].shape();\n\n  NodeDef* const_node =\n      left_child_is_constant ? mul_left_child : mul_right_child;\n  const auto& const_props = properties.GetOutputProperties(const_node->name());\n  if (const_props.empty()) {\n    return false;\n  }\n  const auto& const_shape = const_props[0].shape();\n  if (!IsValidConstShapeForMulConvPushDown(\n          conv_node->attr().at(\"data_format\").s(), filter_shape, const_shape)) {\n    return false;\n  }\n\n  string mul_new_name = AddPrefixToNodeName(\"merged_input\", conv_node->name());\n  if (node_map_->NodeExists(mul_new_name)) {\n    return false;\n  }\n  // Make sure we don't introduce loops in the graph by removing control\n  // dependencies from the conv2d node to c2.\n  string conv_const_input =\n      conv_left_is_constant ? conv_node->input(0) : conv_node->input(1);\n  if (MaybeRemoveControlInput(conv_node->name(), const_node, optimized_graph,\n                              node_map_.get())) {\n    // Add a control dep from c1 to c2 to ensure c2 is in the right frame\n    MaybeAddControlInput(conv_const_input, const_node, optimized_graph,\n                         node_map_.get());\n  }\n\n  conv_node->set_name(node->name());\n  node->set_name(mul_new_name);\n  if (conv_left_is_constant) {\n    node_map_->UpdateInput(conv_node->name(), node->input(0), mul_new_name);\n    conv_node->set_input(0, mul_new_name);\n  } else {\n    node_map_->UpdateInput(conv_node->name(), node->input(1), mul_new_name);\n    conv_node->set_input(1, mul_new_name);\n  }\n  NodeDef* conv_const_node =\n      conv_left_is_constant ? conv_left_child : conv_right_child;\n  if (left_child_is_constant) {\n    node->set_input(1, conv_const_node->name());\n  } else {\n    node->set_input(0, conv_const_node->name());\n  }\n  node_map_->AddNode(mul_new_name, node);\n\n  return true;\n}",
        "post_patch": "bool ConstantFolding::MulConvPushDown(GraphDef* optimized_graph, NodeDef* node,\n                                      const GraphProperties& properties) {\n  // Push down multiplication on ConvND.\n  //                       *                  ConvND\n  //                     /   \\                /    \\\n  //                 ConvND  C2    -- >      X      *\n  //                  / \\                          / \\\n  //                 X  C1                       C1  C2\n  //\n  // where C1 and C2 are constants and X is non-constant.\n  //\n  // TODO(rmlarsen): Use PrepareConstantPushDown() to simplify this code.\n\n  if (!IsAnyMul(*node) || NumNonControlInputs(*node) != 2) return false;\n\n  NodeDef* mul_left_child = node_map_->GetNode(node->input(0));\n  NodeDef* mul_right_child = node_map_->GetNode(node->input(1));\n  if (mul_left_child == nullptr || mul_right_child == nullptr) {\n    return false;\n  }\n  // One child must be constant, and the second must be Conv op.\n  const bool left_child_is_constant = IsReallyConstant(*mul_left_child);\n  const bool right_child_is_constant = IsReallyConstant(*mul_right_child);\n  if (!left_child_is_constant && !right_child_is_constant) {\n    return false;\n  }\n  NodeDef* conv_node =\n      left_child_is_constant ? mul_right_child : mul_left_child;\n  if (!IsConv2D(*conv_node) && !IsConv3D(*conv_node)) {\n    return false;\n  }\n  if (node->device() != mul_left_child->device() ||\n      node->device() != mul_right_child->device()) {\n    return false;\n  }\n\n  // Make sure that it is safe to change the value of the convolution\n  // output.\n  if (conv_node->input_size() < 2 ||\n      NumNonControlOutputs(*conv_node, *node_map_) > 1 ||\n      nodes_to_preserve_.find(conv_node->name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n\n  // Identify the nodes to swap.\n  NodeDef* conv_left_child = node_map_->GetNode(conv_node->input(0));\n  NodeDef* conv_right_child = node_map_->GetNode(conv_node->input(1));\n  const bool conv_left_is_constant = IsReallyConstant(*conv_left_child);\n  const bool conv_right_is_constant = IsReallyConstant(*conv_right_child);\n  if (!conv_left_is_constant && !conv_right_is_constant) {\n    // At least one of the convolution inputs should be constant.\n    return false;\n  }\n  if (conv_left_is_constant && conv_right_is_constant) {\n    // Leverage regular constant folding to handle this.\n    return false;\n  }\n  const auto& mul_props = properties.GetOutputProperties(node->name());\n  const auto& conv_props = properties.GetOutputProperties(conv_node->name());\n  if (mul_props.empty() || conv_props.empty()) {\n    return false;\n  }\n  const auto& mul_shape = mul_props[0].shape();\n  const auto& conv_shape = conv_props[0].shape();\n  if (!ShapesSymbolicallyEqual(mul_shape, conv_shape)) {\n    return false;\n  }\n\n  const auto& input_props = properties.GetInputProperties(conv_node->name());\n  if (input_props.size() < 2) {\n    return false;\n  }\n  const auto& filter_shape = input_props[1].shape();\n\n  NodeDef* const_node =\n      left_child_is_constant ? mul_left_child : mul_right_child;\n  const auto& const_props = properties.GetOutputProperties(const_node->name());\n  if (const_props.empty()) {\n    return false;\n  }\n  const auto& const_shape = const_props[0].shape();\n  if (!IsValidConstShapeForMulConvPushDown(\n          conv_node->attr().at(\"data_format\").s(), filter_shape, const_shape)) {\n    return false;\n  }\n\n  string mul_new_name = AddPrefixToNodeName(\"merged_input\", conv_node->name());\n  if (node_map_->NodeExists(mul_new_name)) {\n    return false;\n  }\n  // Make sure we don't introduce loops in the graph by removing control\n  // dependencies from the conv2d node to c2.\n  string conv_const_input =\n      conv_left_is_constant ? conv_node->input(0) : conv_node->input(1);\n  if (MaybeRemoveControlInput(conv_node->name(), const_node, optimized_graph,\n                              node_map_.get())) {\n    // Add a control dep from c1 to c2 to ensure c2 is in the right frame\n    MaybeAddControlInput(conv_const_input, const_node, optimized_graph,\n                         node_map_.get());\n  }\n\n  conv_node->set_name(node->name());\n  node->set_name(mul_new_name);\n  if (conv_left_is_constant) {\n    node_map_->UpdateInput(conv_node->name(), node->input(0), mul_new_name);\n    conv_node->set_input(0, mul_new_name);\n  } else {\n    node_map_->UpdateInput(conv_node->name(), node->input(1), mul_new_name);\n    conv_node->set_input(1, mul_new_name);\n  }\n  NodeDef* conv_const_node =\n      conv_left_is_constant ? conv_left_child : conv_right_child;\n  if (left_child_is_constant) {\n    node->set_input(1, conv_const_node->name());\n  } else {\n    node->set_input(0, conv_const_node->name());\n  }\n  node_map_->AddNode(mul_new_name, node);\n\n  return true;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }",
        "post_patch": "  void Compute(OpKernelContext* context) override {\n    const Tensor& rhs = context->input(1);\n\n    // We always return the input ref.\n    context->forward_ref_input_to_ref_output(0, 0);\n\n    // Prevent copying uninitialized data, to solve harder to debug undefined\n    // behaviors that cannot be traced back to the original tensor.\n    OP_REQUIRES(\n        context, rhs.IsInitialized(),\n        errors::Internal(\"Right hand side of AssignOp is not initialized\"));\n\n    // We can't always know how this value will be used downstream, so make\n    // conservative assumptions in specifying constraints on the memory\n    // allocation attributes, unless the Grappler graph analysis determined that\n    // it was safe not to.\n    AllocatorAttributes attr;\n    if (!relax_constraints_) {\n      attr.set_gpu_compatible(true);\n      attr.set_nic_compatible(true);\n    }\n\n    {\n      mutex_lock l(*context->input_ref_mutex(0));\n      const Tensor& old_lhs = context->mutable_input(0, /* lock_held */ true);\n      const bool same_shape = old_lhs.shape().IsSameSize(rhs.shape());\n      if (validate_shape_) {\n        OP_REQUIRES(context, same_shape,\n                    errors::InvalidArgument(\n                        \"Assign requires shapes of both tensors to match. \"\n                        \"lhs shape= \",\n                        old_lhs.shape().DebugString(),\n                        \" rhs shape= \", rhs.shape().DebugString()));\n      }\n\n      // In the code below we try to minimize the amount of memory allocation\n      // and copying by trying the following two shortcuts:\n      // 1. If the lhs is initialized and has the same number of elements as\n      //    the rhs we can avoid a memory allocation.\n      // 2. If we can reuse the rhs buffer we avoid both a memory allocation\n      //    and copying.\n\n      // 1. Try to copy into an existing buffer.\n      if (old_lhs.IsInitialized() &&\n          old_lhs.shape().num_elements() == rhs.shape().num_elements()) {\n        // The existing lhs tensor has already been initialized and the right\n        // hand side can fit in the underlying buffer.\n        Tensor reshaped_old_lhs;\n        if (same_shape) {\n          reshaped_old_lhs = old_lhs;\n        } else {\n          CHECK(reshaped_old_lhs.CopyFrom(old_lhs, rhs.shape()));\n          context->replace_ref_input(0, reshaped_old_lhs,\n                                     /* lock_held */ true);\n        }\n        if (use_exclusive_lock_) {\n          Copy(context, &reshaped_old_lhs, rhs);\n          return;\n        }\n      } else {\n        // 2. Try to reuse the rhs.\n        std::unique_ptr<Tensor> input_alias = context->forward_input(\n            1, OpKernelContext::Params::kNoReservation /*output_index*/,\n            rhs.dtype(), rhs.shape(), DEVICE_MEMORY, attr);\n        if (input_alias != nullptr) {\n          // Update the ref to point to the new buffer.\n          context->replace_ref_input(0, *input_alias, /* lock_held */ true);\n          return;\n        }\n\n        // Otherwise, create a new tensor whose shape matches the\n        // right hand side, hand off to lhs and copy the rhs into it.\n        Tensor copy_tensor;\n        OP_REQUIRES_OK(context,\n                       context->allocate_temp(old_lhs.dtype(), rhs.shape(),\n                                              &copy_tensor, attr));\n        // We track memory of variables in variable ops instead of in this\n        // assign op.\n        context->clear_recorded_memory();\n        context->replace_ref_input(0, copy_tensor, /* lock_held */ true);\n        if (use_exclusive_lock_) {\n          Copy(context, &copy_tensor, rhs);\n          return;\n        }\n      }\n    }\n\n    // The tensor has already been initialized and the right hand side\n    // matches the left hand side's shape. We have been told to do the\n    // copy outside the lock.\n    Tensor old_unlocked_lhs = context->mutable_input(0, /* lock_held */ false);\n    Copy(context, &old_unlocked_lhs, rhs);\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "gen_hash(codegen_scope *s, node *tree, int val, int limit)\n{\n  int slimit = GEN_VAL_STACK_MAX;\n  if (cursp() >= GEN_LIT_ARY_MAX) slimit = INT16_MAX;\n  int len = 0;\n  mrb_bool update = FALSE;\n\n  while (tree) {\n    if (nint(tree->car->car->car) == NODE_KW_REST_ARGS) {\n      if (len > 0) {\n        pop_n(len*2);\n        if (!update) {\n          genop_2(s, OP_HASH, cursp(), len);\n        }\n        else {\n          pop();\n          genop_2(s, OP_HASHADD, cursp(), len);\n        }\n        push();\n      }\n      codegen(s, tree->car->cdr, val);\n      if (len > 0 || update) {\n        pop(); pop();\n        genop_1(s, OP_HASHCAT, cursp());\n        push();\n      }\n      update = TRUE;\n      len = 0;\n    }\n    else {\n      codegen(s, tree->car->car, val);\n      codegen(s, tree->car->cdr, val);\n      len++;\n    }\n    tree = tree->cdr;\n    if (val && cursp() >= slimit) {\n      pop_n(len*2);\n      if (!update) {\n        genop_2(s, OP_HASH, cursp(), len);\n      }\n      else {\n        pop();\n        genop_2(s, OP_HASHADD, cursp(), len);\n      }\n      push();\n      update = TRUE;\n      len = 0;\n    }\n  }\n  if (update) {\n    if (val && len > 0) {\n      pop_n(len*2+1);\n      genop_2(s, OP_HASHADD, cursp(), len);\n      push();\n    }\n    return -1;                  /* variable length */\n  }\n  return len;\n}",
        "post_patch": "gen_hash(codegen_scope *s, node *tree, int val, int limit)\n{\n  int slimit = GEN_VAL_STACK_MAX;\n  if (cursp() >= GEN_LIT_ARY_MAX) slimit = INT16_MAX;\n  int len = 0;\n  mrb_bool update = FALSE;\n\n  while (tree) {\n    if (nint(tree->car->car->car) == NODE_KW_REST_ARGS) {\n      if (val && len > 0) {\n        pop_n(len*2);\n        if (!update) {\n          genop_2(s, OP_HASH, cursp(), len);\n        }\n        else {\n          pop();\n          genop_2(s, OP_HASHADD, cursp(), len);\n        }\n        push();\n      }\n      codegen(s, tree->car->cdr, val);\n      if (val && (len > 0 || update)) {\n        pop(); pop();\n        genop_1(s, OP_HASHCAT, cursp());\n        push();\n      }\n      update = TRUE;\n      len = 0;\n    }\n    else {\n      codegen(s, tree->car->car, val);\n      codegen(s, tree->car->cdr, val);\n      len++;\n    }\n    tree = tree->cdr;\n    if (val && cursp() >= slimit) {\n      pop_n(len*2);\n      if (!update) {\n        genop_2(s, OP_HASH, cursp(), len);\n      }\n      else {\n        pop();\n        genop_2(s, OP_HASHADD, cursp(), len);\n      }\n      push();\n      update = TRUE;\n      len = 0;\n    }\n  }\n  if (update) {\n    if (val && len > 0) {\n      pop_n(len*2+1);\n      genop_2(s, OP_HASHADD, cursp(), len);\n      push();\n    }\n    return -1;                  /* variable length */\n  }\n  return len;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }",
        "post_patch": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    OP_REQUIRES(ctx, key_tensor->NumElements() == 1,\n                errors::InvalidArgument(\n                    \"key must be an int64 scalar, got tensor with shape: \",\n                    key_tensor->shape()));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 15) {\n        n++;\n        if (n == 15) {\n          pop_n(14);\n          genop_2(s, OP_ARRAY, cursp(), 15);\n        }\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_massignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "post_patch": "gen_assignment(codegen_scope *s, node *tree, node *rhs, int sp, int val)\n{\n  int idx;\n  int type = nint(tree->car);\n\n  switch (type) {\n  case NODE_GVAR:\n  case NODE_ARG:\n  case NODE_LVAR:\n  case NODE_IVAR:\n  case NODE_CVAR:\n  case NODE_CONST:\n  case NODE_NIL:\n  case NODE_MASGN:\n    if (rhs) {\n      codegen(s, rhs, VAL);\n      pop();\n      sp = cursp();\n    }\n    break;\n\n  case NODE_COLON2:\n  case NODE_CALL:\n  case NODE_SCALL:\n    /* keep evaluation order */\n    break;\n\n  case NODE_NVAR:\n    codegen_error(s, \"Can't assign to numbered parameter\");\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n\n  tree = tree->cdr;\n  switch (type) {\n  case NODE_GVAR:\n    gen_setxv(s, OP_SETGV, sp, nsym(tree), val);\n    break;\n  case NODE_ARG:\n  case NODE_LVAR:\n    idx = lv_idx(s, nsym(tree));\n    if (idx > 0) {\n      if (idx != sp) {\n        gen_move(s, idx, sp, val);\n      }\n      break;\n    }\n    else {                      /* upvar */\n      gen_setupvar(s, sp, nsym(tree));\n    }\n    break;\n  case NODE_IVAR:\n    gen_setxv(s, OP_SETIV, sp, nsym(tree), val);\n    break;\n  case NODE_CVAR:\n    gen_setxv(s, OP_SETCV, sp, nsym(tree), val);\n    break;\n  case NODE_CONST:\n    gen_setxv(s, OP_SETCONST, sp, nsym(tree), val);\n    break;\n  case NODE_COLON2:\n    if (sp) {\n      gen_move(s, cursp(), sp, 0);\n    }\n    sp = cursp();\n    push();\n    codegen(s, tree->car, VAL);\n    if (rhs) {\n      codegen(s, rhs, VAL); pop();\n      gen_move(s, sp, cursp(), 0);\n    }\n    pop_n(2);\n    idx = new_sym(s, nsym(tree->cdr));\n    genop_2(s, OP_SETMCNST, sp, idx);\n    break;\n\n  case NODE_CALL:\n  case NODE_SCALL:\n    {\n      int noself = 0, safe = (type == NODE_SCALL), skip = 0, top, call, n = 0;\n      mrb_sym mid = nsym(tree->cdr->car);\n\n      top = cursp();\n      if (val || sp == cursp()) {\n        push();                   /* room for retval */\n      }\n      call = cursp();\n      if (!tree->car) {\n        noself = 1;\n        push();\n      }\n      else {\n        codegen(s, tree->car, VAL); /* receiver */\n      }\n      if (safe) {\n        int recv = cursp()-1;\n        gen_move(s, cursp(), recv, 1);\n        skip = genjmp2_0(s, OP_JMPNIL, cursp(), val);\n      }\n      tree = tree->cdr->cdr->car;\n      if (tree) {\n        if (tree->car) {            /* positional arguments */\n          n = gen_values(s, tree->car, VAL, (tree->cdr->car)?13:14);\n          if (n < 0) {              /* variable length */\n            n = 15;\n            push();\n          }\n        }\n        if (tree->cdr->car) {       /* keyword arguments */\n          if (n == 13 || n == 14) {\n            pop_n(n);\n            genop_2(s, OP_ARRAY, cursp(), n);\n            push();\n            n = 15;\n          }\n          gen_hash(s, tree->cdr->car->cdr, VAL, 0);\n          if (n < 14) {\n            n++;\n          }\n          else {\n            pop_n(2);\n            genop_2(s, OP_ARYPUSH, cursp(), 1);\n          }\n          push();\n        }\n      }\n      if (rhs) {\n        codegen(s, rhs, VAL);\n        pop();\n      }\n      else {\n        gen_move(s, cursp(), sp, 0);\n      }\n      if (val) {\n        gen_move(s, top, cursp(), 1);\n      }\n      if (n < 15) {\n        n++;\n        if (n == 15) {\n          pop_n(14);\n          genop_2(s, OP_ARRAY, cursp(), 15);\n        }\n      }\n      else {\n        pop();\n        genop_2(s, OP_ARYPUSH, cursp(), 1);\n      }\n      s->sp = call;\n      if (mid == MRB_OPSYM_2(s->mrb, aref) && n == 2) {\n        genop_1(s, OP_SETIDX, cursp());\n      }\n      else {\n        genop_3(s, noself ? OP_SSEND : OP_SEND, cursp(), new_sym(s, attrsym(s, mid)), n);\n      }\n      if (safe) {\n        dispatch(s, skip);\n      }\n      s->sp = top;\n    }\n    break;\n\n  case NODE_MASGN:\n    gen_massignment(s, tree->car, sp, val);\n    break;\n\n  /* splat without assignment */\n  case NODE_NIL:\n    break;\n\n  default:\n    codegen_error(s, \"unknown lhs\");\n    break;\n  }\n  if (val) push();\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "    void publish(Topic *iterator, size_t start, size_t stop, std::string_view topic, std::pair<std::string_view, std::string_view> message) {\n        /* If we already have 64 triggered topics make sure to drain it here */\n        if (numTriggeredTopics == 64) {\n            drain();\n        }\n\n        /* Iterate over all segments in given topic */\n        for (; stop != std::string::npos; start = stop + 1) {\n            stop = topic.find('/', start);\n            std::string_view segment = topic.substr(start, stop - start);\n\n            /* It is very important to disallow wildcards when publishing.\n             * We will not catch EVERY misuse this lazy way, but enough to hinder\n             * explosive recursion.\n             * Terminating wildcards MAY still get triggered along the way, if for\n             * instace the error is found late while iterating the topic segments. */\n            if (segment.length() == 1) {\n                if (segment[0] == '+' || segment[0] == '#') {\n                    return;\n                }\n            }\n\n            /* Do we have a terminating wildcard child? */\n            if (iterator->terminatingWildcardChild) {\n                iterator->terminatingWildcardChild->messages[messageId] = message;\n\n                /* Add this topic to triggered */\n                if (!iterator->terminatingWildcardChild->triggered) {\n                    triggeredTopics[numTriggeredTopics++] = iterator->terminatingWildcardChild;\n                    iterator->terminatingWildcardChild->triggered = true;\n                }\n            }\n\n            /* Do we have a wildcard child? */\n            if (iterator->wildcardChild) {\n                publish(iterator->wildcardChild, stop + 1, stop, topic, message);\n            }\n\n            std::map<std::string_view, Topic *>::iterator it = iterator->children.find(segment);\n            if (it == iterator->children.end()) {\n                /* Stop trying to match by exact string */\n                return;\n            }\n\n            iterator = it->second;\n        }\n\n        /* If we went all the way we matched exactly */\n        iterator->messages[messageId] = message;\n\n        /* Add this topic to triggered */\n        if (!iterator->triggered) {\n            triggeredTopics[numTriggeredTopics++] = iterator;\n            iterator->triggered = true;\n        }\n    }",
        "post_patch": "    void publish(Topic *iterator, size_t start, size_t stop, std::string_view topic, std::pair<std::string_view, std::string_view> message) {\n\n        /* Iterate over all segments in given topic */\n        for (; stop != std::string::npos; start = stop + 1) {\n            stop = topic.find('/', start);\n            std::string_view segment = topic.substr(start, stop - start);\n\n            /* It is very important to disallow wildcards when publishing.\n             * We will not catch EVERY misuse this lazy way, but enough to hinder\n             * explosive recursion.\n             * Terminating wildcards MAY still get triggered along the way, if for\n             * instace the error is found late while iterating the topic segments. */\n            if (segment.length() == 1) {\n                if (segment[0] == '+' || segment[0] == '#') {\n                    return;\n                }\n            }\n\n            /* Do we have a terminating wildcard child? */\n            if (iterator->terminatingWildcardChild) {\n                iterator->terminatingWildcardChild->messages[messageId] = message;\n\n                /* Add this topic to triggered */\n                if (!iterator->terminatingWildcardChild->triggered) {\n                    /* If we already have 64 triggered topics make sure to drain it here */\n                    if (numTriggeredTopics == 64) {\n                        drain();\n                    }\n\n                    triggeredTopics[numTriggeredTopics++] = iterator->terminatingWildcardChild;\n                    iterator->terminatingWildcardChild->triggered = true;\n                }\n            }\n\n            /* Do we have a wildcard child? */\n            if (iterator->wildcardChild) {\n                publish(iterator->wildcardChild, stop + 1, stop, topic, message);\n            }\n\n            std::map<std::string_view, Topic *>::iterator it = iterator->children.find(segment);\n            if (it == iterator->children.end()) {\n                /* Stop trying to match by exact string */\n                return;\n            }\n\n            iterator = it->second;\n        }\n\n        /* If we went all the way we matched exactly */\n        iterator->messages[messageId] = message;\n\n        /* Add this topic to triggered */\n        if (!iterator->triggered) {\n            /* If we already have 64 triggered topics make sure to drain it here */\n            if (numTriggeredTopics == 64) {\n                drain();\n            }\n\n            triggeredTopics[numTriggeredTopics++] = iterator;\n            iterator->triggered = true;\n        }\n    }",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (setns), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (umount), EPERM},\n    {SCMP_SYS (umount2), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n\n    /* New mount manipulation APIs can also change our VFS. There's no\n     * legitimate reason to do these in the sandbox, so block all of them\n     * rather than thinking about which ones might be dangerous.\n     * (GHSA-67h7-w3jq-vh4q) */\n    {SCMP_SYS (open_tree), ENOSYS},\n    {SCMP_SYS (move_mount), ENOSYS},\n    {SCMP_SYS (fsopen), ENOSYS},\n    {SCMP_SYS (fsconfig), ENOSYS},\n    {SCMP_SYS (fsmount), ENOSYS},\n    {SCMP_SYS (fspick), ENOSYS},\n    {SCMP_SYS (mount_setattr), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "post_patch": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (setns), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (umount), EPERM},\n    {SCMP_SYS (umount2), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n    {SCMP_SYS (chroot), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n\n    /* New mount manipulation APIs can also change our VFS. There's no\n     * legitimate reason to do these in the sandbox, so block all of them\n     * rather than thinking about which ones might be dangerous.\n     * (GHSA-67h7-w3jq-vh4q) */\n    {SCMP_SYS (open_tree), ENOSYS},\n    {SCMP_SYS (move_mount), ENOSYS},\n    {SCMP_SYS (fsopen), ENOSYS},\n    {SCMP_SYS (fsconfig), ENOSYS},\n    {SCMP_SYS (fsmount), ENOSYS},\n    {SCMP_SYS (fspick), ENOSYS},\n    {SCMP_SYS (mount_setattr), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    LOCAL_ARRAY(char, tmpbuf, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    String outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n            gopherState->overflowed = true; // may already be true\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    case GOPHER_WWW:\n                        icon_url = mimeGetIconURL(\"internal-link\");\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    memset(tmpbuf, '\\0', TEMP_BUF_SIZE);\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        snprintf(tmpbuf, TEMP_BUF_SIZE, \"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"%s\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            snprintf(tmpbuf, TEMP_BUF_SIZE, \"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                    outbuf.append(tmpbuf);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"%s\\n\", html_quote(result));\n                }\n\n                outbuf.append(tmpbuf);\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    snprintf(tmpbuf, TEMP_BUF_SIZE, \"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    outbuf.append(tmpbuf);\n                    break;\n                }\n\n                }\n            }\n\n            break;\n            }           /* HTML_CSO_RESULT */\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.size() > 0) {\n        entry->append(outbuf.rawBuf(), outbuf.size());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    outbuf.clean();\n    return;\n}",
        "post_patch": "gopherToHTML(GopherStateData * gopherState, char *inbuf, int len)\n{\n    char *pos = inbuf;\n    char *lpos = NULL;\n    char *tline = NULL;\n    LOCAL_ARRAY(char, line, TEMP_BUF_SIZE);\n    char *name = NULL;\n    char *selector = NULL;\n    char *host = NULL;\n    char *port = NULL;\n    char *escaped_selector = NULL;\n    const char *icon_url = NULL;\n    char gtype;\n    StoreEntry *entry = NULL;\n\n    memset(line, '\\0', TEMP_BUF_SIZE);\n\n    entry = gopherState->entry;\n\n    if (gopherState->conversion == GopherStateData::HTML_INDEX_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"Gopher Index %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<p>This is a searchable Gopher index. Use the search\\n\"\n                          \"function of your browser to enter search terms.\\n\"\n                          \"<ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    if (gopherState->conversion == GopherStateData::HTML_CSO_PAGE) {\n        char *html_url = html_quote(entry->url());\n        gopherHTMLHeader(entry, \"CSO Search of %s\", html_url);\n        storeAppendPrintf(entry,\n                          \"<P>A CSO database usually contains a phonebook or\\n\"\n                          \"directory.  Use the search function of your browser to enter\\n\"\n                          \"search terms.</P><ISINDEX>\\n\");\n        gopherHTMLFooter(entry);\n        /* now let start sending stuff to client */\n        entry->flush();\n        gopherState->HTML_header_added = 1;\n\n        return;\n    }\n\n    SBuf outbuf;\n\n    if (!gopherState->HTML_header_added) {\n        if (gopherState->conversion == GopherStateData::HTML_CSO_RESULT)\n            gopherHTMLHeader(entry, \"CSO Search Result\", NULL);\n        else\n            gopherHTMLHeader(entry, \"Gopher Menu\", NULL);\n\n        outbuf.append (\"<PRE>\");\n\n        gopherState->HTML_header_added = 1;\n\n        gopherState->HTML_pre = 1;\n    }\n\n    while (pos < inbuf + len) {\n        int llen;\n        int left = len - (pos - inbuf);\n        lpos = (char *)memchr(pos, '\\n', left);\n        if (lpos) {\n            ++lpos;             /* Next line is after \\n */\n            llen = lpos - pos;\n        } else {\n            llen = left;\n        }\n        if (gopherState->len + llen >= TEMP_BUF_SIZE) {\n            debugs(10, DBG_IMPORTANT, \"GopherHTML: Buffer overflow. Lost some data on URL: \" << entry->url()  );\n            llen = TEMP_BUF_SIZE - gopherState->len - 1;\n            gopherState->overflowed = true; // may already be true\n        }\n        if (!lpos) {\n            /* there is no complete line in inbuf */\n            /* copy it to temp buffer */\n            /* note: llen is adjusted above */\n            memcpy(gopherState->buf + gopherState->len, pos, llen);\n            gopherState->len += llen;\n            break;\n        }\n        if (gopherState->len != 0) {\n            /* there is something left from last tx. */\n            memcpy(line, gopherState->buf, gopherState->len);\n            memcpy(line + gopherState->len, pos, llen);\n            llen += gopherState->len;\n            gopherState->len = 0;\n        } else {\n            memcpy(line, pos, llen);\n        }\n        line[llen + 1] = '\\0';\n        /* move input to next line */\n        pos = lpos;\n\n        /* at this point. We should have one line in buffer to process */\n\n        if (*line == '.') {\n            /* skip it */\n            memset(line, '\\0', TEMP_BUF_SIZE);\n            continue;\n        }\n\n        switch (gopherState->conversion) {\n\n        case GopherStateData::HTML_INDEX_RESULT:\n\n        case GopherStateData::HTML_DIR: {\n            tline = line;\n            gtype = *tline;\n            ++tline;\n            name = tline;\n            selector = strchr(tline, TAB);\n\n            if (selector) {\n                *selector = '\\0';\n                ++selector;\n                host = strchr(selector, TAB);\n\n                if (host) {\n                    *host = '\\0';\n                    ++host;\n                    port = strchr(host, TAB);\n\n                    if (port) {\n                        char *junk;\n                        port[0] = ':';\n                        junk = strchr(host, TAB);\n\n                        if (junk)\n                            *junk++ = 0;    /* Chop port */\n                        else {\n                            junk = strchr(host, '\\r');\n\n                            if (junk)\n                                *junk++ = 0;    /* Chop port */\n                            else {\n                                junk = strchr(host, '\\n');\n\n                                if (junk)\n                                    *junk++ = 0;    /* Chop port */\n                            }\n                        }\n\n                        if ((port[1] == '0') && (!port[2]))\n                            port[0] = 0;    /* 0 means none */\n                    }\n\n                    /* escape a selector here */\n                    escaped_selector = xstrdup(rfc1738_escape_part(selector));\n\n                    switch (gtype) {\n\n                    case GOPHER_DIRECTORY:\n                        icon_url = mimeGetIconURL(\"internal-menu\");\n                        break;\n\n                    case GOPHER_HTML:\n\n                    case GOPHER_FILE:\n                        icon_url = mimeGetIconURL(\"internal-text\");\n                        break;\n\n                    case GOPHER_INDEX:\n\n                    case GOPHER_CSO:\n                        icon_url = mimeGetIconURL(\"internal-index\");\n                        break;\n\n                    case GOPHER_IMAGE:\n\n                    case GOPHER_GIF:\n\n                    case GOPHER_PLUS_IMAGE:\n                        icon_url = mimeGetIconURL(\"internal-image\");\n                        break;\n\n                    case GOPHER_SOUND:\n\n                    case GOPHER_PLUS_SOUND:\n                        icon_url = mimeGetIconURL(\"internal-sound\");\n                        break;\n\n                    case GOPHER_PLUS_MOVIE:\n                        icon_url = mimeGetIconURL(\"internal-movie\");\n                        break;\n\n                    case GOPHER_TELNET:\n\n                    case GOPHER_3270:\n                        icon_url = mimeGetIconURL(\"internal-telnet\");\n                        break;\n\n                    case GOPHER_BIN:\n\n                    case GOPHER_MACBINHEX:\n\n                    case GOPHER_DOSBIN:\n\n                    case GOPHER_UUENCODED:\n                        icon_url = mimeGetIconURL(\"internal-binary\");\n                        break;\n\n                    case GOPHER_INFO:\n                        icon_url = NULL;\n                        break;\n\n                    case GOPHER_WWW:\n                        icon_url = mimeGetIconURL(\"internal-link\");\n                        break;\n\n                    default:\n                        icon_url = mimeGetIconURL(\"internal-unknown\");\n                        break;\n                    }\n\n                    if ((gtype == GOPHER_TELNET) || (gtype == GOPHER_3270)) {\n                        if (strlen(escaped_selector) != 0)\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s@%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, escaped_selector, rfc1738_escape_part(host),\n                                     *port ? \":\" : \"\", port, html_quote(name));\n                        else\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"telnet://%s%s%s/\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_part(host), *port ? \":\" : \"\",\n                                     port, html_quote(name));\n\n                    } else if (gtype == GOPHER_INFO) {\n                        outbuf.appendf(\"\\t%s\\n\", html_quote(name));\n                    } else {\n                        if (strncmp(selector, \"GET /\", 5) == 0) {\n                            /* WWW link */\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"http://%s/%s\\\">%s</A>\\n\",\n                                     icon_url, host, rfc1738_escape_unescaped(selector + 5), html_quote(name));\n                        } else if (gtype == GOPHER_WWW) {\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, rfc1738_escape_unescaped(selector), html_quote(name));\n                        } else {\n                            /* Standard link */\n                            outbuf.appendf(\"<IMG border=\\\"0\\\" SRC=\\\"%s\\\"> <A HREF=\\\"gopher://%s/%c%s\\\">%s</A>\\n\",\n                                     icon_url, host, gtype, escaped_selector, html_quote(name));\n                        }\n                    }\n\n                    safe_free(escaped_selector);\n                } else {\n                    memset(line, '\\0', TEMP_BUF_SIZE);\n                    continue;\n                }\n            } else {\n                memset(line, '\\0', TEMP_BUF_SIZE);\n                continue;\n            }\n\n            break;\n            }           /* HTML_DIR, HTML_INDEX_RESULT */\n\n        case GopherStateData::HTML_CSO_RESULT: {\n            if (line[0] == '-') {\n                int code, recno;\n                char *s_code, *s_recno, *result;\n\n                s_code = strtok(line + 1, \":\\n\");\n                s_recno = strtok(NULL, \":\\n\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                recno = atoi(s_recno);\n\n                if (code != 200)\n                    break;\n\n                if (gopherState->cso_recno != recno) {\n                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>Record# %d<br><i>%s</i></H2>\\n<PRE>\", recno, html_quote(result));\n                    gopherState->cso_recno = recno;\n                } else {\n                    outbuf.appendf(\"%s\\n\", html_quote(result));\n                }\n\n                break;\n            } else {\n                int code;\n                char *s_code, *result;\n\n                s_code = strtok(line, \":\");\n                result = strtok(NULL, \"\\n\");\n\n                if (!result)\n                    break;\n\n                code = atoi(s_code);\n\n                switch (code) {\n\n                case 200: {\n                    /* OK */\n                    /* Do nothing here */\n                    break;\n                }\n\n                case 102:   /* Number of matches */\n\n                case 501:   /* No Match */\n\n                case 502: { /* Too Many Matches */\n                    /* Print the message the server returns */\n                    outbuf.appendf(\"</PRE><HR noshade size=\\\"1px\\\"><H2>%s</H2>\\n<PRE>\", html_quote(result));\n                    break;\n                }\n\n                }\n            }\n\n            break;\n            }           /* HTML_CSO_RESULT */\n        default:\n            break;      /* do nothing */\n\n        }           /* switch */\n\n    }               /* while loop */\n\n    if (outbuf.length() > 0) {\n        entry->append(outbuf.rawContent(), outbuf.length());\n        /* now let start sending stuff to client */\n        entry->flush();\n    }\n\n    return;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    },
    {
        "pre_patch": "char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicode_type)\n{\n\tu32 i, j, len;\n\tchar *sOK;\n\tchar szLineConv[1024];\n\tunsigned short *sptr;\n\n\tmemset(szLine, 0, sizeof(char)*lineSize);\n\tsOK = gf_fgets(szLine, lineSize, txt_in);\n\tif (!sOK) return NULL;\n\tif (unicode_type<=1) {\n\t\tj=0;\n\t\tlen = (u32) strlen(szLine);\n\t\tfor (i=0; i<len; i++) {\n\t\t\tif (!unicode_type && (szLine[i] & 0x80)) {\n\t\t\t\t/*non UTF8 (likely some win-CP)*/\n\t\t\t\tif ((szLine[i+1] & 0xc0) != 0x80) {\n\t\t\t\t\tszLineConv[j] = 0xc0 | ( (szLine[i] >> 6) & 0x3 );\n\t\t\t\t\tj++;\n\t\t\t\t\tszLine[i] &= 0xbf;\n\t\t\t\t}\n\t\t\t\t/*UTF8 2 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xe0) == 0xc0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 3 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf0) == 0xe0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 4 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf8) == 0xf0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t} else {\n\t\t\t\t\ti+=1;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tszLineConv[j] = szLine[i];\n\t\t\tj++;\n\t\t}\n\t\tszLineConv[j] = 0;\n\t\tstrcpy(szLine, szLineConv);\n\t\treturn sOK;\n\t}\n\n#ifdef GPAC_BIG_ENDIAN\n\tif (unicode_type==3)\n#else\n\tif (unicode_type==2)\n#endif\n\t{\n\t\ti=0;\n\t\twhile (1) {\n\t\t\tchar c;\n\t\t\tif (!szLine[i] && !szLine[i+1]) break;\n\t\t\tc = szLine[i+1];\n\t\t\tszLine[i+1] = szLine[i];\n\t\t\tszLine[i] = c;\n\t\t\ti+=2;\n\t\t}\n\t}\n\tsptr = (u16 *)szLine;\n\ti = (u32) gf_utf8_wcstombs(szLineConv, 1024, (const unsigned short **) &sptr);\n\tszLineConv[i] = 0;\n\tstrcpy(szLine, szLineConv);\n\t/*this is ugly indeed: since input is UTF16-LE, there are many chances the gf_fgets never reads the \\0 after a \\n*/\n\tif (unicode_type==3) gf_fgetc(txt_in);\n\treturn sOK;\n}",
        "post_patch": "char *gf_text_get_utf8_line(char *szLine, u32 lineSize, FILE *txt_in, s32 unicode_type)\n{\n\tu32 i, j, len;\n\tchar *sOK;\n\tchar szLineConv[2048];\n\tunsigned short *sptr;\n\n\tmemset(szLine, 0, sizeof(char)*lineSize);\n\tsOK = gf_fgets(szLine, lineSize, txt_in);\n\tif (!sOK) return NULL;\n\tif (unicode_type<=1) {\n\t\tj=0;\n\t\tlen = (u32) strlen(szLine);\n\t\tfor (i=0; i<len; i++) {\n\t\t\tif (!unicode_type && (szLine[i] & 0x80)) {\n\t\t\t\t/*non UTF8 (likely some win-CP)*/\n\t\t\t\tif ((szLine[i+1] & 0xc0) != 0x80) {\n\t\t\t\t\tszLineConv[j] = 0xc0 | ( (szLine[i] >> 6) & 0x3 );\n\t\t\t\t\tj++;\n\t\t\t\t\tszLine[i] &= 0xbf;\n\t\t\t\t}\n\t\t\t\t/*UTF8 2 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xe0) == 0xc0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 3 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf0) == 0xe0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\t/*UTF8 4 bytes char*/\n\t\t\t\telse if ( (szLine[i] & 0xf8) == 0xf0) {\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t\tszLineConv[j] = szLine[i];\n\t\t\t\t\ti++;\n\t\t\t\t\tj++;\n\t\t\t\t} else {\n\t\t\t\t\ti+=1;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tszLineConv[j] = szLine[i];\n\t\t\tj++;\n\t\t}\n\t\tszLineConv[j] = 0;\n\t\tstrcpy(szLine, szLineConv);\n\t\treturn sOK;\n\t}\n\n#ifdef GPAC_BIG_ENDIAN\n\tif (unicode_type==3)\n#else\n\tif (unicode_type==2)\n#endif\n\t{\n\t\ti=0;\n\t\twhile (1) {\n\t\t\tchar c;\n\t\t\tif (!szLine[i] && !szLine[i+1]) break;\n\t\t\tc = szLine[i+1];\n\t\t\tszLine[i+1] = szLine[i];\n\t\t\tszLine[i] = c;\n\t\t\ti+=2;\n\t\t}\n\t}\n\tsptr = (u16 *)szLine;\n\ti = (u32) gf_utf8_wcstombs(szLineConv, 2048, (const unsigned short **) &sptr);\n\tszLineConv[i] = 0;\n\tstrcpy(szLine, szLineConv);\n\t/*this is ugly indeed: since input is UTF16-LE, there are many chances the gf_fgets never reads the \\0 after a \\n*/\n\tif (unicode_type==3) gf_fgetc(txt_in);\n\treturn sOK;\n}",
        "pre_patch_label": 1,
        "post_patch_label": 0
    }
]
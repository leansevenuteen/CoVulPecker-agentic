[
    {
        "pre_patch": "static bool mtrr_valid(struct kvm_vcpu *vcpu, u32 msr, u64 data)\n{\n\tint i;\n\tu64 mask;\n\n\tif (!msr_mtrr_valid(msr))\n\t\treturn false;\n\n\tif (msr == MSR_IA32_CR_PAT) {\n\t\tfor (i = 0; i < 8; i++)\n\t\t\tif (!valid_pat_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t} else if (msr == MSR_MTRRdefType) {\n\t\tif (data & ~0xcff)\n\t\t\treturn false;\n\t\treturn valid_mtrr_type(data & 0xff);\n\t} else if (msr >= MSR_MTRRfix64K_00000 && msr <= MSR_MTRRfix4K_F8000) {\n\t\tfor (i = 0; i < 8 ; i++)\n\t\t\tif (!valid_mtrr_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t}\n\n\t/* variable MTRRs */\n\tWARN_ON(!(msr >= 0x200 && msr < 0x200 + 2 * KVM_NR_VAR_MTRR));\n\n\tmask = (~0ULL) << cpuid_maxphyaddr(vcpu);\n\tif ((msr & 1) == 0) {\n\t\t/* MTRR base */\n\t\tif (!valid_mtrr_type(data & 0xff))\n\t\t\treturn false;\n\t\tmask |= 0xf00;\n\t} else\n\t\t/* MTRR mask */\n\t\tmask |= 0x7ff;\n\tif (data & mask) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n",
        "post_patch": "static bool mtrr_valid(struct kvm_vcpu *vcpu, u32 msr, u64 data)\n{\n\tint i;\n\tu64 mask;\n\n\tif (!msr_mtrr_valid(msr))\n\t\treturn false;\n\n\tif (msr == MSR_IA32_CR_PAT) {\n\t\tfor (i = 0; i < 8; i++)\n\t\t\tif (!valid_pat_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t} else if (msr == MSR_MTRRdefType) {\n\t\tif (data & ~0xcff)\n\t\t\treturn false;\n\t\treturn valid_mtrr_type(data & 0xff);\n\t} else if (msr >= MSR_MTRRfix64K_00000 && msr <= MSR_MTRRfix4K_F8000) {\n\t\tfor (i = 0; i < 8 ; i++)\n\t\t\tif (!valid_mtrr_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t}\n\n\t/* variable MTRRs */\n\tWARN_ON(!(msr >= 0x200 && msr < 0x200 + 2 * KVM_NR_VAR_MTRR));\n\n\tmask = (~0ULL) << cpuid_maxphyaddr(vcpu);\n\tif ((msr & 1) == 0) {\n\t\t/* MTRR base */\n\t\tif (!valid_mtrr_type(data & 0xff))\n\t\t\treturn false;\n\t\tmask |= 0xf00;\n\t} else\n\t\t/* MTRR mask */\n\t\tmask |= 0x7ff;\n\tif (data & mask) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n",
        "post_patch_with_fix": "static bool mtrr_valid(struct kvm_vcpu *vcpu, u32 msr, u64 data)\n{\n\tint i;\n\tu64 mask;\n\n\tif (!msr_mtrr_valid(msr))\n\t\treturn false;\n\n\tif (msr == MSR_IA32_CR_PAT) {\n\t\tfor (i = 0; i < 8; i++)\n\t\t\tif (!valid_pat_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t} else if (msr == MSR_MTRRdefType) {\n\t\tif (data & ~0xcff)\n\t\t\treturn false;\n\t\treturn valid_mtrr_type(data & 0xff);\n\t} else if (msr >= MSR_MTRRfix64K_00000 && msr <= MSR_MTRRfix4K_F8000) {\n\t\tfor (i = 0; i < 8 ; i++)\n\t\t\tif (!valid_mtrr_type((data >> (i * 8)) & 0xff))\n\t\t\t\treturn false;\n\t\treturn true;\n\t}\n\n\t/* variable MTRRs */\n\tWARN_ON(!(msr >= 0x200 && msr < 0x200 + 2 * KVM_NR_VAR_MTRR));\n\n\tmask = (~0ULL) << cpuid_maxphyaddr(vcpu);\n\tif ((msr & 1) == 0) {\n\t\t/* MTRR base */\n\t\tif (!valid_mtrr_type(data & 0xff))\n\t\t\treturn false;\n\t\tmask |= 0xf00;\n\t} else\n\t\t/* MTRR mask */\n\t\tmask |= 0x7ff;\n\tif (data & mask) {\n\t\tkvm_inject_gp(vcpu, 0);\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "String AudioNode::channelCountMode() const {\n  return Handler().GetChannelCountMode();\n}\n",
        "post_patch": "String AudioNode::channelCountMode() const {\n  return Handler().GetChannelCountMode();\n}\n",
        "post_patch_with_fix": "String AudioNode::channelCountMode() const {\n  return Handler().GetChannelCountMode();\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static __always_inline int __linearize(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t       struct segmented_address addr,\n\t\t\t\t       unsigned *max_size, unsigned size,\n\t\t\t\t       bool write, bool fetch,\n\t\t\t\t       enum x86emul_mode mode, ulong *linear)\n{\n\tstruct desc_struct desc;\n\tbool usable;\n\tulong la;\n\tu32 lim;\n\tu16 sel;\n\n\tla = seg_base(ctxt, addr.seg) + addr.ea;\n\t*max_size = 0;\n\tswitch (mode) {\n\tcase X86EMUL_MODE_PROT64:\n\t\t*linear = la;\n\t\tif (is_noncanonical_address(la))\n\t\t\tgoto bad;\n\n\t\t*max_size = min_t(u64, ~0u, (1ull << 48) - la);\n\t\tif (size > *max_size)\n\t\t\tgoto bad;\n\t\tbreak;\n\tdefault:\n\t\t*linear = la = (u32)la;\n\t\tusable = ctxt->ops->get_segment(ctxt, &sel, &desc, NULL,\n\t\t\t\t\t\taddr.seg);\n\t\tif (!usable)\n\t\t\tgoto bad;\n\t\t/* code segment in protected mode or read-only data segment */\n\t\tif ((((ctxt->mode != X86EMUL_MODE_REAL) && (desc.type & 8))\n\t\t\t\t\t|| !(desc.type & 2)) && write)\n\t\t\tgoto bad;\n\t\t/* unreadable code segment */\n\t\tif (!fetch && (desc.type & 8) && !(desc.type & 2))\n\t\t\tgoto bad;\n\t\tlim = desc_limit_scaled(&desc);\n\t\tif (!(desc.type & 8) && (desc.type & 4)) {\n\t\t\t/* expand-down segment */\n\t\t\tif (addr.ea <= lim)\n\t\t\t\tgoto bad;\n\t\t\tlim = desc.d ? 0xffffffff : 0xffff;\n\t\t}\n\t\tif (addr.ea > lim)\n\t\t\tgoto bad;\n\t\tif (lim == 0xffffffff)\n\t\t\t*max_size = ~0u;\n\t\telse {\n\t\t\t*max_size = (u64)lim + 1 - addr.ea;\n\t\t\tif (size > *max_size)\n\t\t\t\tgoto bad;\n\t\t}\n\t\tbreak;\n\t}\n\tif (la & (insn_alignment(ctxt, size) - 1))\n\t\treturn emulate_gp(ctxt, 0);\n\treturn X86EMUL_CONTINUE;\nbad:\n\tif (addr.seg == VCPU_SREG_SS)\n\t\treturn emulate_ss(ctxt, 0);\n\telse\n\t\treturn emulate_gp(ctxt, 0);\n}\n",
        "post_patch": "static __always_inline int __linearize(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t       struct segmented_address addr,\n\t\t\t\t       unsigned *max_size, unsigned size,\n\t\t\t\t       bool write, bool fetch,\n\t\t\t\t       enum x86emul_mode mode, ulong *linear)\n{\n\tstruct desc_struct desc;\n\tbool usable;\n\tulong la;\n\tu32 lim;\n\tu16 sel;\n\n\tla = seg_base(ctxt, addr.seg) + addr.ea;\n\t*max_size = 0;\n\tswitch (mode) {\n\tcase X86EMUL_MODE_PROT64:\n\t\t*linear = la;\n\t\tif (is_noncanonical_address(la))\n\t\t\tgoto bad;\n\n\t\t*max_size = min_t(u64, ~0u, (1ull << 48) - la);\n\t\tif (size > *max_size)\n\t\t\tgoto bad;\n\t\tbreak;\n\tdefault:\n\t\t*linear = la = (u32)la;\n\t\tusable = ctxt->ops->get_segment(ctxt, &sel, &desc, NULL,\n\t\t\t\t\t\taddr.seg);\n\t\tif (!usable)\n\t\t\tgoto bad;\n\t\t/* code segment in protected mode or read-only data segment */\n\t\tif ((((ctxt->mode != X86EMUL_MODE_REAL) && (desc.type & 8))\n\t\t\t\t\t|| !(desc.type & 2)) && write)\n\t\t\tgoto bad;\n\t\t/* unreadable code segment */\n\t\tif (!fetch && (desc.type & 8) && !(desc.type & 2))\n\t\t\tgoto bad;\n\t\tlim = desc_limit_scaled(&desc);\n\t\tif (!(desc.type & 8) && (desc.type & 4)) {\n\t\t\t/* expand-down segment */\n\t\t\tif (addr.ea <= lim)\n\t\t\t\tgoto bad;\n\t\t\tlim = desc.d ? 0xffffffff : 0xffff;\n\t\t}\n\t\tif (addr.ea > lim)\n\t\t\tgoto bad;\n\t\tif (lim == 0xffffffff)\n\t\t\t*max_size = ~0u;\n\t\telse {\n\t\t\t*max_size = (u64)lim + 1 - addr.ea;\n\t\t\tif (size > *max_size)\n\t\t\t\tgoto bad;\n\t\t}\n\t\tbreak;\n\t}\n\tif (la & (insn_alignment(ctxt, size) - 1))\n\t\treturn emulate_gp(ctxt, 0);\n\treturn X86EMUL_CONTINUE;\nbad:\n\tif (addr.seg == VCPU_SREG_SS)\n\t\treturn emulate_ss(ctxt, 0);\n\telse\n\t\treturn emulate_gp(ctxt, 0);\n}\n",
        "post_patch_with_fix": "static __always_inline int __linearize(struct x86_emulate_ctxt *ctxt,\n\t\t\t\t       struct segmented_address addr,\n\t\t\t\t       unsigned *max_size, unsigned size,\n\t\t\t\t       bool write, bool fetch,\n\t\t\t\t       enum x86emul_mode mode, ulong *linear)\n{\n\tstruct desc_struct desc;\n\tbool usable;\n\tulong la;\n\tu32 lim;\n\tu16 sel;\n\n\tla = seg_base(ctxt, addr.seg) + addr.ea;\n\t*max_size = 0;\n\tswitch (mode) {\n\tcase X86EMUL_MODE_PROT64:\n\t\t*linear = la;\n\t\tif (is_noncanonical_address(la))\n\t\t\tgoto bad;\n\n\t\t*max_size = min_t(u64, ~0u, (1ull << 48) - la);\n\t\tif (size > *max_size)\n\t\t\tgoto bad;\n\t\tbreak;\n\tdefault:\n\t\t*linear = la = (u32)la;\n\t\tusable = ctxt->ops->get_segment(ctxt, &sel, &desc, NULL,\n\t\t\t\t\t\taddr.seg);\n\t\tif (!usable)\n\t\t\tgoto bad;\n\t\t/* code segment in protected mode or read-only data segment */\n\t\tif ((((ctxt->mode != X86EMUL_MODE_REAL) && (desc.type & 8))\n\t\t\t\t\t|| !(desc.type & 2)) && write)\n\t\t\tgoto bad;\n\t\t/* unreadable code segment */\n\t\tif (!fetch && (desc.type & 8) && !(desc.type & 2))\n\t\t\tgoto bad;\n\t\tlim = desc_limit_scaled(&desc);\n\t\tif (!(desc.type & 8) && (desc.type & 4)) {\n\t\t\t/* expand-down segment */\n\t\t\tif (addr.ea <= lim)\n\t\t\t\tgoto bad;\n\t\t\tlim = desc.d ? 0xffffffff : 0xffff;\n\t\t}\n\t\tif (addr.ea > lim)\n\t\t\tgoto bad;\n\t\tif (lim == 0xffffffff)\n\t\t\t*max_size = ~0u;\n\t\telse {\n\t\t\t*max_size = (u64)lim + 1 - addr.ea;\n\t\t\tif (size > *max_size)\n\t\t\t\tgoto bad;\n\t\t}\n\t\tbreak;\n\t}\n\tif (la & (insn_alignment(ctxt, size) - 1))\n\t\treturn emulate_gp(ctxt, 0);\n\treturn X86EMUL_CONTINUE;\nbad:\n\tif (addr.seg == VCPU_SREG_SS)\n\t\treturn emulate_ss(ctxt, 0);\n\telse\n\t\treturn emulate_gp(ctxt, 0);\n}\n",
        "label": 0
    },
    {
        "pre_patch": " void RenderFrameImpl::OnSelectPopupMenuItems(\n    bool canceled,\n    const std::vector<int>& selected_indices) {\n  if (!external_popup_menu_)\n     return;\n \n   blink::WebScopedUserGesture gesture(frame_);\n  external_popup_menu_->DidSelectItems(canceled, selected_indices);\n  external_popup_menu_.reset();\n }\n",
        "post_patch": " void RenderFrameImpl::OnSelectPopupMenuItems(\n    bool canceled,\n    const std::vector<int>& selected_indices) {\n  if (!external_popup_menu_)\n     return;\n \n   blink::WebScopedUserGesture gesture(frame_);\n  // We need to reset |external_popup_menu_| before calling DidSelectItems(),\n  // which might delete |this|.\n  // See ExternalPopupMenuRemoveTest.RemoveFrameOnChange\n  std::unique_ptr<ExternalPopupMenu> popup;\n  popup.swap(external_popup_menu_);\n  popup->DidSelectItems(canceled, selected_indices);\n }\n",
        "post_patch_with_fix": " void RenderFrameImpl::OnSelectPopupMenuItems(\n    bool canceled,\n    const std::vector<int>& selected_indices) {\n  // It is possible to receive more than one of these calls if the user presses\n  // a select faster than it takes for the show-select-popup IPC message to make\n  // it to the browser UI thread. Ignore the extra-messages.\n  // TODO(jcivelli): http:/b/5793321 Implement a better fix, as detailed in bug.\n  if (!external_popup_menu_)\n     return;\n \n   blink::WebScopedUserGesture gesture(frame_);\n//flaw_line_below:\n  external_popup_menu_->DidSelectItems(canceled, selected_indices);\n//flaw_line_below:\n  external_popup_menu_.reset();\n//fix_flaw_line_below:\n//  // We need to reset |external_popup_menu_| before calling DidSelectItems(),\n//fix_flaw_line_below:\n//  // which might delete |this|.\n//fix_flaw_line_below:\n//  // See ExternalPopupMenuRemoveTest.RemoveFrameOnChange\n//fix_flaw_line_below:\n//  std::unique_ptr<ExternalPopupMenu> popup;\n//fix_flaw_line_below:\n//  popup.swap(external_popup_menu_);\n//fix_flaw_line_below:\n//  popup->DidSelectItems(canceled, selected_indices);\n }\n",
        "label": 1
    },
    {
        "pre_patch": "static __be32 nfsd4_encode_fs_locations(struct xdr_stream *xdr,\n\t\t\tstruct svc_rqst *rqstp, struct svc_export *exp)\n{\n\t__be32 status;\n\tint i;\n\t__be32 *p;\n\tstruct nfsd4_fs_locations *fslocs = &exp->ex_fslocs;\n\n\tstatus = nfsd4_encode_fsloc_fsroot(xdr, rqstp, &exp->ex_path);\n\tif (status)\n\t\treturn status;\n\tp = xdr_reserve_space(xdr, 4);\n\tif (!p)\n\t\treturn nfserr_resource;\n\t*p++ = cpu_to_be32(fslocs->locations_count);\n\tfor (i=0; i<fslocs->locations_count; i++) {\n\t\tstatus = nfsd4_encode_fs_location4(xdr, &fslocs->locations[i]);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\treturn 0;\n}\n",
        "post_patch": "static __be32 nfsd4_encode_fs_locations(struct xdr_stream *xdr,\n\t\t\tstruct svc_rqst *rqstp, struct svc_export *exp)\n{\n\t__be32 status;\n\tint i;\n\t__be32 *p;\n\tstruct nfsd4_fs_locations *fslocs = &exp->ex_fslocs;\n\n\tstatus = nfsd4_encode_fsloc_fsroot(xdr, rqstp, &exp->ex_path);\n\tif (status)\n\t\treturn status;\n\tp = xdr_reserve_space(xdr, 4);\n\tif (!p)\n\t\treturn nfserr_resource;\n\t*p++ = cpu_to_be32(fslocs->locations_count);\n\tfor (i=0; i<fslocs->locations_count; i++) {\n\t\tstatus = nfsd4_encode_fs_location4(xdr, &fslocs->locations[i]);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\treturn 0;\n}\n",
        "post_patch_with_fix": "static __be32 nfsd4_encode_fs_locations(struct xdr_stream *xdr,\n\t\t\tstruct svc_rqst *rqstp, struct svc_export *exp)\n{\n\t__be32 status;\n\tint i;\n\t__be32 *p;\n\tstruct nfsd4_fs_locations *fslocs = &exp->ex_fslocs;\n\n\tstatus = nfsd4_encode_fsloc_fsroot(xdr, rqstp, &exp->ex_path);\n\tif (status)\n\t\treturn status;\n\tp = xdr_reserve_space(xdr, 4);\n\tif (!p)\n\t\treturn nfserr_resource;\n\t*p++ = cpu_to_be32(fslocs->locations_count);\n\tfor (i=0; i<fslocs->locations_count; i++) {\n\t\tstatus = nfsd4_encode_fs_location4(xdr, &fslocs->locations[i]);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\treturn 0;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int link_pipe(struct pipe_inode_info *ipipe,\n\t\t     struct pipe_inode_info *opipe,\n\t\t     size_t len, unsigned int flags)\n{\n\tstruct pipe_buffer *ibuf, *obuf;\n\tint ret = 0, i = 0, nbuf;\n\n\t/*\n\t * Potential ABBA deadlock, work around it by ordering lock\n\t * grabbing by pipe info address. Otherwise two different processes\n\t * could deadlock (one doing tee from A -> B, the other from B -> A).\n\t */\n\tpipe_double_lock(ipipe, opipe);\n\n\tdo {\n\t\tif (!opipe->readers) {\n\t\t\tsend_sig(SIGPIPE, current, 0);\n\t\t\tif (!ret)\n\t\t\t\tret = -EPIPE;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * If we have iterated all input buffers or ran out of\n\t\t * output room, break.\n\t\t */\n\t\tif (i >= ipipe->nrbufs || opipe->nrbufs >= opipe->buffers)\n\t\t\tbreak;\n\n\t\tibuf = ipipe->bufs + ((ipipe->curbuf + i) & (ipipe->buffers-1));\n\t\tnbuf = (opipe->curbuf + opipe->nrbufs) & (opipe->buffers - 1);\n\n\t\t/*\n \t\t * Get a reference to this pipe buffer,\n \t\t * so we can copy the contents over.\n \t\t */\n\t\tpipe_buf_get(ipipe, ibuf);\n \n \t\tobuf = opipe->bufs + nbuf;\n \t\t*obuf = *ibuf;\n\n\t\t/*\n\t\t * Don't inherit the gift flag, we need to\n\t\t * prevent multiple steals of this page.\n\t\t */\n\t\tobuf->flags &= ~PIPE_BUF_FLAG_GIFT;\n\n\t\tpipe_buf_mark_unmergeable(obuf);\n\n\t\tif (obuf->len > len)\n\t\t\tobuf->len = len;\n\n\t\topipe->nrbufs++;\n\t\tret += obuf->len;\n\t\tlen -= obuf->len;\n\t\ti++;\n\t} while (len);\n\n\t/*\n\t * return EAGAIN if we have the potential of some data in the\n\t * future, otherwise just return 0\n\t */\n\tif (!ret && ipipe->waiting_writers && (flags & SPLICE_F_NONBLOCK))\n\t\tret = -EAGAIN;\n\n\tpipe_unlock(ipipe);\n\tpipe_unlock(opipe);\n\n\t/*\n\t * If we put data in the output pipe, wakeup any potential readers.\n\t */\n\tif (ret > 0)\n\t\twakeup_pipe_readers(opipe);\n\n\treturn ret;\n}\n",
        "post_patch": "static int link_pipe(struct pipe_inode_info *ipipe,\n\t\t     struct pipe_inode_info *opipe,\n\t\t     size_t len, unsigned int flags)\n{\n\tstruct pipe_buffer *ibuf, *obuf;\n\tint ret = 0, i = 0, nbuf;\n\n\t/*\n\t * Potential ABBA deadlock, work around it by ordering lock\n\t * grabbing by pipe info address. Otherwise two different processes\n\t * could deadlock (one doing tee from A -> B, the other from B -> A).\n\t */\n\tpipe_double_lock(ipipe, opipe);\n\n\tdo {\n\t\tif (!opipe->readers) {\n\t\t\tsend_sig(SIGPIPE, current, 0);\n\t\t\tif (!ret)\n\t\t\t\tret = -EPIPE;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * If we have iterated all input buffers or ran out of\n\t\t * output room, break.\n\t\t */\n\t\tif (i >= ipipe->nrbufs || opipe->nrbufs >= opipe->buffers)\n\t\t\tbreak;\n\n\t\tibuf = ipipe->bufs + ((ipipe->curbuf + i) & (ipipe->buffers-1));\n\t\tnbuf = (opipe->curbuf + opipe->nrbufs) & (opipe->buffers - 1);\n\n\t\t/*\n \t\t * Get a reference to this pipe buffer,\n \t\t * so we can copy the contents over.\n \t\t */\n\t\tif (!pipe_buf_get(ipipe, ibuf)) {\n\t\t\tif (ret == 0)\n\t\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n \n \t\tobuf = opipe->bufs + nbuf;\n \t\t*obuf = *ibuf;\n\n\t\t/*\n\t\t * Don't inherit the gift flag, we need to\n\t\t * prevent multiple steals of this page.\n\t\t */\n\t\tobuf->flags &= ~PIPE_BUF_FLAG_GIFT;\n\n\t\tpipe_buf_mark_unmergeable(obuf);\n\n\t\tif (obuf->len > len)\n\t\t\tobuf->len = len;\n\n\t\topipe->nrbufs++;\n\t\tret += obuf->len;\n\t\tlen -= obuf->len;\n\t\ti++;\n\t} while (len);\n\n\t/*\n\t * return EAGAIN if we have the potential of some data in the\n\t * future, otherwise just return 0\n\t */\n\tif (!ret && ipipe->waiting_writers && (flags & SPLICE_F_NONBLOCK))\n\t\tret = -EAGAIN;\n\n\tpipe_unlock(ipipe);\n\tpipe_unlock(opipe);\n\n\t/*\n\t * If we put data in the output pipe, wakeup any potential readers.\n\t */\n\tif (ret > 0)\n\t\twakeup_pipe_readers(opipe);\n\n\treturn ret;\n}\n",
        "post_patch_with_fix": "static int link_pipe(struct pipe_inode_info *ipipe,\n\t\t     struct pipe_inode_info *opipe,\n\t\t     size_t len, unsigned int flags)\n{\n\tstruct pipe_buffer *ibuf, *obuf;\n\tint ret = 0, i = 0, nbuf;\n\n\t/*\n\t * Potential ABBA deadlock, work around it by ordering lock\n\t * grabbing by pipe info address. Otherwise two different processes\n\t * could deadlock (one doing tee from A -> B, the other from B -> A).\n\t */\n\tpipe_double_lock(ipipe, opipe);\n\n\tdo {\n\t\tif (!opipe->readers) {\n\t\t\tsend_sig(SIGPIPE, current, 0);\n\t\t\tif (!ret)\n\t\t\t\tret = -EPIPE;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * If we have iterated all input buffers or ran out of\n\t\t * output room, break.\n\t\t */\n\t\tif (i >= ipipe->nrbufs || opipe->nrbufs >= opipe->buffers)\n\t\t\tbreak;\n\n\t\tibuf = ipipe->bufs + ((ipipe->curbuf + i) & (ipipe->buffers-1));\n\t\tnbuf = (opipe->curbuf + opipe->nrbufs) & (opipe->buffers - 1);\n\n\t\t/*\n \t\t * Get a reference to this pipe buffer,\n \t\t * so we can copy the contents over.\n \t\t */\n//flaw_line_below:\n\t\tpipe_buf_get(ipipe, ibuf);\n//fix_flaw_line_below:\n//\t\tif (!pipe_buf_get(ipipe, ibuf)) {\n//fix_flaw_line_below:\n//\t\t\tif (ret == 0)\n//fix_flaw_line_below:\n//\t\t\t\tret = -EFAULT;\n//fix_flaw_line_below:\n//\t\t\tbreak;\n//fix_flaw_line_below:\n//\t\t}\n \n \t\tobuf = opipe->bufs + nbuf;\n \t\t*obuf = *ibuf;\n\n\t\t/*\n\t\t * Don't inherit the gift flag, we need to\n\t\t * prevent multiple steals of this page.\n\t\t */\n\t\tobuf->flags &= ~PIPE_BUF_FLAG_GIFT;\n\n\t\tpipe_buf_mark_unmergeable(obuf);\n\n\t\tif (obuf->len > len)\n\t\t\tobuf->len = len;\n\n\t\topipe->nrbufs++;\n\t\tret += obuf->len;\n\t\tlen -= obuf->len;\n\t\ti++;\n\t} while (len);\n\n\t/*\n\t * return EAGAIN if we have the potential of some data in the\n\t * future, otherwise just return 0\n\t */\n\tif (!ret && ipipe->waiting_writers && (flags & SPLICE_F_NONBLOCK))\n\t\tret = -EAGAIN;\n\n\tpipe_unlock(ipipe);\n\tpipe_unlock(opipe);\n\n\t/*\n\t * If we put data in the output pipe, wakeup any potential readers.\n\t */\n\tif (ret > 0)\n\t\twakeup_pipe_readers(opipe);\n\n\treturn ret;\n}\n",
        "label": 1
    },
    {
        "pre_patch": "int sm_looptest_inject_packets_each_sweep(p_fm_config_conx_hdlt hdl, fm_mgr_type_t mgr, int argc, char *argv[]) {\n\tfm_mgr_config_errno_t\tres;\n\tfm_msg_ret_code_t\t\tret_code;\n\tint\t\t\t\t\t\tinject=1;\n\tuint8_t                 data[BUF_SZ];\n\n\tif (argc > 1) {\n\t\tprintf(\"Error: only 1 argument expected\\n\");\n\t\treturn 0;\n\t}\n\tif (argc == 1) {\n\t\tinject = atol(argv[0]);\n\t}\n\t*(int*)data = inject;\n\tif((res = fm_mgr_simple_query(hdl, FM_ACT_GET, FM_DT_SM_LOOP_TEST_INJECT_EACH_SWEEP, mgr, \n\t\t\t\t\t\t\t\t  BUF_SZ, data, &ret_code)) != FM_CONF_OK)\n\t{\n\t\tfprintf(stderr, \"sm_looptest_inject_packets_each_sweep: Failed to retrieve data: \\n\"\n\t\t\t   \"\\tError:(%d) %s \\n\\tRet code:(%d) %s\\n\",\n\t\t\t   res, fm_mgr_get_error_str(res),ret_code,\n\t\t\t   fm_mgr_get_resp_error_str(ret_code));\n\t} else {\n\t\tprintf(\"Successfully sent Loop Test Inject Packet Each Sweep %d control to local SM instance\\n\", inject);\n\t\tdata[BUF_SZ-1]=0;\n\t\tprintf(\"%s\", (char*) data);\n\t}\n\treturn 0;\n}\n",
        "post_patch": "int sm_looptest_inject_packets_each_sweep(p_fm_config_conx_hdlt hdl, fm_mgr_type_t mgr, int argc, char *argv[]) {\n\tfm_mgr_config_errno_t\tres;\n\tfm_msg_ret_code_t\t\tret_code;\n\tint\t\t\t\t\t\tinject=1;\n\tuint8_t                 data[BUF_SZ];\n\n\tif (argc > 1) {\n\t\tprintf(\"Error: only 1 argument expected\\n\");\n\t\treturn 0;\n\t}\n\tif (argc == 1) {\n\t\tinject = atol(argv[0]);\n\t}\n\t*(int*)data = inject;\n\tif((res = fm_mgr_simple_query(hdl, FM_ACT_GET, FM_DT_SM_LOOP_TEST_INJECT_EACH_SWEEP, mgr, \n\t\t\t\t\t\t\t\t  BUF_SZ, data, &ret_code)) != FM_CONF_OK)\n\t{\n\t\tfprintf(stderr, \"sm_looptest_inject_packets_each_sweep: Failed to retrieve data: \\n\"\n\t\t\t   \"\\tError:(%d) %s \\n\\tRet code:(%d) %s\\n\",\n\t\t\t   res, fm_mgr_get_error_str(res),ret_code,\n\t\t\t   fm_mgr_get_resp_error_str(ret_code));\n\t} else {\n\t\tprintf(\"Successfully sent Loop Test Inject Packet Each Sweep %d control to local SM instance\\n\", inject);\n\t\tdata[BUF_SZ-1]=0;\n\t\tprintf(\"%s\", (char*) data);\n\t}\n\treturn 0;\n}\n",
        "post_patch_with_fix": "int sm_looptest_inject_packets_each_sweep(p_fm_config_conx_hdlt hdl, fm_mgr_type_t mgr, int argc, char *argv[]) {\n\tfm_mgr_config_errno_t\tres;\n\tfm_msg_ret_code_t\t\tret_code;\n\tint\t\t\t\t\t\tinject=1;\n\tuint8_t                 data[BUF_SZ];\n\n\tif (argc > 1) {\n\t\tprintf(\"Error: only 1 argument expected\\n\");\n\t\treturn 0;\n\t}\n\tif (argc == 1) {\n\t\tinject = atol(argv[0]);\n\t}\n\t*(int*)data = inject;\n\tif((res = fm_mgr_simple_query(hdl, FM_ACT_GET, FM_DT_SM_LOOP_TEST_INJECT_EACH_SWEEP, mgr, \n\t\t\t\t\t\t\t\t  BUF_SZ, data, &ret_code)) != FM_CONF_OK)\n\t{\n\t\tfprintf(stderr, \"sm_looptest_inject_packets_each_sweep: Failed to retrieve data: \\n\"\n\t\t\t   \"\\tError:(%d) %s \\n\\tRet code:(%d) %s\\n\",\n\t\t\t   res, fm_mgr_get_error_str(res),ret_code,\n\t\t\t   fm_mgr_get_resp_error_str(ret_code));\n\t} else {\n\t\tprintf(\"Successfully sent Loop Test Inject Packet Each Sweep %d control to local SM instance\\n\", inject);\n\t\tdata[BUF_SZ-1]=0;\n\t\tprintf(\"%s\", (char*) data);\n\t}\n\treturn 0;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "ofputil_decode_table_desc(struct ofpbuf *msg,\n                          struct ofputil_table_desc *td,\n                          enum ofp_version version)\n{\n    memset(td, 0, sizeof *td);\n\n    if (!msg->header) {\n        ofpraw_pull_assert(msg);\n    }\n\n    if (!msg->size) {\n        return EOF;\n    }\n\n    struct ofp14_table_desc *otd = ofpbuf_try_pull(msg, sizeof *otd);\n    if (!otd) {\n        VLOG_WARN_RL(&bad_ofmsg_rl, \"OFP14_TABLE_DESC reply has %\"PRIu32\" \"\n                     \"leftover bytes at end\", msg->size);\n        return OFPERR_OFPBRC_BAD_LEN;\n    }\n\n    td->table_id = otd->table_id;\n    size_t length = ntohs(otd->length);\n    if (length < sizeof *otd || length - sizeof *otd > msg->size) {\n        VLOG_WARN_RL(&bad_ofmsg_rl, \"OFP14_TABLE_DESC reply claims invalid \"\n                     \"length %\"PRIuSIZE, length);\n        return OFPERR_OFPBRC_BAD_LEN;\n    }\n    length -= sizeof *otd;\n\n    td->eviction = ofputil_decode_table_eviction(otd->config, version);\n    td->vacancy = ofputil_decode_table_vacancy(otd->config, version);\n    td->eviction_flags = UINT32_MAX;\n\n    struct ofpbuf properties = ofpbuf_const_initializer(\n        ofpbuf_pull(msg, length), length);\n    while (properties.size > 0) {\n        struct ofpbuf payload;\n        enum ofperr error;\n        uint64_t type;\n\n        error = ofpprop_pull(&properties, &payload, &type);\n        if (error) {\n            return error;\n        }\n\n        switch (type) {\n        case OFPTMPT14_EVICTION:\n            error = ofpprop_parse_u32(&payload, &td->eviction_flags);\n            break;\n\n        case OFPTMPT14_VACANCY:\n            error = parse_table_desc_vacancy_property(&payload, td);\n            break;\n\n        default:\n            error = OFPPROP_UNKNOWN(true, \"table_desc\", type);\n            break;\n        }\n\n        if (error) {\n            return error;\n        }\n    }\n\n    return 0;\n}\n",
        "post_patch": "ofputil_decode_table_desc(struct ofpbuf *msg,\n                          struct ofputil_table_desc *td,\n                          enum ofp_version version)\n{\n    memset(td, 0, sizeof *td);\n\n    if (!msg->header) {\n        ofpraw_pull_assert(msg);\n    }\n\n    if (!msg->size) {\n        return EOF;\n    }\n\n    struct ofp14_table_desc *otd = ofpbuf_try_pull(msg, sizeof *otd);\n    if (!otd) {\n        VLOG_WARN_RL(&bad_ofmsg_rl, \"OFP14_TABLE_DESC reply has %\"PRIu32\" \"\n                     \"leftover bytes at end\", msg->size);\n        return OFPERR_OFPBRC_BAD_LEN;\n    }\n\n    td->table_id = otd->table_id;\n    size_t length = ntohs(otd->length);\n    if (length < sizeof *otd || length - sizeof *otd > msg->size) {\n        VLOG_WARN_RL(&bad_ofmsg_rl, \"OFP14_TABLE_DESC reply claims invalid \"\n                     \"length %\"PRIuSIZE, length);\n        return OFPERR_OFPBRC_BAD_LEN;\n    }\n    length -= sizeof *otd;\n\n    td->eviction = ofputil_decode_table_eviction(otd->config, version);\n    td->vacancy = ofputil_decode_table_vacancy(otd->config, version);\n    td->eviction_flags = UINT32_MAX;\n\n    struct ofpbuf properties = ofpbuf_const_initializer(\n        ofpbuf_pull(msg, length), length);\n    while (properties.size > 0) {\n        struct ofpbuf payload;\n        enum ofperr error;\n        uint64_t type;\n\n        error = ofpprop_pull(&properties, &payload, &type);\n        if (error) {\n            return error;\n        }\n\n        switch (type) {\n        case OFPTMPT14_EVICTION:\n            error = ofpprop_parse_u32(&payload, &td->eviction_flags);\n            break;\n\n        case OFPTMPT14_VACANCY:\n            error = parse_table_desc_vacancy_property(&payload, td);\n            break;\n\n        default:\n            error = OFPPROP_UNKNOWN(true, \"table_desc\", type);\n            break;\n        }\n\n        if (error) {\n            return error;\n        }\n    }\n\n    return 0;\n}\n",
        "post_patch_with_fix": "ofputil_decode_table_desc(struct ofpbuf *msg,\n                          struct ofputil_table_desc *td,\n                          enum ofp_version version)\n{\n    memset(td, 0, sizeof *td);\n\n    if (!msg->header) {\n        ofpraw_pull_assert(msg);\n    }\n\n    if (!msg->size) {\n        return EOF;\n    }\n\n    struct ofp14_table_desc *otd = ofpbuf_try_pull(msg, sizeof *otd);\n    if (!otd) {\n        VLOG_WARN_RL(&bad_ofmsg_rl, \"OFP14_TABLE_DESC reply has %\"PRIu32\" \"\n                     \"leftover bytes at end\", msg->size);\n        return OFPERR_OFPBRC_BAD_LEN;\n    }\n\n    td->table_id = otd->table_id;\n    size_t length = ntohs(otd->length);\n    if (length < sizeof *otd || length - sizeof *otd > msg->size) {\n        VLOG_WARN_RL(&bad_ofmsg_rl, \"OFP14_TABLE_DESC reply claims invalid \"\n                     \"length %\"PRIuSIZE, length);\n        return OFPERR_OFPBRC_BAD_LEN;\n    }\n    length -= sizeof *otd;\n\n    td->eviction = ofputil_decode_table_eviction(otd->config, version);\n    td->vacancy = ofputil_decode_table_vacancy(otd->config, version);\n    td->eviction_flags = UINT32_MAX;\n\n    struct ofpbuf properties = ofpbuf_const_initializer(\n        ofpbuf_pull(msg, length), length);\n    while (properties.size > 0) {\n        struct ofpbuf payload;\n        enum ofperr error;\n        uint64_t type;\n\n        error = ofpprop_pull(&properties, &payload, &type);\n        if (error) {\n            return error;\n        }\n\n        switch (type) {\n        case OFPTMPT14_EVICTION:\n            error = ofpprop_parse_u32(&payload, &td->eviction_flags);\n            break;\n\n        case OFPTMPT14_VACANCY:\n            error = parse_table_desc_vacancy_property(&payload, td);\n            break;\n\n        default:\n            error = OFPPROP_UNKNOWN(true, \"table_desc\", type);\n            break;\n        }\n\n        if (error) {\n            return error;\n        }\n    }\n\n    return 0;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int mxf_match_uid(const UID key, const UID uid, int len)\n{\n    int i;\n    for (i = 0; i < len; i++) {\n        if (i != 7 && key[i] != uid[i])\n            return 0;\n    }\n    return 1;\n}\n",
        "post_patch": "static int mxf_match_uid(const UID key, const UID uid, int len)\n{\n    int i;\n    for (i = 0; i < len; i++) {\n        if (i != 7 && key[i] != uid[i])\n            return 0;\n    }\n    return 1;\n}\n",
        "post_patch_with_fix": "static int mxf_match_uid(const UID key, const UID uid, int len)\n{\n    int i;\n    for (i = 0; i < len; i++) {\n        if (i != 7 && key[i] != uid[i])\n            return 0;\n    }\n    return 1;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "ofputil_encode_table_mod(const struct ofputil_table_mod *tm,\n                        enum ofputil_protocol protocol)\n{\n    enum ofp_version ofp_version = ofputil_protocol_to_ofp_version(protocol);\n    struct ofpbuf *b;\n\n    switch (ofp_version) {\n    case OFP10_VERSION: {\n        ovs_fatal(0, \"table mod needs OpenFlow 1.1 or later \"\n                     \"(\\'-O OpenFlow11\\')\");\n        break;\n    }\n    case OFP11_VERSION:\n    case OFP12_VERSION:\n    case OFP13_VERSION: {\n        struct ofp11_table_mod *otm;\n\n        b = ofpraw_alloc(OFPRAW_OFPT11_TABLE_MOD, ofp_version, 0);\n        otm = ofpbuf_put_zeros(b, sizeof *otm);\n        otm->table_id = tm->table_id;\n        otm->config = ofputil_encode_table_config(tm->miss, tm->eviction,\n                                                  tm->vacancy, ofp_version);\n        break;\n    }\n    case OFP14_VERSION:\n    case OFP15_VERSION:\n    case OFP16_VERSION: {\n        struct ofp14_table_mod *otm;\n\n        b = ofpraw_alloc(OFPRAW_OFPT14_TABLE_MOD, ofp_version, 0);\n        otm = ofpbuf_put_zeros(b, sizeof *otm);\n        otm->table_id = tm->table_id;\n        otm->config = ofputil_encode_table_config(tm->miss, tm->eviction,\n                                                  tm->vacancy, ofp_version);\n\n        if (tm->eviction_flags != UINT32_MAX) {\n            ofpprop_put_u32(b, OFPTMPT14_EVICTION, tm->eviction_flags);\n        }\n        if (tm->vacancy == OFPUTIL_TABLE_VACANCY_ON) {\n            struct ofp14_table_mod_prop_vacancy *otv;\n\n            otv = ofpprop_put_zeros(b, OFPTMPT14_VACANCY, sizeof *otv);\n            otv->vacancy_down = tm->table_vacancy.vacancy_down;\n            otv->vacancy_up = tm->table_vacancy.vacancy_up;\n        }\n        break;\n    }\n    default:\n        OVS_NOT_REACHED();\n    }\n\n    return b;\n}\n",
        "post_patch": "ofputil_encode_table_mod(const struct ofputil_table_mod *tm,\n                        enum ofputil_protocol protocol)\n{\n    enum ofp_version ofp_version = ofputil_protocol_to_ofp_version(protocol);\n    struct ofpbuf *b;\n\n    switch (ofp_version) {\n    case OFP10_VERSION: {\n        ovs_fatal(0, \"table mod needs OpenFlow 1.1 or later \"\n                     \"(\\'-O OpenFlow11\\')\");\n        break;\n    }\n    case OFP11_VERSION:\n    case OFP12_VERSION:\n    case OFP13_VERSION: {\n        struct ofp11_table_mod *otm;\n\n        b = ofpraw_alloc(OFPRAW_OFPT11_TABLE_MOD, ofp_version, 0);\n        otm = ofpbuf_put_zeros(b, sizeof *otm);\n        otm->table_id = tm->table_id;\n        otm->config = ofputil_encode_table_config(tm->miss, tm->eviction,\n                                                  tm->vacancy, ofp_version);\n        break;\n    }\n    case OFP14_VERSION:\n    case OFP15_VERSION:\n    case OFP16_VERSION: {\n        struct ofp14_table_mod *otm;\n\n        b = ofpraw_alloc(OFPRAW_OFPT14_TABLE_MOD, ofp_version, 0);\n        otm = ofpbuf_put_zeros(b, sizeof *otm);\n        otm->table_id = tm->table_id;\n        otm->config = ofputil_encode_table_config(tm->miss, tm->eviction,\n                                                  tm->vacancy, ofp_version);\n\n        if (tm->eviction_flags != UINT32_MAX) {\n            ofpprop_put_u32(b, OFPTMPT14_EVICTION, tm->eviction_flags);\n        }\n        if (tm->vacancy == OFPUTIL_TABLE_VACANCY_ON) {\n            struct ofp14_table_mod_prop_vacancy *otv;\n\n            otv = ofpprop_put_zeros(b, OFPTMPT14_VACANCY, sizeof *otv);\n            otv->vacancy_down = tm->table_vacancy.vacancy_down;\n            otv->vacancy_up = tm->table_vacancy.vacancy_up;\n        }\n        break;\n    }\n    default:\n        OVS_NOT_REACHED();\n    }\n\n    return b;\n}\n",
        "post_patch_with_fix": "ofputil_encode_table_mod(const struct ofputil_table_mod *tm,\n                        enum ofputil_protocol protocol)\n{\n    enum ofp_version ofp_version = ofputil_protocol_to_ofp_version(protocol);\n    struct ofpbuf *b;\n\n    switch (ofp_version) {\n    case OFP10_VERSION: {\n        ovs_fatal(0, \"table mod needs OpenFlow 1.1 or later \"\n                     \"(\\'-O OpenFlow11\\')\");\n        break;\n    }\n    case OFP11_VERSION:\n    case OFP12_VERSION:\n    case OFP13_VERSION: {\n        struct ofp11_table_mod *otm;\n\n        b = ofpraw_alloc(OFPRAW_OFPT11_TABLE_MOD, ofp_version, 0);\n        otm = ofpbuf_put_zeros(b, sizeof *otm);\n        otm->table_id = tm->table_id;\n        otm->config = ofputil_encode_table_config(tm->miss, tm->eviction,\n                                                  tm->vacancy, ofp_version);\n        break;\n    }\n    case OFP14_VERSION:\n    case OFP15_VERSION:\n    case OFP16_VERSION: {\n        struct ofp14_table_mod *otm;\n\n        b = ofpraw_alloc(OFPRAW_OFPT14_TABLE_MOD, ofp_version, 0);\n        otm = ofpbuf_put_zeros(b, sizeof *otm);\n        otm->table_id = tm->table_id;\n        otm->config = ofputil_encode_table_config(tm->miss, tm->eviction,\n                                                  tm->vacancy, ofp_version);\n\n        if (tm->eviction_flags != UINT32_MAX) {\n            ofpprop_put_u32(b, OFPTMPT14_EVICTION, tm->eviction_flags);\n        }\n        if (tm->vacancy == OFPUTIL_TABLE_VACANCY_ON) {\n            struct ofp14_table_mod_prop_vacancy *otv;\n\n            otv = ofpprop_put_zeros(b, OFPTMPT14_VACANCY, sizeof *otv);\n            otv->vacancy_down = tm->table_vacancy.vacancy_down;\n            otv->vacancy_up = tm->table_vacancy.vacancy_up;\n        }\n        break;\n    }\n    default:\n        OVS_NOT_REACHED();\n    }\n\n    return b;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "int GetIPv4AddressFromIndex(int socket, uint32 index, uint32* address){\n  if (!index) {\n    *address = htonl(INADDR_ANY);\n    return OK;\n  }\n  ifreq ifr;\n  ifr.ifr_addr.sa_family = AF_INET;\n  if (!if_indextoname(index, ifr.ifr_name))\n    return ERR_FAILED;\n  int rv = ioctl(socket, SIOCGIFADDR, &ifr);\n  if (!rv)\n    return MapSystemError(rv);\n  *address = reinterpret_cast<sockaddr_in*>(&ifr.ifr_addr)->sin_addr.s_addr;\n  return OK;\n}\n",
        "post_patch": "int GetIPv4AddressFromIndex(int socket, uint32 index, uint32* address){\n  if (!index) {\n    *address = htonl(INADDR_ANY);\n    return OK;\n  }\n  ifreq ifr;\n  ifr.ifr_addr.sa_family = AF_INET;\n  if (!if_indextoname(index, ifr.ifr_name))\n    return ERR_FAILED;\n  int rv = ioctl(socket, SIOCGIFADDR, &ifr);\n  if (!rv)\n    return MapSystemError(rv);\n  *address = reinterpret_cast<sockaddr_in*>(&ifr.ifr_addr)->sin_addr.s_addr;\n  return OK;\n}\n",
        "post_patch_with_fix": "int GetIPv4AddressFromIndex(int socket, uint32 index, uint32* address){\n  if (!index) {\n    *address = htonl(INADDR_ANY);\n    return OK;\n  }\n  ifreq ifr;\n  ifr.ifr_addr.sa_family = AF_INET;\n  if (!if_indextoname(index, ifr.ifr_name))\n    return ERR_FAILED;\n  int rv = ioctl(socket, SIOCGIFADDR, &ifr);\n  if (!rv)\n    return MapSystemError(rv);\n  *address = reinterpret_cast<sockaddr_in*>(&ifr.ifr_addr)->sin_addr.s_addr;\n  return OK;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "setup_quant(Node* node, regex_t* reg, int state, ScanEnv* env)\n{\n  int r;\n  OnigLen d;\n  QuantNode* qn = QUANT_(node);\n  Node* body = NODE_BODY(node);\n\n  if ((state & IN_REAL_REPEAT) != 0) {\n    NODE_STATUS_ADD(node, IN_REAL_REPEAT);\n  }\n  if ((state & IN_MULTI_ENTRY) != 0) {\n    NODE_STATUS_ADD(node, IN_MULTI_ENTRY);\n  }\n\n  if (IS_REPEAT_INFINITE(qn->upper) || qn->upper >= 1) {\n    d = tree_min_len(body, env);\n    if (d == 0) {\n#ifdef USE_INSISTENT_CHECK_CAPTURES_IN_EMPTY_REPEAT\n      qn->empty_info = quantifiers_memory_node_info(body);\n      if (qn->empty_info == BODY_IS_EMPTY_REC) {\n        if (NODE_TYPE(body) == NODE_BAG &&\n            BAG_(body)->type == BAG_MEMORY) {\n          MEM_STATUS_ON(env->bt_mem_end, BAG_(body)->m.regnum);\n        }\n      }\n#else\n      qn->empty_info = BODY_IS_EMPTY;\n#endif\n    }\n  }\n\n  if (IS_REPEAT_INFINITE(qn->upper) || qn->upper >= 2)\n    state |= IN_REAL_REPEAT;\n  if (qn->lower != qn->upper)\n    state |= IN_VAR_REPEAT;\n\n  r = setup_tree(body, reg, state, env);\n  if (r != 0) return r;\n\n  /* expand string */\n#define EXPAND_STRING_MAX_LENGTH  100\n  if (NODE_TYPE(body) == NODE_STRING) {\n    if (!IS_REPEAT_INFINITE(qn->lower) && qn->lower == qn->upper &&\n        qn->lower > 1 && qn->lower <= EXPAND_STRING_MAX_LENGTH) {\n      int len = NODE_STRING_LEN(body);\n      StrNode* sn = STR_(body);\n\n      if (len * qn->lower <= EXPAND_STRING_MAX_LENGTH) {\n        int i, n = qn->lower;\n        onig_node_conv_to_str_node(node, STR_(body)->flag);\n        for (i = 0; i < n; i++) {\n          r = onig_node_str_cat(node, sn->s, sn->end);\n          if (r != 0) return r;\n        }\n        onig_node_free(body);\n        return r;\n      }\n    }\n  }\n\n  if (qn->greedy && (qn->empty_info == BODY_IS_NOT_EMPTY)) {\n    if (NODE_TYPE(body) == NODE_QUANT) {\n      QuantNode* tqn = QUANT_(body);\n      if (IS_NOT_NULL(tqn->head_exact)) {\n        qn->head_exact  = tqn->head_exact;\n        tqn->head_exact = NULL;\n      }\n    }\n    else {\n      qn->head_exact = get_head_value_node(NODE_BODY(node), 1, reg);\n    }\n  }\n\n  return r;\n}\n",
        "post_patch": "setup_quant(Node* node, regex_t* reg, int state, ScanEnv* env)\n{\n  int r;\n  OnigLen d;\n  QuantNode* qn = QUANT_(node);\n  Node* body = NODE_BODY(node);\n\n  if ((state & IN_REAL_REPEAT) != 0) {\n    NODE_STATUS_ADD(node, IN_REAL_REPEAT);\n  }\n  if ((state & IN_MULTI_ENTRY) != 0) {\n    NODE_STATUS_ADD(node, IN_MULTI_ENTRY);\n  }\n\n  if (IS_REPEAT_INFINITE(qn->upper) || qn->upper >= 1) {\n    d = tree_min_len(body, env);\n    if (d == 0) {\n#ifdef USE_INSISTENT_CHECK_CAPTURES_IN_EMPTY_REPEAT\n      qn->empty_info = quantifiers_memory_node_info(body);\n      if (qn->empty_info == BODY_IS_EMPTY_REC) {\n        if (NODE_TYPE(body) == NODE_BAG &&\n            BAG_(body)->type == BAG_MEMORY) {\n          MEM_STATUS_ON(env->bt_mem_end, BAG_(body)->m.regnum);\n        }\n      }\n#else\n      qn->empty_info = BODY_IS_EMPTY;\n#endif\n    }\n  }\n\n  if (IS_REPEAT_INFINITE(qn->upper) || qn->upper >= 2)\n    state |= IN_REAL_REPEAT;\n  if (qn->lower != qn->upper)\n    state |= IN_VAR_REPEAT;\n\n  r = setup_tree(body, reg, state, env);\n  if (r != 0) return r;\n\n  /* expand string */\n#define EXPAND_STRING_MAX_LENGTH  100\n  if (NODE_TYPE(body) == NODE_STRING) {\n    if (!IS_REPEAT_INFINITE(qn->lower) && qn->lower == qn->upper &&\n        qn->lower > 1 && qn->lower <= EXPAND_STRING_MAX_LENGTH) {\n      int len = NODE_STRING_LEN(body);\n      StrNode* sn = STR_(body);\n\n      if (len * qn->lower <= EXPAND_STRING_MAX_LENGTH) {\n        int i, n = qn->lower;\n        onig_node_conv_to_str_node(node, STR_(body)->flag);\n        for (i = 0; i < n; i++) {\n          r = onig_node_str_cat(node, sn->s, sn->end);\n          if (r != 0) return r;\n        }\n        onig_node_free(body);\n        return r;\n      }\n    }\n  }\n\n  if (qn->greedy && (qn->empty_info == BODY_IS_NOT_EMPTY)) {\n    if (NODE_TYPE(body) == NODE_QUANT) {\n      QuantNode* tqn = QUANT_(body);\n      if (IS_NOT_NULL(tqn->head_exact)) {\n        qn->head_exact  = tqn->head_exact;\n        tqn->head_exact = NULL;\n      }\n    }\n    else {\n      qn->head_exact = get_head_value_node(NODE_BODY(node), 1, reg);\n    }\n  }\n\n  return r;\n}\n",
        "post_patch_with_fix": "setup_quant(Node* node, regex_t* reg, int state, ScanEnv* env)\n{\n  int r;\n  OnigLen d;\n  QuantNode* qn = QUANT_(node);\n  Node* body = NODE_BODY(node);\n\n  if ((state & IN_REAL_REPEAT) != 0) {\n    NODE_STATUS_ADD(node, IN_REAL_REPEAT);\n  }\n  if ((state & IN_MULTI_ENTRY) != 0) {\n    NODE_STATUS_ADD(node, IN_MULTI_ENTRY);\n  }\n\n  if (IS_REPEAT_INFINITE(qn->upper) || qn->upper >= 1) {\n    d = tree_min_len(body, env);\n    if (d == 0) {\n#ifdef USE_INSISTENT_CHECK_CAPTURES_IN_EMPTY_REPEAT\n      qn->empty_info = quantifiers_memory_node_info(body);\n      if (qn->empty_info == BODY_IS_EMPTY_REC) {\n        if (NODE_TYPE(body) == NODE_BAG &&\n            BAG_(body)->type == BAG_MEMORY) {\n          MEM_STATUS_ON(env->bt_mem_end, BAG_(body)->m.regnum);\n        }\n      }\n#else\n      qn->empty_info = BODY_IS_EMPTY;\n#endif\n    }\n  }\n\n  if (IS_REPEAT_INFINITE(qn->upper) || qn->upper >= 2)\n    state |= IN_REAL_REPEAT;\n  if (qn->lower != qn->upper)\n    state |= IN_VAR_REPEAT;\n\n  r = setup_tree(body, reg, state, env);\n  if (r != 0) return r;\n\n  /* expand string */\n#define EXPAND_STRING_MAX_LENGTH  100\n  if (NODE_TYPE(body) == NODE_STRING) {\n    if (!IS_REPEAT_INFINITE(qn->lower) && qn->lower == qn->upper &&\n        qn->lower > 1 && qn->lower <= EXPAND_STRING_MAX_LENGTH) {\n      int len = NODE_STRING_LEN(body);\n      StrNode* sn = STR_(body);\n\n      if (len * qn->lower <= EXPAND_STRING_MAX_LENGTH) {\n        int i, n = qn->lower;\n        onig_node_conv_to_str_node(node, STR_(body)->flag);\n        for (i = 0; i < n; i++) {\n          r = onig_node_str_cat(node, sn->s, sn->end);\n          if (r != 0) return r;\n        }\n        onig_node_free(body);\n        return r;\n      }\n    }\n  }\n\n  if (qn->greedy && (qn->empty_info == BODY_IS_NOT_EMPTY)) {\n    if (NODE_TYPE(body) == NODE_QUANT) {\n      QuantNode* tqn = QUANT_(body);\n      if (IS_NOT_NULL(tqn->head_exact)) {\n        qn->head_exact  = tqn->head_exact;\n        tqn->head_exact = NULL;\n      }\n    }\n    else {\n      qn->head_exact = get_head_value_node(NODE_BODY(node), 1, reg);\n    }\n  }\n\n  return r;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static void pf_req_sense(struct pf_unit *pf, int quiet)\n{\n\tchar rs_cmd[12] =\n\t    { ATAPI_REQ_SENSE, pf->lun << 5, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0 };\n\tchar buf[16];\n\tint r;\n\n\tr = pf_command(pf, rs_cmd, 16, \"Request sense\");\n\tmdelay(1);\n\tif (!r)\n\t\tpf_completion(pf, buf, \"Request sense\");\n\n\tif ((!r) && (!quiet))\n\t\tprintk(\"%s: Sense key: %x, ASC: %x, ASQ: %x\\n\",\n\t\t       pf->name, buf[2] & 0xf, buf[12], buf[13]);\n}\n",
        "post_patch": "static void pf_req_sense(struct pf_unit *pf, int quiet)\n{\n\tchar rs_cmd[12] =\n\t    { ATAPI_REQ_SENSE, pf->lun << 5, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0 };\n\tchar buf[16];\n\tint r;\n\n\tr = pf_command(pf, rs_cmd, 16, \"Request sense\");\n\tmdelay(1);\n\tif (!r)\n\t\tpf_completion(pf, buf, \"Request sense\");\n\n\tif ((!r) && (!quiet))\n\t\tprintk(\"%s: Sense key: %x, ASC: %x, ASQ: %x\\n\",\n\t\t       pf->name, buf[2] & 0xf, buf[12], buf[13]);\n}\n",
        "post_patch_with_fix": "static void pf_req_sense(struct pf_unit *pf, int quiet)\n{\n\tchar rs_cmd[12] =\n\t    { ATAPI_REQ_SENSE, pf->lun << 5, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0 };\n\tchar buf[16];\n\tint r;\n\n\tr = pf_command(pf, rs_cmd, 16, \"Request sense\");\n\tmdelay(1);\n\tif (!r)\n\t\tpf_completion(pf, buf, \"Request sense\");\n\n\tif ((!r) && (!quiet))\n\t\tprintk(\"%s: Sense key: %x, ASC: %x, ASQ: %x\\n\",\n\t\t       pf->name, buf[2] & 0xf, buf[12], buf[13]);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct sockaddr_in *usin = (struct sockaddr_in *) uaddr;\n\tstruct flowi4 *fl4;\n\tstruct rtable *rt;\n\t__be32 saddr;\n\tint oif;\n\tint err;\n\n\n\tif (addr_len < sizeof(*usin))\n\t\treturn -EINVAL;\n\n\tif (usin->sin_family != AF_INET)\n\t\treturn -EAFNOSUPPORT;\n\n\tsk_dst_reset(sk);\n\n\tlock_sock(sk);\n\n\toif = sk->sk_bound_dev_if;\n\tsaddr = inet->inet_saddr;\n\tif (ipv4_is_multicast(usin->sin_addr.s_addr)) {\n\t\tif (!oif)\n\t\t\toif = inet->mc_index;\n\t\tif (!saddr)\n\t\t\tsaddr = inet->mc_addr;\n\t}\n\tfl4 = &inet->cork.fl.u.ip4;\n\trt = ip_route_connect(fl4, usin->sin_addr.s_addr, saddr,\n\t\t\t      RT_CONN_FLAGS(sk), oif,\n\t\t\t      sk->sk_protocol,\n\t\t\t      inet->inet_sport, usin->sin_port, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\tif (err == -ENETUNREACH)\n\t\t\tIP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTNOROUTES);\n\t\tgoto out;\n\t}\n\n\tif ((rt->rt_flags & RTCF_BROADCAST) && !sock_flag(sk, SOCK_BROADCAST)) {\n\t\tip_rt_put(rt);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!inet->inet_saddr)\n\t\tinet->inet_saddr = fl4->saddr;\t/* Update source address */\n\tif (!inet->inet_rcv_saddr) {\n\t\tinet->inet_rcv_saddr = fl4->saddr;\n\t\tif (sk->sk_prot->rehash)\n\t\t\tsk->sk_prot->rehash(sk);\n\t}\n\tinet->inet_daddr = fl4->daddr;\n\tinet->inet_dport = usin->sin_port;\n\tsk->sk_state = TCP_ESTABLISHED;\n\tinet->inet_id = jiffies;\n\n\tsk_dst_set(sk, &rt->dst);\n\terr = 0;\nout:\n\trelease_sock(sk);\n\treturn err;\n }\n",
        "post_patch": "int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct sockaddr_in *usin = (struct sockaddr_in *) uaddr;\n\tstruct flowi4 *fl4;\n\tstruct rtable *rt;\n\t__be32 saddr;\n\tint oif;\n\tint err;\n\n\n\tif (addr_len < sizeof(*usin))\n\t\treturn -EINVAL;\n\n\tif (usin->sin_family != AF_INET)\n\t\treturn -EAFNOSUPPORT;\n\n\tsk_dst_reset(sk);\n\n\tlock_sock(sk);\n\n\toif = sk->sk_bound_dev_if;\n\tsaddr = inet->inet_saddr;\n\tif (ipv4_is_multicast(usin->sin_addr.s_addr)) {\n\t\tif (!oif)\n\t\t\toif = inet->mc_index;\n\t\tif (!saddr)\n\t\t\tsaddr = inet->mc_addr;\n\t}\n\tfl4 = &inet->cork.fl.u.ip4;\n\trt = ip_route_connect(fl4, usin->sin_addr.s_addr, saddr,\n\t\t\t      RT_CONN_FLAGS(sk), oif,\n\t\t\t      sk->sk_protocol,\n\t\t\t      inet->inet_sport, usin->sin_port, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\tif (err == -ENETUNREACH)\n\t\t\tIP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTNOROUTES);\n\t\tgoto out;\n\t}\n\n\tif ((rt->rt_flags & RTCF_BROADCAST) && !sock_flag(sk, SOCK_BROADCAST)) {\n\t\tip_rt_put(rt);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!inet->inet_saddr)\n\t\tinet->inet_saddr = fl4->saddr;\t/* Update source address */\n\tif (!inet->inet_rcv_saddr) {\n\t\tinet->inet_rcv_saddr = fl4->saddr;\n\t\tif (sk->sk_prot->rehash)\n\t\t\tsk->sk_prot->rehash(sk);\n\t}\n\tinet->inet_daddr = fl4->daddr;\n\tinet->inet_dport = usin->sin_port;\n\tsk->sk_state = TCP_ESTABLISHED;\n\tinet->inet_id = jiffies;\n\n\tsk_dst_set(sk, &rt->dst);\n\terr = 0;\nout:\n\trelease_sock(sk);\n\treturn err;\n }\n",
        "post_patch_with_fix": "int ip4_datagram_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)\n{\n\tstruct inet_sock *inet = inet_sk(sk);\n\tstruct sockaddr_in *usin = (struct sockaddr_in *) uaddr;\n\tstruct flowi4 *fl4;\n\tstruct rtable *rt;\n\t__be32 saddr;\n\tint oif;\n\tint err;\n\n\n\tif (addr_len < sizeof(*usin))\n\t\treturn -EINVAL;\n\n\tif (usin->sin_family != AF_INET)\n\t\treturn -EAFNOSUPPORT;\n\n\tsk_dst_reset(sk);\n\n\tlock_sock(sk);\n\n\toif = sk->sk_bound_dev_if;\n\tsaddr = inet->inet_saddr;\n\tif (ipv4_is_multicast(usin->sin_addr.s_addr)) {\n\t\tif (!oif)\n\t\t\toif = inet->mc_index;\n\t\tif (!saddr)\n\t\t\tsaddr = inet->mc_addr;\n\t}\n\tfl4 = &inet->cork.fl.u.ip4;\n\trt = ip_route_connect(fl4, usin->sin_addr.s_addr, saddr,\n\t\t\t      RT_CONN_FLAGS(sk), oif,\n\t\t\t      sk->sk_protocol,\n\t\t\t      inet->inet_sport, usin->sin_port, sk);\n\tif (IS_ERR(rt)) {\n\t\terr = PTR_ERR(rt);\n\t\tif (err == -ENETUNREACH)\n\t\t\tIP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTNOROUTES);\n\t\tgoto out;\n\t}\n\n\tif ((rt->rt_flags & RTCF_BROADCAST) && !sock_flag(sk, SOCK_BROADCAST)) {\n\t\tip_rt_put(rt);\n\t\terr = -EACCES;\n\t\tgoto out;\n\t}\n\tif (!inet->inet_saddr)\n\t\tinet->inet_saddr = fl4->saddr;\t/* Update source address */\n\tif (!inet->inet_rcv_saddr) {\n\t\tinet->inet_rcv_saddr = fl4->saddr;\n\t\tif (sk->sk_prot->rehash)\n\t\t\tsk->sk_prot->rehash(sk);\n\t}\n\tinet->inet_daddr = fl4->daddr;\n\tinet->inet_dport = usin->sin_port;\n\tsk->sk_state = TCP_ESTABLISHED;\n\tinet->inet_id = jiffies;\n\n\tsk_dst_set(sk, &rt->dst);\n\terr = 0;\nout:\n\trelease_sock(sk);\n\treturn err;\n }\n",
        "label": 0
    },
    {
        "pre_patch": "TestRenderFrame::~TestRenderFrame() {}\n",
        "post_patch": "TestRenderFrame::~TestRenderFrame() {}\n",
        "post_patch_with_fix": "TestRenderFrame::~TestRenderFrame() {}\n",
        "label": 0
    },
    {
        "pre_patch": "get_entries(struct net *net, struct ipt_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get))\n\t\treturn -EINVAL;\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ipt_get_entries) + get.size)\n\t\treturn -EINVAL;\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse\n\t\t\tret = -EAGAIN;\n\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = PTR_ERR(t);\n\n\treturn ret;\n}\n",
        "post_patch": "get_entries(struct net *net, struct ipt_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get))\n\t\treturn -EINVAL;\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ipt_get_entries) + get.size)\n\t\treturn -EINVAL;\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse\n\t\t\tret = -EAGAIN;\n\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = PTR_ERR(t);\n\n\treturn ret;\n}\n",
        "post_patch_with_fix": "get_entries(struct net *net, struct ipt_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get))\n\t\treturn -EINVAL;\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ipt_get_entries) + get.size)\n\t\treturn -EINVAL;\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse\n\t\t\tret = -EAGAIN;\n\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = PTR_ERR(t);\n\n\treturn ret;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n {\n   size_t i;\n   size_t e;\n \n   if (c->stack == NULL) return;\n   e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n     mrb_value v = c->stbase[i];\n \n     if (!mrb_immediate_p(v)) {\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n        c->stbase[i] = mrb_nil_value();\n      }\n      else {\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n      }\n     }\n   }\n }\n",
        "post_patch": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n {\n   size_t i;\n   size_t e;\n  mrb_value nil;\n \n   if (c->stack == NULL) return;\n   e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n     mrb_value v = c->stbase[i];\n \n     if (!mrb_immediate_p(v)) {\n      mrb_gc_mark(mrb, mrb_basic_ptr(v));\n     }\n   }\n  e = c->stend - c->stbase;\n  nil = mrb_nil_value();\n  for (; i<e; i++) {\n    c->stbase[i] = nil;\n  }\n }\n",
        "post_patch_with_fix": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n {\n   size_t i;\n   size_t e;\n//fix_flaw_line_below:\n//  mrb_value nil;\n \n   if (c->stack == NULL) return;\n   e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n     mrb_value v = c->stbase[i];\n \n     if (!mrb_immediate_p(v)) {\n//flaw_line_below:\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n//flaw_line_below:\n        c->stbase[i] = mrb_nil_value();\n//flaw_line_below:\n      }\n//flaw_line_below:\n      else {\n//flaw_line_below:\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n//flaw_line_below:\n      }\n//fix_flaw_line_below:\n//      mrb_gc_mark(mrb, mrb_basic_ptr(v));\n     }\n   }\n//fix_flaw_line_below:\n//  e = c->stend - c->stbase;\n//fix_flaw_line_below:\n//  nil = mrb_nil_value();\n//fix_flaw_line_below:\n//  for (; i<e; i++) {\n//fix_flaw_line_below:\n//    c->stbase[i] = nil;\n//fix_flaw_line_below:\n//  }\n }\n",
        "label": 1
    },
    {
        "pre_patch": "int hsr_dev_finalize(struct net_device *hsr_dev, struct net_device *slave[2],\n\t\t     unsigned char multicast_spec, u8 protocol_version)\n{\n\tstruct hsr_priv *hsr;\n\tstruct hsr_port *port;\n\tint res;\n\n\thsr = netdev_priv(hsr_dev);\n\tINIT_LIST_HEAD(&hsr->ports);\n\tINIT_LIST_HEAD(&hsr->node_db);\n\tINIT_LIST_HEAD(&hsr->self_node_db);\n\n\tether_addr_copy(hsr_dev->dev_addr, slave[0]->dev_addr);\n\n\t/* Make sure we recognize frames from ourselves in hsr_rcv() */\n\tres = hsr_create_self_node(&hsr->self_node_db, hsr_dev->dev_addr,\n\t\t\t\t   slave[1]->dev_addr);\n\tif (res < 0)\n\t\treturn res;\n\n\tspin_lock_init(&hsr->seqnr_lock);\n\t/* Overflow soon to find bugs easier: */\n\thsr->sequence_nr = HSR_SEQNR_START;\n\thsr->sup_sequence_nr = HSR_SUP_SEQNR_START;\n\n\ttimer_setup(&hsr->announce_timer, hsr_announce, 0);\n\ttimer_setup(&hsr->prune_timer, hsr_prune_nodes, 0);\n\n\tether_addr_copy(hsr->sup_multicast_addr, def_multicast_addr);\n\thsr->sup_multicast_addr[ETH_ALEN - 1] = multicast_spec;\n\n\thsr->protVersion = protocol_version;\n\n\t/* FIXME: should I modify the value of these?\n\t *\n\t * - hsr_dev->flags - i.e.\n\t *\t\t\tIFF_MASTER/SLAVE?\n\t * - hsr_dev->priv_flags - i.e.\n\t *\t\t\tIFF_EBRIDGE?\n\t *\t\t\tIFF_TX_SKB_SHARING?\n\t *\t\t\tIFF_HSR_MASTER/SLAVE?\n\t */\n\n\t/* Make sure the 1st call to netif_carrier_on() gets through */\n\tnetif_carrier_off(hsr_dev);\n \n \tres = hsr_add_port(hsr, hsr_dev, HSR_PT_MASTER);\n \tif (res)\n\t\treturn res;\n \n \tres = register_netdevice(hsr_dev);\n \tif (res)\n\t\tgoto fail;\n\n\tres = hsr_add_port(hsr, slave[0], HSR_PT_SLAVE_A);\n\tif (res)\n\t\tgoto fail;\n\tres = hsr_add_port(hsr, slave[1], HSR_PT_SLAVE_B);\n\tif (res)\n\t\tgoto fail;\n\n\tmod_timer(&hsr->prune_timer, jiffies + msecs_to_jiffies(PRUNE_PERIOD));\n\n\treturn 0;\n\n fail:\n \thsr_for_each_port(hsr, port)\n \t\thsr_del_port(port);\n \n \treturn res;\n }\n",
        "post_patch": "int hsr_dev_finalize(struct net_device *hsr_dev, struct net_device *slave[2],\n\t\t     unsigned char multicast_spec, u8 protocol_version)\n{\n\tstruct hsr_priv *hsr;\n\tstruct hsr_port *port;\n\tint res;\n\n\thsr = netdev_priv(hsr_dev);\n\tINIT_LIST_HEAD(&hsr->ports);\n\tINIT_LIST_HEAD(&hsr->node_db);\n\tINIT_LIST_HEAD(&hsr->self_node_db);\n\n\tether_addr_copy(hsr_dev->dev_addr, slave[0]->dev_addr);\n\n\t/* Make sure we recognize frames from ourselves in hsr_rcv() */\n\tres = hsr_create_self_node(&hsr->self_node_db, hsr_dev->dev_addr,\n\t\t\t\t   slave[1]->dev_addr);\n\tif (res < 0)\n\t\treturn res;\n\n\tspin_lock_init(&hsr->seqnr_lock);\n\t/* Overflow soon to find bugs easier: */\n\thsr->sequence_nr = HSR_SEQNR_START;\n\thsr->sup_sequence_nr = HSR_SUP_SEQNR_START;\n\n\ttimer_setup(&hsr->announce_timer, hsr_announce, 0);\n\ttimer_setup(&hsr->prune_timer, hsr_prune_nodes, 0);\n\n\tether_addr_copy(hsr->sup_multicast_addr, def_multicast_addr);\n\thsr->sup_multicast_addr[ETH_ALEN - 1] = multicast_spec;\n\n\thsr->protVersion = protocol_version;\n\n\t/* FIXME: should I modify the value of these?\n\t *\n\t * - hsr_dev->flags - i.e.\n\t *\t\t\tIFF_MASTER/SLAVE?\n\t * - hsr_dev->priv_flags - i.e.\n\t *\t\t\tIFF_EBRIDGE?\n\t *\t\t\tIFF_TX_SKB_SHARING?\n\t *\t\t\tIFF_HSR_MASTER/SLAVE?\n\t */\n\n\t/* Make sure the 1st call to netif_carrier_on() gets through */\n\tnetif_carrier_off(hsr_dev);\n \n \tres = hsr_add_port(hsr, hsr_dev, HSR_PT_MASTER);\n \tif (res)\n\t\tgoto err_add_port;\n \n \tres = register_netdevice(hsr_dev);\n \tif (res)\n\t\tgoto fail;\n\n\tres = hsr_add_port(hsr, slave[0], HSR_PT_SLAVE_A);\n\tif (res)\n\t\tgoto fail;\n\tres = hsr_add_port(hsr, slave[1], HSR_PT_SLAVE_B);\n\tif (res)\n\t\tgoto fail;\n\n\tmod_timer(&hsr->prune_timer, jiffies + msecs_to_jiffies(PRUNE_PERIOD));\n\n\treturn 0;\n\n fail:\n \thsr_for_each_port(hsr, port)\n \t\thsr_del_port(port);\nerr_add_port:\n\thsr_del_node(&hsr->self_node_db);\n \n \treturn res;\n }\n",
        "post_patch_with_fix": "int hsr_dev_finalize(struct net_device *hsr_dev, struct net_device *slave[2],\n\t\t     unsigned char multicast_spec, u8 protocol_version)\n{\n\tstruct hsr_priv *hsr;\n\tstruct hsr_port *port;\n\tint res;\n\n\thsr = netdev_priv(hsr_dev);\n\tINIT_LIST_HEAD(&hsr->ports);\n\tINIT_LIST_HEAD(&hsr->node_db);\n\tINIT_LIST_HEAD(&hsr->self_node_db);\n\n\tether_addr_copy(hsr_dev->dev_addr, slave[0]->dev_addr);\n\n\t/* Make sure we recognize frames from ourselves in hsr_rcv() */\n\tres = hsr_create_self_node(&hsr->self_node_db, hsr_dev->dev_addr,\n\t\t\t\t   slave[1]->dev_addr);\n\tif (res < 0)\n\t\treturn res;\n\n\tspin_lock_init(&hsr->seqnr_lock);\n\t/* Overflow soon to find bugs easier: */\n\thsr->sequence_nr = HSR_SEQNR_START;\n\thsr->sup_sequence_nr = HSR_SUP_SEQNR_START;\n\n\ttimer_setup(&hsr->announce_timer, hsr_announce, 0);\n\ttimer_setup(&hsr->prune_timer, hsr_prune_nodes, 0);\n\n\tether_addr_copy(hsr->sup_multicast_addr, def_multicast_addr);\n\thsr->sup_multicast_addr[ETH_ALEN - 1] = multicast_spec;\n\n\thsr->protVersion = protocol_version;\n\n\t/* FIXME: should I modify the value of these?\n\t *\n\t * - hsr_dev->flags - i.e.\n\t *\t\t\tIFF_MASTER/SLAVE?\n\t * - hsr_dev->priv_flags - i.e.\n\t *\t\t\tIFF_EBRIDGE?\n\t *\t\t\tIFF_TX_SKB_SHARING?\n\t *\t\t\tIFF_HSR_MASTER/SLAVE?\n\t */\n\n\t/* Make sure the 1st call to netif_carrier_on() gets through */\n\tnetif_carrier_off(hsr_dev);\n \n \tres = hsr_add_port(hsr, hsr_dev, HSR_PT_MASTER);\n \tif (res)\n//flaw_line_below:\n\t\treturn res;\n//fix_flaw_line_below:\n//\t\tgoto err_add_port;\n \n \tres = register_netdevice(hsr_dev);\n \tif (res)\n\t\tgoto fail;\n\n\tres = hsr_add_port(hsr, slave[0], HSR_PT_SLAVE_A);\n\tif (res)\n\t\tgoto fail;\n\tres = hsr_add_port(hsr, slave[1], HSR_PT_SLAVE_B);\n\tif (res)\n\t\tgoto fail;\n\n\tmod_timer(&hsr->prune_timer, jiffies + msecs_to_jiffies(PRUNE_PERIOD));\n\n\treturn 0;\n\n fail:\n \thsr_for_each_port(hsr, port)\n \t\thsr_del_port(port);\n//fix_flaw_line_below:\n//err_add_port:\n//fix_flaw_line_below:\n//\thsr_del_node(&hsr->self_node_db);\n \n \treturn res;\n }\n",
        "label": 1
    },
    {
        "pre_patch": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n \trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n \tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n \n\tif (!int_port || !ext_port || !protocol)\n \t{\n \t\tClearNameValueList(&data);\n \t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}\n",
        "post_patch": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n \trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n \tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n \n\tif (!int_port || !rem_port || !protocol)\n \t{\n \t\tClearNameValueList(&data);\n \t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}\n",
        "post_patch_with_fix": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n \trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n \tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n \n//flaw_line_below:\n\tif (!int_port || !ext_port || !protocol)\n//fix_flaw_line_below:\n//\tif (!int_port || !rem_port || !protocol)\n \t{\n \t\tClearNameValueList(&data);\n \t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}\n",
        "label": 1
    },
    {
        "pre_patch": "e1000e_core_post_load(E1000ECore *core)\n{\n    NetClientState *nc = qemu_get_queue(core->owner_nic);\n\n    /* nc.link_down can't be migrated, so infer link_down according\n     * to link status bit in core.mac[STATUS].\n     */\n    nc->link_down = (core->mac[STATUS] & E1000_STATUS_LU) == 0;\n\n    return 0;\n}\n",
        "post_patch": "e1000e_core_post_load(E1000ECore *core)\n{\n    NetClientState *nc = qemu_get_queue(core->owner_nic);\n\n    /* nc.link_down can't be migrated, so infer link_down according\n     * to link status bit in core.mac[STATUS].\n     */\n    nc->link_down = (core->mac[STATUS] & E1000_STATUS_LU) == 0;\n\n    return 0;\n}\n",
        "post_patch_with_fix": "e1000e_core_post_load(E1000ECore *core)\n{\n    NetClientState *nc = qemu_get_queue(core->owner_nic);\n\n    /* nc.link_down can't be migrated, so infer link_down according\n     * to link status bit in core.mac[STATUS].\n     */\n    nc->link_down = (core->mac[STATUS] & E1000_STATUS_LU) == 0;\n\n    return 0;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int __init init_ipv4_mibs(void)\n{\n\treturn register_pernet_subsys(&ipv4_mib_ops);\n}\n",
        "post_patch": "static int __init init_ipv4_mibs(void)\n{\n\treturn register_pernet_subsys(&ipv4_mib_ops);\n}\n",
        "post_patch_with_fix": "static int __init init_ipv4_mibs(void)\n{\n\treturn register_pernet_subsys(&ipv4_mib_ops);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "bool NavigationControllerImpl::RendererDidNavigateAutoSubframe(\n    RenderFrameHostImpl* rfh,\n    const FrameHostMsg_DidCommitProvisionalLoad_Params& params) {\n  DCHECK(ui::PageTransitionCoreTypeIs(params.transition,\n                                      ui::PAGE_TRANSITION_AUTO_SUBFRAME));\n\n  DCHECK(GetLastCommittedEntry());\n\n  bool send_commit_notification = false;\n\n  if (params.nav_entry_id) {\n    int entry_index = GetEntryIndexWithUniqueID(params.nav_entry_id);\n    if (entry_index != -1 && entry_index != last_committed_entry_index_) {\n      const GURL& dest_top_url = GetEntryAtIndex(entry_index)->GetURL();\n      const GURL& current_top_url = GetLastCommittedEntry()->GetURL();\n      if (current_top_url.SchemeIsHTTPOrHTTPS() &&\n          dest_top_url.SchemeIsHTTPOrHTTPS() &&\n          current_top_url.GetOrigin() != dest_top_url.GetOrigin()) {\n        bad_message::ReceivedBadMessage(rfh->GetProcess(),\n                                        bad_message::NC_AUTO_SUBFRAME);\n      }\n\n      last_committed_entry_index_ = entry_index;\n      DiscardNonCommittedEntriesInternal();\n\n      send_commit_notification = true;\n    }\n  }\n\n  NavigationEntryImpl* last_committed = GetLastCommittedEntry();\n  last_committed->AddOrUpdateFrameEntry(\n      rfh->frame_tree_node(), params.item_sequence_number,\n      params.document_sequence_number, rfh->GetSiteInstance(), nullptr,\n      params.url, params.referrer, params.redirects, params.page_state,\n      params.method, params.post_id);\n\n  return send_commit_notification;\n}\n",
        "post_patch": "bool NavigationControllerImpl::RendererDidNavigateAutoSubframe(\n    RenderFrameHostImpl* rfh,\n    const FrameHostMsg_DidCommitProvisionalLoad_Params& params) {\n  DCHECK(ui::PageTransitionCoreTypeIs(params.transition,\n                                      ui::PAGE_TRANSITION_AUTO_SUBFRAME));\n\n  DCHECK(GetLastCommittedEntry());\n\n  bool send_commit_notification = false;\n\n  if (params.nav_entry_id) {\n    int entry_index = GetEntryIndexWithUniqueID(params.nav_entry_id);\n    if (entry_index != -1 && entry_index != last_committed_entry_index_) {\n      const GURL& dest_top_url = GetEntryAtIndex(entry_index)->GetURL();\n      const GURL& current_top_url = GetLastCommittedEntry()->GetURL();\n      if (current_top_url.SchemeIsHTTPOrHTTPS() &&\n          dest_top_url.SchemeIsHTTPOrHTTPS() &&\n          current_top_url.GetOrigin() != dest_top_url.GetOrigin()) {\n        bad_message::ReceivedBadMessage(rfh->GetProcess(),\n                                        bad_message::NC_AUTO_SUBFRAME);\n      }\n\n      last_committed_entry_index_ = entry_index;\n      DiscardNonCommittedEntriesInternal();\n\n      send_commit_notification = true;\n    }\n  }\n\n  NavigationEntryImpl* last_committed = GetLastCommittedEntry();\n  last_committed->AddOrUpdateFrameEntry(\n      rfh->frame_tree_node(), params.item_sequence_number,\n      params.document_sequence_number, rfh->GetSiteInstance(), nullptr,\n      params.url, params.referrer, params.redirects, params.page_state,\n      params.method, params.post_id);\n\n  return send_commit_notification;\n}\n",
        "post_patch_with_fix": "bool NavigationControllerImpl::RendererDidNavigateAutoSubframe(\n    RenderFrameHostImpl* rfh,\n    const FrameHostMsg_DidCommitProvisionalLoad_Params& params) {\n  DCHECK(ui::PageTransitionCoreTypeIs(params.transition,\n                                      ui::PAGE_TRANSITION_AUTO_SUBFRAME));\n\n  // We're guaranteed to have a previously committed entry, and we now need to\n  // handle navigation inside of a subframe in it without creating a new entry.\n  DCHECK(GetLastCommittedEntry());\n\n  // For newly created subframes, we don't need to send a commit notification.\n  // This is only necessary for history navigations in subframes.\n  bool send_commit_notification = false;\n\n  // If the |nav_entry_id| is non-zero and matches an existing entry, this is\n  // a history navigation.  Update the last committed index accordingly.\n  // If we don't recognize the |nav_entry_id|, it might be a recently pruned\n  // entry.  We'll handle it below.\n  if (params.nav_entry_id) {\n    int entry_index = GetEntryIndexWithUniqueID(params.nav_entry_id);\n    if (entry_index != -1 && entry_index != last_committed_entry_index_) {\n      // Make sure that a subframe commit isn't changing the main frame's\n      // origin. Otherwise the renderer process may be confused, leading to a\n      // URL spoof. We can't check the path since that may change\n      // (https://crbug.com/373041).\n      // TODO(creis): For now, restrict this check to HTTP(S) origins, because\n      // about:blank, file, and unique origins are more subtle to get right.\n      // We'll abstract out the relevant checks from IsURLInPageNavigation and\n      // share them here.  See https://crbug.com/618104.\n      const GURL& dest_top_url = GetEntryAtIndex(entry_index)->GetURL();\n      const GURL& current_top_url = GetLastCommittedEntry()->GetURL();\n      if (current_top_url.SchemeIsHTTPOrHTTPS() &&\n          dest_top_url.SchemeIsHTTPOrHTTPS() &&\n          current_top_url.GetOrigin() != dest_top_url.GetOrigin()) {\n        bad_message::ReceivedBadMessage(rfh->GetProcess(),\n                                        bad_message::NC_AUTO_SUBFRAME);\n      }\n\n      // We only need to discard the pending entry in this history navigation\n      // case.  For newly created subframes, there was no pending entry.\n      last_committed_entry_index_ = entry_index;\n      DiscardNonCommittedEntriesInternal();\n\n      // History navigations should send a commit notification.\n      send_commit_notification = true;\n    }\n  }\n\n  // This may be a \"new auto\" case where we add a new FrameNavigationEntry, or\n  // it may be a \"history auto\" case where we update an existing one.\n  NavigationEntryImpl* last_committed = GetLastCommittedEntry();\n  last_committed->AddOrUpdateFrameEntry(\n      rfh->frame_tree_node(), params.item_sequence_number,\n      params.document_sequence_number, rfh->GetSiteInstance(), nullptr,\n      params.url, params.referrer, params.redirects, params.page_state,\n      params.method, params.post_id);\n\n  return send_commit_notification;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "int yr_arena_allocate_memory(\n    YR_ARENA* arena,\n    size_t size,\n    void** allocated_memory)\n{\n  FAIL_ON_ERROR(yr_arena_reserve_memory(arena, size));\n\n  *allocated_memory = arena->current_page->address + \\\n                      arena->current_page->used;\n\n  arena->current_page->used += size;\n\n  return ERROR_SUCCESS;\n}\n",
        "post_patch": "int yr_arena_allocate_memory(\n    YR_ARENA* arena,\n    size_t size,\n    void** allocated_memory)\n{\n  FAIL_ON_ERROR(yr_arena_reserve_memory(arena, size));\n\n  *allocated_memory = arena->current_page->address + \\\n                      arena->current_page->used;\n\n  arena->current_page->used += size;\n\n  return ERROR_SUCCESS;\n}\n",
        "post_patch_with_fix": "int yr_arena_allocate_memory(\n    YR_ARENA* arena,\n    size_t size,\n    void** allocated_memory)\n{\n  FAIL_ON_ERROR(yr_arena_reserve_memory(arena, size));\n\n  *allocated_memory = arena->current_page->address + \\\n                      arena->current_page->used;\n\n  arena->current_page->used += size;\n\n  return ERROR_SUCCESS;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int hns_nic_maybe_stop_tso(\n\tstruct sk_buff **out_skb, int *bnum, struct hnae_ring *ring)\n{\n\tint i;\n\tint size;\n\tint buf_num;\n\tint frag_num;\n\tstruct sk_buff *skb = *out_skb;\n\tstruct sk_buff *new_skb = NULL;\n\tstruct skb_frag_struct *frag;\n\n\tsize = skb_headlen(skb);\n\tbuf_num = (size + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\n\tfrag_num = skb_shinfo(skb)->nr_frags;\n\tfor (i = 0; i < frag_num; i++) {\n\t\tfrag = &skb_shinfo(skb)->frags[i];\n\t\tsize = skb_frag_size(frag);\n\t\tbuf_num += (size + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\t}\n\n\tif (unlikely(buf_num > ring->max_desc_num_per_pkt)) {\n\t\tbuf_num = (skb->len + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\t\tif (ring_space(ring) < buf_num)\n\t\t\treturn -EBUSY;\n\t\t/* manual split the send packet */\n\t\tnew_skb = skb_copy(skb, GFP_ATOMIC);\n\t\tif (!new_skb)\n\t\t\treturn -ENOMEM;\n\t\tdev_kfree_skb_any(skb);\n\t\t*out_skb = new_skb;\n\n\t} else if (ring_space(ring) < buf_num) {\n\t\treturn -EBUSY;\n\t}\n\n\t*bnum = buf_num;\n\treturn 0;\n}\n",
        "post_patch": "static int hns_nic_maybe_stop_tso(\n\tstruct sk_buff **out_skb, int *bnum, struct hnae_ring *ring)\n{\n\tint i;\n\tint size;\n\tint buf_num;\n\tint frag_num;\n\tstruct sk_buff *skb = *out_skb;\n\tstruct sk_buff *new_skb = NULL;\n\tstruct skb_frag_struct *frag;\n\n\tsize = skb_headlen(skb);\n\tbuf_num = (size + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\n\tfrag_num = skb_shinfo(skb)->nr_frags;\n\tfor (i = 0; i < frag_num; i++) {\n\t\tfrag = &skb_shinfo(skb)->frags[i];\n\t\tsize = skb_frag_size(frag);\n\t\tbuf_num += (size + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\t}\n\n\tif (unlikely(buf_num > ring->max_desc_num_per_pkt)) {\n\t\tbuf_num = (skb->len + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\t\tif (ring_space(ring) < buf_num)\n\t\t\treturn -EBUSY;\n\t\t/* manual split the send packet */\n\t\tnew_skb = skb_copy(skb, GFP_ATOMIC);\n\t\tif (!new_skb)\n\t\t\treturn -ENOMEM;\n\t\tdev_kfree_skb_any(skb);\n\t\t*out_skb = new_skb;\n\n\t} else if (ring_space(ring) < buf_num) {\n\t\treturn -EBUSY;\n\t}\n\n\t*bnum = buf_num;\n\treturn 0;\n}\n",
        "post_patch_with_fix": "static int hns_nic_maybe_stop_tso(\n\tstruct sk_buff **out_skb, int *bnum, struct hnae_ring *ring)\n{\n\tint i;\n\tint size;\n\tint buf_num;\n\tint frag_num;\n\tstruct sk_buff *skb = *out_skb;\n\tstruct sk_buff *new_skb = NULL;\n\tstruct skb_frag_struct *frag;\n\n\tsize = skb_headlen(skb);\n\tbuf_num = (size + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\n\tfrag_num = skb_shinfo(skb)->nr_frags;\n\tfor (i = 0; i < frag_num; i++) {\n\t\tfrag = &skb_shinfo(skb)->frags[i];\n\t\tsize = skb_frag_size(frag);\n\t\tbuf_num += (size + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\t}\n\n\tif (unlikely(buf_num > ring->max_desc_num_per_pkt)) {\n\t\tbuf_num = (skb->len + BD_MAX_SEND_SIZE - 1) / BD_MAX_SEND_SIZE;\n\t\tif (ring_space(ring) < buf_num)\n\t\t\treturn -EBUSY;\n\t\t/* manual split the send packet */\n\t\tnew_skb = skb_copy(skb, GFP_ATOMIC);\n\t\tif (!new_skb)\n\t\t\treturn -ENOMEM;\n\t\tdev_kfree_skb_any(skb);\n\t\t*out_skb = new_skb;\n\n\t} else if (ring_space(ring) < buf_num) {\n\t\treturn -EBUSY;\n\t}\n\n\t*bnum = buf_num;\n\treturn 0;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void LayerTreeHostImpl::SetTreeLayerTransformMutated(\n    ElementId element_id,\n    LayerTreeImpl* tree,\n    const gfx::Transform& transform) {\n  if (!tree)\n    return;\n\n  PropertyTrees* property_trees = tree->property_trees();\n  DCHECK_EQ(\n      1u, property_trees->element_id_to_transform_node_index.count(element_id));\n  const int transform_node_index =\n      property_trees->element_id_to_transform_node_index[element_id];\n  property_trees->transform_tree.OnTransformAnimated(\n      transform, transform_node_index, tree);\n  if (LayerImpl* layer = tree->LayerByElementId(element_id))\n    layer->set_was_ever_ready_since_last_transform_animation(false);\n}\n",
        "post_patch": "void LayerTreeHostImpl::SetTreeLayerTransformMutated(\n    ElementId element_id,\n    LayerTreeImpl* tree,\n    const gfx::Transform& transform) {\n  if (!tree)\n    return;\n\n  PropertyTrees* property_trees = tree->property_trees();\n  DCHECK_EQ(\n      1u, property_trees->element_id_to_transform_node_index.count(element_id));\n  const int transform_node_index =\n      property_trees->element_id_to_transform_node_index[element_id];\n  property_trees->transform_tree.OnTransformAnimated(\n      transform, transform_node_index, tree);\n  if (LayerImpl* layer = tree->LayerByElementId(element_id))\n    layer->set_was_ever_ready_since_last_transform_animation(false);\n}\n",
        "post_patch_with_fix": "void LayerTreeHostImpl::SetTreeLayerTransformMutated(\n    ElementId element_id,\n    LayerTreeImpl* tree,\n    const gfx::Transform& transform) {\n  if (!tree)\n    return;\n\n  PropertyTrees* property_trees = tree->property_trees();\n  DCHECK_EQ(\n      1u, property_trees->element_id_to_transform_node_index.count(element_id));\n  const int transform_node_index =\n      property_trees->element_id_to_transform_node_index[element_id];\n  property_trees->transform_tree.OnTransformAnimated(\n      transform, transform_node_index, tree);\n  if (LayerImpl* layer = tree->LayerByElementId(element_id))\n    layer->set_was_ever_ready_since_last_transform_animation(false);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static void __net_exit tcpv6_net_exit(struct net *net)\n{\n\tinet_ctl_sock_destroy(net->ipv6.tcp_sk);\n}\n",
        "post_patch": "static void __net_exit tcpv6_net_exit(struct net *net)\n{\n\tinet_ctl_sock_destroy(net->ipv6.tcp_sk);\n}\n",
        "post_patch_with_fix": "static void __net_exit tcpv6_net_exit(struct net *net)\n{\n\tinet_ctl_sock_destroy(net->ipv6.tcp_sk);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void svc_rdma_xdr_encode_reply_array(struct rpcrdma_write_array *ary,\n\t\t\t\t int chunks)\n{\n\tary->wc_discrim = xdr_one;\n\tary->wc_nchunks = cpu_to_be32(chunks);\n}\n",
        "post_patch": "void svc_rdma_xdr_encode_reply_array(struct rpcrdma_write_array *ary,\n",
        "post_patch_with_fix": "void svc_rdma_xdr_encode_reply_array(struct rpcrdma_write_array *ary,\n//flaw_line_below:\n\t\t\t\t int chunks)\n//flaw_line_below:\n{\n//flaw_line_below:\n\tary->wc_discrim = xdr_one;\n//flaw_line_below:\n\tary->wc_nchunks = cpu_to_be32(chunks);\n//flaw_line_below:\n}\n",
        "label": 1
    },
    {
        "pre_patch": "static int finish_open_channel (lua_State *L, int status, lua_KContext ctx) {\n    ssh_userdata *state = (ssh_userdata *)lua_touserdata(L, 1);\n    LIBSSH2_CHANNEL **channel = (LIBSSH2_CHANNEL **) lua_touserdata(L, 2);\n\n    while ((*channel = libssh2_channel_open_session(state->session)) == NULL\n    && libssh2_session_last_errno(state->session) == LIBSSH2_ERROR_EAGAIN) {\n        luaL_getmetafield(L, 1, \"filter\");\n        lua_pushvalue(L, 1);\n        lua_callk(L, 1, 0, 0, finish_open_channel);\n    }\n    if (channel == NULL)\n        return luaL_error(L, \"Opening channel\");\n\n    return setup_channel(L, 0, 0);\n}\n",
        "post_patch": "static int finish_open_channel (lua_State *L, int status, lua_KContext ctx) {\n    ssh_userdata *state = (ssh_userdata *)lua_touserdata(L, 1);\n    LIBSSH2_CHANNEL **channel = (LIBSSH2_CHANNEL **) lua_touserdata(L, 2);\n\n    while ((*channel = libssh2_channel_open_session(state->session)) == NULL\n    && libssh2_session_last_errno(state->session) == LIBSSH2_ERROR_EAGAIN) {\n        luaL_getmetafield(L, 1, \"filter\");\n        lua_pushvalue(L, 1);\n        lua_callk(L, 1, 0, 0, finish_open_channel);\n    }\n    if (channel == NULL)\n        return luaL_error(L, \"Opening channel\");\n\n    return setup_channel(L, 0, 0);\n}\n",
        "post_patch_with_fix": "static int finish_open_channel (lua_State *L, int status, lua_KContext ctx) {\n    ssh_userdata *state = (ssh_userdata *)lua_touserdata(L, 1);\n    LIBSSH2_CHANNEL **channel = (LIBSSH2_CHANNEL **) lua_touserdata(L, 2);\n\n    while ((*channel = libssh2_channel_open_session(state->session)) == NULL\n    && libssh2_session_last_errno(state->session) == LIBSSH2_ERROR_EAGAIN) {\n        luaL_getmetafield(L, 1, \"filter\");\n        lua_pushvalue(L, 1);\n        lua_callk(L, 1, 0, 0, finish_open_channel);\n    }\n    if (channel == NULL)\n        return luaL_error(L, \"Opening channel\");\n\n    return setup_channel(L, 0, 0);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void AudioHandler::SetChannelInterpretation(const String& interpretation,\n                                            ExceptionState& exception_state) {\n  DCHECK(IsMainThread());\n  BaseAudioContext::GraphAutoLocker locker(Context());\n\n  AudioBus::ChannelInterpretation old_mode = channel_interpretation_;\n\n  if (interpretation == \"speakers\") {\n    new_channel_interpretation_ = AudioBus::kSpeakers;\n  } else if (interpretation == \"discrete\") {\n    new_channel_interpretation_ = AudioBus::kDiscrete;\n  } else {\n    NOTREACHED();\n  }\n\n  if (new_channel_interpretation_ != old_mode)\n    Context()->GetDeferredTaskHandler().AddChangedChannelInterpretation(this);\n}\n",
        "post_patch": "void AudioHandler::SetChannelInterpretation(const String& interpretation,\n                                            ExceptionState& exception_state) {\n  DCHECK(IsMainThread());\n  BaseAudioContext::GraphAutoLocker locker(Context());\n\n  AudioBus::ChannelInterpretation old_mode = channel_interpretation_;\n\n  if (interpretation == \"speakers\") {\n    new_channel_interpretation_ = AudioBus::kSpeakers;\n  } else if (interpretation == \"discrete\") {\n    new_channel_interpretation_ = AudioBus::kDiscrete;\n  } else {\n    NOTREACHED();\n  }\n\n  if (new_channel_interpretation_ != old_mode)\n    Context()->GetDeferredTaskHandler().AddChangedChannelInterpretation(this);\n}\n",
        "post_patch_with_fix": "void AudioHandler::SetChannelInterpretation(const String& interpretation,\n                                            ExceptionState& exception_state) {\n  DCHECK(IsMainThread());\n  BaseAudioContext::GraphAutoLocker locker(Context());\n\n  AudioBus::ChannelInterpretation old_mode = channel_interpretation_;\n\n  if (interpretation == \"speakers\") {\n    new_channel_interpretation_ = AudioBus::kSpeakers;\n  } else if (interpretation == \"discrete\") {\n    new_channel_interpretation_ = AudioBus::kDiscrete;\n  } else {\n    NOTREACHED();\n  }\n\n  if (new_channel_interpretation_ != old_mode)\n    Context()->GetDeferredTaskHandler().AddChangedChannelInterpretation(this);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "nfs3svc_decode_linkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_linkargs *args)\n{\n\tif (!(p = decode_fh(p, &args->ffh))\n\t || !(p = decode_fh(p, &args->tfh))\n\t || !(p = decode_filename(p, &args->tname, &args->tlen)))\n\t\treturn 0;\n\n\treturn xdr_argsize_check(rqstp, p);\n}\n",
        "post_patch": "nfs3svc_decode_linkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_linkargs *args)\n{\n\tif (!(p = decode_fh(p, &args->ffh))\n\t || !(p = decode_fh(p, &args->tfh))\n\t || !(p = decode_filename(p, &args->tname, &args->tlen)))\n\t\treturn 0;\n\n\treturn xdr_argsize_check(rqstp, p);\n}\n",
        "post_patch_with_fix": "nfs3svc_decode_linkargs(struct svc_rqst *rqstp, __be32 *p,\n\t\t\t\t\tstruct nfsd3_linkargs *args)\n{\n\tif (!(p = decode_fh(p, &args->ffh))\n\t || !(p = decode_fh(p, &args->tfh))\n\t || !(p = decode_filename(p, &args->tname, &args->tlen)))\n\t\treturn 0;\n\n\treturn xdr_argsize_check(rqstp, p);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static void ohci_eof_timer(OHCIState *ohci)\n{\n    ohci->sof_time = qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL);\n    timer_mod(ohci->eof_timer, ohci->sof_time + usb_frame_time);\n}\n",
        "post_patch": "static void ohci_eof_timer(OHCIState *ohci)\n{\n    ohci->sof_time = qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL);\n    timer_mod(ohci->eof_timer, ohci->sof_time + usb_frame_time);\n}\n",
        "post_patch_with_fix": "static void ohci_eof_timer(OHCIState *ohci)\n{\n    ohci->sof_time = qemu_clock_get_ns(QEMU_CLOCK_VIRTUAL);\n    timer_mod(ohci->eof_timer, ohci->sof_time + usb_frame_time);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void ip_rt_send_redirect(struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct in_device *in_dev;\n\tstruct inet_peer *peer;\n\tstruct net *net;\n\tint log_martians;\n\tint vif;\n\n\trcu_read_lock();\n\tin_dev = __in_dev_get_rcu(rt->dst.dev);\n\tif (!in_dev || !IN_DEV_TX_REDIRECTS(in_dev)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tlog_martians = IN_DEV_LOG_MARTIANS(in_dev);\n\tvif = l3mdev_master_ifindex_rcu(rt->dst.dev);\n\trcu_read_unlock();\n\n\tnet = dev_net(rt->dst.dev);\n\tpeer = inet_getpeer_v4(net->ipv4.peers, ip_hdr(skb)->saddr, vif, 1);\n\tif (!peer) {\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST,\n\t\t\t  rt_nexthop(rt, ip_hdr(skb)->daddr));\n\t\treturn;\n\t}\n\n\t/* No redirected packets during ip_rt_redirect_silence;\n\t * reset the algorithm.\n\t */\n\tif (time_after(jiffies, peer->rate_last + ip_rt_redirect_silence))\n\t\tpeer->rate_tokens = 0;\n\n\t/* Too many ignored redirects; do not send anything\n\t * set dst.rate_last to the last seen redirected packet.\n\t */\n\tif (peer->rate_tokens >= ip_rt_redirect_number) {\n\t\tpeer->rate_last = jiffies;\n\t\tgoto out_put_peer;\n\t}\n\n\t/* Check for load limit; set rate_last to the latest sent\n\t * redirect.\n\t */\n\tif (peer->rate_tokens == 0 ||\n\t    time_after(jiffies,\n\t\t       (peer->rate_last +\n\t\t\t(ip_rt_redirect_load << peer->rate_tokens)))) {\n\t\t__be32 gw = rt_nexthop(rt, ip_hdr(skb)->daddr);\n\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST, gw);\n\t\tpeer->rate_last = jiffies;\n\t\t++peer->rate_tokens;\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\t\tif (log_martians &&\n\t\t    peer->rate_tokens == ip_rt_redirect_number)\n\t\t\tnet_warn_ratelimited(\"host %pI4/if%d ignores redirects for %pI4 to %pI4\\n\",\n\t\t\t\t\t     &ip_hdr(skb)->saddr, inet_iif(skb),\n\t\t\t\t\t     &ip_hdr(skb)->daddr, &gw);\n#endif\n\t}\nout_put_peer:\n\tinet_putpeer(peer);\n}\n",
        "post_patch": "void ip_rt_send_redirect(struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct in_device *in_dev;\n\tstruct inet_peer *peer;\n\tstruct net *net;\n\tint log_martians;\n\tint vif;\n\n\trcu_read_lock();\n\tin_dev = __in_dev_get_rcu(rt->dst.dev);\n\tif (!in_dev || !IN_DEV_TX_REDIRECTS(in_dev)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tlog_martians = IN_DEV_LOG_MARTIANS(in_dev);\n\tvif = l3mdev_master_ifindex_rcu(rt->dst.dev);\n\trcu_read_unlock();\n\n\tnet = dev_net(rt->dst.dev);\n\tpeer = inet_getpeer_v4(net->ipv4.peers, ip_hdr(skb)->saddr, vif, 1);\n\tif (!peer) {\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST,\n\t\t\t  rt_nexthop(rt, ip_hdr(skb)->daddr));\n\t\treturn;\n\t}\n\n\t/* No redirected packets during ip_rt_redirect_silence;\n\t * reset the algorithm.\n\t */\n\tif (time_after(jiffies, peer->rate_last + ip_rt_redirect_silence))\n\t\tpeer->rate_tokens = 0;\n\n\t/* Too many ignored redirects; do not send anything\n\t * set dst.rate_last to the last seen redirected packet.\n\t */\n\tif (peer->rate_tokens >= ip_rt_redirect_number) {\n\t\tpeer->rate_last = jiffies;\n\t\tgoto out_put_peer;\n\t}\n\n\t/* Check for load limit; set rate_last to the latest sent\n\t * redirect.\n\t */\n\tif (peer->rate_tokens == 0 ||\n\t    time_after(jiffies,\n\t\t       (peer->rate_last +\n\t\t\t(ip_rt_redirect_load << peer->rate_tokens)))) {\n\t\t__be32 gw = rt_nexthop(rt, ip_hdr(skb)->daddr);\n\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST, gw);\n\t\tpeer->rate_last = jiffies;\n\t\t++peer->rate_tokens;\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\t\tif (log_martians &&\n\t\t    peer->rate_tokens == ip_rt_redirect_number)\n\t\t\tnet_warn_ratelimited(\"host %pI4/if%d ignores redirects for %pI4 to %pI4\\n\",\n\t\t\t\t\t     &ip_hdr(skb)->saddr, inet_iif(skb),\n\t\t\t\t\t     &ip_hdr(skb)->daddr, &gw);\n#endif\n\t}\nout_put_peer:\n\tinet_putpeer(peer);\n}\n",
        "post_patch_with_fix": "void ip_rt_send_redirect(struct sk_buff *skb)\n{\n\tstruct rtable *rt = skb_rtable(skb);\n\tstruct in_device *in_dev;\n\tstruct inet_peer *peer;\n\tstruct net *net;\n\tint log_martians;\n\tint vif;\n\n\trcu_read_lock();\n\tin_dev = __in_dev_get_rcu(rt->dst.dev);\n\tif (!in_dev || !IN_DEV_TX_REDIRECTS(in_dev)) {\n\t\trcu_read_unlock();\n\t\treturn;\n\t}\n\tlog_martians = IN_DEV_LOG_MARTIANS(in_dev);\n\tvif = l3mdev_master_ifindex_rcu(rt->dst.dev);\n\trcu_read_unlock();\n\n\tnet = dev_net(rt->dst.dev);\n\tpeer = inet_getpeer_v4(net->ipv4.peers, ip_hdr(skb)->saddr, vif, 1);\n\tif (!peer) {\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST,\n\t\t\t  rt_nexthop(rt, ip_hdr(skb)->daddr));\n\t\treturn;\n\t}\n\n\t/* No redirected packets during ip_rt_redirect_silence;\n\t * reset the algorithm.\n\t */\n\tif (time_after(jiffies, peer->rate_last + ip_rt_redirect_silence))\n\t\tpeer->rate_tokens = 0;\n\n\t/* Too many ignored redirects; do not send anything\n\t * set dst.rate_last to the last seen redirected packet.\n\t */\n\tif (peer->rate_tokens >= ip_rt_redirect_number) {\n\t\tpeer->rate_last = jiffies;\n\t\tgoto out_put_peer;\n\t}\n\n\t/* Check for load limit; set rate_last to the latest sent\n\t * redirect.\n\t */\n\tif (peer->rate_tokens == 0 ||\n\t    time_after(jiffies,\n\t\t       (peer->rate_last +\n\t\t\t(ip_rt_redirect_load << peer->rate_tokens)))) {\n\t\t__be32 gw = rt_nexthop(rt, ip_hdr(skb)->daddr);\n\n\t\ticmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST, gw);\n\t\tpeer->rate_last = jiffies;\n\t\t++peer->rate_tokens;\n#ifdef CONFIG_IP_ROUTE_VERBOSE\n\t\tif (log_martians &&\n\t\t    peer->rate_tokens == ip_rt_redirect_number)\n\t\t\tnet_warn_ratelimited(\"host %pI4/if%d ignores redirects for %pI4 to %pI4\\n\",\n\t\t\t\t\t     &ip_hdr(skb)->saddr, inet_iif(skb),\n\t\t\t\t\t     &ip_hdr(skb)->daddr, &gw);\n#endif\n\t}\nout_put_peer:\n\tinet_putpeer(peer);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "error::Error GLES2DecoderImpl::HandleMultiDrawElementsCHROMIUM(\n    uint32_t immediate_data_size,\n    const volatile void* cmd_data) {\n  const volatile gles2::cmds::MultiDrawElementsCHROMIUM& c =\n      *static_cast<const volatile gles2::cmds::MultiDrawElementsCHROMIUM*>(\n          cmd_data);\n  if (!features().webgl_multi_draw) {\n    return error::kUnknownCommand;\n  }\n\n  GLenum mode = static_cast<GLenum>(c.mode);\n  GLenum type = static_cast<GLenum>(c.type);\n  GLsizei drawcount = static_cast<GLsizei>(c.drawcount);\n\n  uint32_t counts_size, offsets_size;\n  base::CheckedNumeric<uint32_t> checked_size(drawcount);\n  if (!(checked_size * sizeof(GLsizei)).AssignIfValid(&counts_size)) {\n    return error::kOutOfBounds;\n  }\n  if (!(checked_size * sizeof(GLsizei)).AssignIfValid(&offsets_size)) {\n    return error::kOutOfBounds;\n  }\n  const GLsizei* counts = GetSharedMemoryAs<const GLsizei*>(\n      c.counts_shm_id, c.counts_shm_offset, counts_size);\n  const GLsizei* offsets = GetSharedMemoryAs<const GLsizei*>(\n      c.offsets_shm_id, c.offsets_shm_offset, offsets_size);\n  if (counts == nullptr) {\n    return error::kOutOfBounds;\n  }\n  if (offsets == nullptr) {\n    return error::kOutOfBounds;\n  }\n  if (!multi_draw_manager_->MultiDrawElements(mode, counts, type, offsets,\n                                              drawcount)) {\n    return error::kInvalidArguments;\n  }\n  return error::kNoError;\n}\n",
        "post_patch": "error::Error GLES2DecoderImpl::HandleMultiDrawElementsCHROMIUM(\n    uint32_t immediate_data_size,\n    const volatile void* cmd_data) {\n  const volatile gles2::cmds::MultiDrawElementsCHROMIUM& c =\n      *static_cast<const volatile gles2::cmds::MultiDrawElementsCHROMIUM*>(\n          cmd_data);\n  if (!features().webgl_multi_draw) {\n    return error::kUnknownCommand;\n  }\n\n  GLenum mode = static_cast<GLenum>(c.mode);\n  GLenum type = static_cast<GLenum>(c.type);\n  GLsizei drawcount = static_cast<GLsizei>(c.drawcount);\n\n  uint32_t counts_size, offsets_size;\n  base::CheckedNumeric<uint32_t> checked_size(drawcount);\n  if (!(checked_size * sizeof(GLsizei)).AssignIfValid(&counts_size)) {\n    return error::kOutOfBounds;\n  }\n  if (!(checked_size * sizeof(GLsizei)).AssignIfValid(&offsets_size)) {\n    return error::kOutOfBounds;\n  }\n  const GLsizei* counts = GetSharedMemoryAs<const GLsizei*>(\n      c.counts_shm_id, c.counts_shm_offset, counts_size);\n  const GLsizei* offsets = GetSharedMemoryAs<const GLsizei*>(\n      c.offsets_shm_id, c.offsets_shm_offset, offsets_size);\n  if (counts == nullptr) {\n    return error::kOutOfBounds;\n  }\n  if (offsets == nullptr) {\n    return error::kOutOfBounds;\n  }\n  if (!multi_draw_manager_->MultiDrawElements(mode, counts, type, offsets,\n                                              drawcount)) {\n    return error::kInvalidArguments;\n  }\n  return error::kNoError;\n}\n",
        "post_patch_with_fix": "error::Error GLES2DecoderImpl::HandleMultiDrawElementsCHROMIUM(\n    uint32_t immediate_data_size,\n    const volatile void* cmd_data) {\n  const volatile gles2::cmds::MultiDrawElementsCHROMIUM& c =\n      *static_cast<const volatile gles2::cmds::MultiDrawElementsCHROMIUM*>(\n          cmd_data);\n  if (!features().webgl_multi_draw) {\n    return error::kUnknownCommand;\n  }\n\n  GLenum mode = static_cast<GLenum>(c.mode);\n  GLenum type = static_cast<GLenum>(c.type);\n  GLsizei drawcount = static_cast<GLsizei>(c.drawcount);\n\n  uint32_t counts_size, offsets_size;\n  base::CheckedNumeric<uint32_t> checked_size(drawcount);\n  if (!(checked_size * sizeof(GLsizei)).AssignIfValid(&counts_size)) {\n    return error::kOutOfBounds;\n  }\n  if (!(checked_size * sizeof(GLsizei)).AssignIfValid(&offsets_size)) {\n    return error::kOutOfBounds;\n  }\n  const GLsizei* counts = GetSharedMemoryAs<const GLsizei*>(\n      c.counts_shm_id, c.counts_shm_offset, counts_size);\n  const GLsizei* offsets = GetSharedMemoryAs<const GLsizei*>(\n      c.offsets_shm_id, c.offsets_shm_offset, offsets_size);\n  if (counts == nullptr) {\n    return error::kOutOfBounds;\n  }\n  if (offsets == nullptr) {\n    return error::kOutOfBounds;\n  }\n  if (!multi_draw_manager_->MultiDrawElements(mode, counts, type, offsets,\n                                              drawcount)) {\n    return error::kInvalidArguments;\n  }\n  return error::kNoError;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "xsmp_get_discard_command (GsmClient *client)\n{\n        SmProp *prop;\n\n        prop = find_property (GSM_XSMP_CLIENT (client), SmDiscardCommand, NULL);\n\n        if (!prop || strcmp (prop->type, SmLISTofARRAY8) != 0) {\n                return NULL;\n        }\n\n        return prop_to_command (prop);\n}\n",
        "post_patch": "xsmp_get_discard_command (GsmClient *client)\n{\n        SmProp *prop;\n\n        prop = find_property (GSM_XSMP_CLIENT (client), SmDiscardCommand, NULL);\n\n        if (!prop || strcmp (prop->type, SmLISTofARRAY8) != 0) {\n                return NULL;\n        }\n\n        return prop_to_command (prop);\n}\n",
        "post_patch_with_fix": "xsmp_get_discard_command (GsmClient *client)\n{\n        SmProp *prop;\n\n        prop = find_property (GSM_XSMP_CLIENT (client), SmDiscardCommand, NULL);\n\n        if (!prop || strcmp (prop->type, SmLISTofARRAY8) != 0) {\n                return NULL;\n        }\n\n        return prop_to_command (prop);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static struct Curl_easy* gethandleathead(struct curl_llist *pipeline)\n{\n  struct curl_llist_element *curr = pipeline->head;\n#ifdef DEBUGBUILD\n  {\n    struct curl_llist_element *p = pipeline->head;\n    while(p) {\n      struct Curl_easy *e = p->ptr;\n      DEBUGASSERT(GOOD_EASY_HANDLE(e));\n      p = p->next;\n    }\n  }\n#endif\n  if(curr) {\n    return (struct Curl_easy *) curr->ptr;\n  }\n\n  return NULL;\n}\n",
        "post_patch": "static struct Curl_easy* gethandleathead(struct curl_llist *pipeline)\n{\n  struct curl_llist_element *curr = pipeline->head;\n#ifdef DEBUGBUILD\n  {\n    struct curl_llist_element *p = pipeline->head;\n    while(p) {\n      struct Curl_easy *e = p->ptr;\n      DEBUGASSERT(GOOD_EASY_HANDLE(e));\n      p = p->next;\n    }\n  }\n#endif\n  if(curr) {\n    return (struct Curl_easy *) curr->ptr;\n  }\n\n  return NULL;\n}\n",
        "post_patch_with_fix": "static struct Curl_easy* gethandleathead(struct curl_llist *pipeline)\n{\n  struct curl_llist_element *curr = pipeline->head;\n#ifdef DEBUGBUILD\n  {\n    struct curl_llist_element *p = pipeline->head;\n    while(p) {\n      struct Curl_easy *e = p->ptr;\n      DEBUGASSERT(GOOD_EASY_HANDLE(e));\n      p = p->next;\n    }\n  }\n#endif\n  if(curr) {\n    return (struct Curl_easy *) curr->ptr;\n  }\n\n  return NULL;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static const char *ep_state_name(uint32_t state)\n{\n    return lookup_name(state, ep_state_names,\n                       ARRAY_SIZE(ep_state_names));\n}\n",
        "post_patch": "static const char *ep_state_name(uint32_t state)\n{\n    return lookup_name(state, ep_state_names,\n                       ARRAY_SIZE(ep_state_names));\n}\n",
        "post_patch_with_fix": "static const char *ep_state_name(uint32_t state)\n{\n    return lookup_name(state, ep_state_names,\n                       ARRAY_SIZE(ep_state_names));\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static void lo_release(struct gendisk *disk, fmode_t mode)\n {\n\tstruct loop_device *lo = disk->private_data;\n \tint err;\n \n \tif (atomic_dec_return(&lo->lo_refcnt))\n\t\treturn;\n\n\tmutex_lock(&lo->lo_ctl_mutex);\n\tif (lo->lo_flags & LO_FLAGS_AUTOCLEAR) {\n\t\t/*\n\t\t * In autoclear mode, stop the loop thread\n\t\t * and remove configuration after last close.\n\t\t */\n\t\terr = loop_clr_fd(lo);\n\t\tif (!err)\n\t\t\treturn;\n\t} else if (lo->lo_state == Lo_bound) {\n\t\t/*\n\t\t * Otherwise keep thread (if running) and config,\n\t\t * but flush possible ongoing bios in thread.\n\t\t */\n\t\tblk_mq_freeze_queue(lo->lo_queue);\n\t\tblk_mq_unfreeze_queue(lo->lo_queue);\n\t}\n\n \tmutex_unlock(&lo->lo_ctl_mutex);\n }\n",
        "post_patch": "static void lo_release(struct gendisk *disk, fmode_t mode)\nstatic void __lo_release(struct loop_device *lo)\n {\n \tint err;\n \n \tif (atomic_dec_return(&lo->lo_refcnt))\n\t\treturn;\n\n\tmutex_lock(&lo->lo_ctl_mutex);\n\tif (lo->lo_flags & LO_FLAGS_AUTOCLEAR) {\n\t\t/*\n\t\t * In autoclear mode, stop the loop thread\n\t\t * and remove configuration after last close.\n\t\t */\n\t\terr = loop_clr_fd(lo);\n\t\tif (!err)\n\t\t\treturn;\n\t} else if (lo->lo_state == Lo_bound) {\n\t\t/*\n\t\t * Otherwise keep thread (if running) and config,\n\t\t * but flush possible ongoing bios in thread.\n\t\t */\n\t\tblk_mq_freeze_queue(lo->lo_queue);\n\t\tblk_mq_unfreeze_queue(lo->lo_queue);\n\t}\n\n \tmutex_unlock(&lo->lo_ctl_mutex);\n }\n",
        "post_patch_with_fix": "static void lo_release(struct gendisk *disk, fmode_t mode)\n//fix_flaw_line_below:\n//static void __lo_release(struct loop_device *lo)\n {\n//flaw_line_below:\n\tstruct loop_device *lo = disk->private_data;\n \tint err;\n \n \tif (atomic_dec_return(&lo->lo_refcnt))\n\t\treturn;\n\n\tmutex_lock(&lo->lo_ctl_mutex);\n\tif (lo->lo_flags & LO_FLAGS_AUTOCLEAR) {\n\t\t/*\n\t\t * In autoclear mode, stop the loop thread\n\t\t * and remove configuration after last close.\n\t\t */\n\t\terr = loop_clr_fd(lo);\n\t\tif (!err)\n\t\t\treturn;\n\t} else if (lo->lo_state == Lo_bound) {\n\t\t/*\n\t\t * Otherwise keep thread (if running) and config,\n\t\t * but flush possible ongoing bios in thread.\n\t\t */\n\t\tblk_mq_freeze_queue(lo->lo_queue);\n\t\tblk_mq_unfreeze_queue(lo->lo_queue);\n\t}\n\n \tmutex_unlock(&lo->lo_ctl_mutex);\n }\n",
        "label": 1
    },
    {
        "pre_patch": "void nicklist_update_flags(SERVER_REC *server, const char *nick,\n\t\t\t   int gone, int serverop)\n{\n\tnicklist_update_flags_list(server, gone, serverop,\n\t\t\t\t   nicklist_get_same(server, nick));\n}\n",
        "post_patch": "void nicklist_update_flags(SERVER_REC *server, const char *nick,\n\t\t\t   int gone, int serverop)\n{\n\tnicklist_update_flags_list(server, gone, serverop,\n\t\t\t\t   nicklist_get_same(server, nick));\n}\n",
        "post_patch_with_fix": "void nicklist_update_flags(SERVER_REC *server, const char *nick,\n\t\t\t   int gone, int serverop)\n{\n\tnicklist_update_flags_list(server, gone, serverop,\n\t\t\t\t   nicklist_get_same(server, nick));\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int csnmp_shutdown(void) {\n  data_definition_t *data_this;\n  data_definition_t *data_next;\n\n  /* When we get here, the read threads have been stopped and all the\n   * `host_definition_t' will be freed. */\n  DEBUG(\"snmp plugin: Destroying all data definitions.\");\n\n  data_this = data_head;\n  data_head = NULL;\n  while (data_this != NULL) {\n    data_next = data_this->next;\n\n    sfree(data_this->name);\n    sfree(data_this->type);\n    sfree(data_this->values);\n    sfree(data_this->ignores);\n    sfree(data_this);\n\n    data_this = data_next;\n  }\n\n  return (0);\n} /* int csnmp_shutdown */\n",
        "post_patch": "static int csnmp_shutdown(void) {\n  data_definition_t *data_this;\n  data_definition_t *data_next;\n\n  /* When we get here, the read threads have been stopped and all the\n   * `host_definition_t' will be freed. */\n  DEBUG(\"snmp plugin: Destroying all data definitions.\");\n\n  data_this = data_head;\n  data_head = NULL;\n  while (data_this != NULL) {\n    data_next = data_this->next;\n\n    sfree(data_this->name);\n    sfree(data_this->type);\n    sfree(data_this->values);\n    sfree(data_this->ignores);\n    sfree(data_this);\n\n    data_this = data_next;\n  }\n\n  return (0);\n} /* int csnmp_shutdown */\n",
        "post_patch_with_fix": "static int csnmp_shutdown(void) {\n  data_definition_t *data_this;\n  data_definition_t *data_next;\n\n  /* When we get here, the read threads have been stopped and all the\n   * `host_definition_t' will be freed. */\n  DEBUG(\"snmp plugin: Destroying all data definitions.\");\n\n  data_this = data_head;\n  data_head = NULL;\n  while (data_this != NULL) {\n    data_next = data_this->next;\n\n    sfree(data_this->name);\n    sfree(data_this->type);\n    sfree(data_this->values);\n    sfree(data_this->ignores);\n    sfree(data_this);\n\n    data_this = data_next;\n  }\n\n  return (0);\n} /* int csnmp_shutdown */\n",
        "label": 0
    },
    {
        "pre_patch": "  void VerifyDailyContentLengthPrefLists(\n       const int64* original_values, size_t original_count,\n       const int64* received_values, size_t received_count,\n       const int64* original_with_data_reduction_proxy_enabled_values,\n      size_t original_with_data_reduction_proxy_enabled_count,\n      const int64* received_with_data_reduction_proxy_enabled_values,\n      size_t received_with_data_reduction_proxy_count,\n      const int64* original_via_data_reduction_proxy_values,\n      size_t original_via_data_reduction_proxy_count,\n      const int64* received_via_data_reduction_proxy_values,\n      size_t received_via_data_reduction_proxy_count) {\n    VerifyPrefList(prefs::kDailyHttpOriginalContentLength,\n                   original_values, original_count);\n    VerifyPrefList(prefs::kDailyHttpReceivedContentLength,\n                   received_values, received_count);\n    VerifyPrefList(\n        prefs::kDailyOriginalContentLengthWithDataReductionProxyEnabled,\n        original_with_data_reduction_proxy_enabled_values,\n        original_with_data_reduction_proxy_enabled_count);\n    VerifyPrefList(\n        prefs::kDailyContentLengthWithDataReductionProxyEnabled,\n        received_with_data_reduction_proxy_enabled_values,\n        received_with_data_reduction_proxy_count);\n    VerifyPrefList(\n        prefs::kDailyOriginalContentLengthViaDataReductionProxy,\n        original_via_data_reduction_proxy_values,\n        original_via_data_reduction_proxy_count);\n    VerifyPrefList(\n        prefs::kDailyContentLengthViaDataReductionProxy,\n        received_via_data_reduction_proxy_values,\n         received_via_data_reduction_proxy_count);\n   }\n",
        "post_patch": "  void VerifyDailyContentLengthPrefLists(\n  // Verify all daily data saving pref list values.\n  void VerifyDailyDataSavingContentLengthPrefLists(\n       const int64* original_values, size_t original_count,\n       const int64* received_values, size_t received_count,\n       const int64* original_with_data_reduction_proxy_enabled_values,\n      size_t original_with_data_reduction_proxy_enabled_count,\n      const int64* received_with_data_reduction_proxy_enabled_values,\n      size_t received_with_data_reduction_proxy_count,\n      const int64* original_via_data_reduction_proxy_values,\n      size_t original_via_data_reduction_proxy_count,\n      const int64* received_via_data_reduction_proxy_values,\n      size_t received_via_data_reduction_proxy_count) {\n    VerifyPrefList(prefs::kDailyHttpOriginalContentLength,\n                   original_values, original_count);\n    VerifyPrefList(prefs::kDailyHttpReceivedContentLength,\n                   received_values, received_count);\n    VerifyPrefList(\n        prefs::kDailyOriginalContentLengthWithDataReductionProxyEnabled,\n        original_with_data_reduction_proxy_enabled_values,\n        original_with_data_reduction_proxy_enabled_count);\n    VerifyPrefList(\n        prefs::kDailyContentLengthWithDataReductionProxyEnabled,\n        received_with_data_reduction_proxy_enabled_values,\n        received_with_data_reduction_proxy_count);\n    VerifyPrefList(\n        prefs::kDailyOriginalContentLengthViaDataReductionProxy,\n        original_via_data_reduction_proxy_values,\n        original_via_data_reduction_proxy_count);\n    VerifyPrefList(\n        prefs::kDailyContentLengthViaDataReductionProxy,\n        received_via_data_reduction_proxy_values,\n         received_via_data_reduction_proxy_count);\n   }\n",
        "post_patch_with_fix": "  void VerifyDailyContentLengthPrefLists(\n//fix_flaw_line_below:\n//  // Verify all daily data saving pref list values.\n//fix_flaw_line_below:\n//  void VerifyDailyDataSavingContentLengthPrefLists(\n       const int64* original_values, size_t original_count,\n       const int64* received_values, size_t received_count,\n       const int64* original_with_data_reduction_proxy_enabled_values,\n      size_t original_with_data_reduction_proxy_enabled_count,\n      const int64* received_with_data_reduction_proxy_enabled_values,\n      size_t received_with_data_reduction_proxy_count,\n      const int64* original_via_data_reduction_proxy_values,\n      size_t original_via_data_reduction_proxy_count,\n      const int64* received_via_data_reduction_proxy_values,\n      size_t received_via_data_reduction_proxy_count) {\n    VerifyPrefList(prefs::kDailyHttpOriginalContentLength,\n                   original_values, original_count);\n    VerifyPrefList(prefs::kDailyHttpReceivedContentLength,\n                   received_values, received_count);\n    VerifyPrefList(\n        prefs::kDailyOriginalContentLengthWithDataReductionProxyEnabled,\n        original_with_data_reduction_proxy_enabled_values,\n        original_with_data_reduction_proxy_enabled_count);\n    VerifyPrefList(\n        prefs::kDailyContentLengthWithDataReductionProxyEnabled,\n        received_with_data_reduction_proxy_enabled_values,\n        received_with_data_reduction_proxy_count);\n    VerifyPrefList(\n        prefs::kDailyOriginalContentLengthViaDataReductionProxy,\n        original_via_data_reduction_proxy_values,\n        original_via_data_reduction_proxy_count);\n    VerifyPrefList(\n        prefs::kDailyContentLengthViaDataReductionProxy,\n        received_via_data_reduction_proxy_values,\n         received_via_data_reduction_proxy_count);\n   }\n",
        "label": 1
    },
    {
        "pre_patch": "static int compat_dev_ifconf(struct net *net, struct compat_ifconf __user *uifc32)\n{\n\tstruct compat_ifconf ifc32;\n\tstruct ifconf ifc;\n\tint err;\n\n\tif (copy_from_user(&ifc32, uifc32, sizeof(struct compat_ifconf)))\n\t\treturn -EFAULT;\n\n\tifc.ifc_len = ifc32.ifc_len;\n\tifc.ifc_req = compat_ptr(ifc32.ifcbuf);\n\n\trtnl_lock();\n\terr = dev_ifconf(net, &ifc, sizeof(struct compat_ifreq));\n\trtnl_unlock();\n\tif (err)\n\t\treturn err;\n\n\tifc32.ifc_len = ifc.ifc_len;\n\tif (copy_to_user(uifc32, &ifc32, sizeof(struct compat_ifconf)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n",
        "post_patch": "static int compat_dev_ifconf(struct net *net, struct compat_ifconf __user *uifc32)\n{\n\tstruct compat_ifconf ifc32;\n\tstruct ifconf ifc;\n\tint err;\n\n\tif (copy_from_user(&ifc32, uifc32, sizeof(struct compat_ifconf)))\n\t\treturn -EFAULT;\n\n\tifc.ifc_len = ifc32.ifc_len;\n\tifc.ifc_req = compat_ptr(ifc32.ifcbuf);\n\n\trtnl_lock();\n\terr = dev_ifconf(net, &ifc, sizeof(struct compat_ifreq));\n\trtnl_unlock();\n\tif (err)\n\t\treturn err;\n\n\tifc32.ifc_len = ifc.ifc_len;\n\tif (copy_to_user(uifc32, &ifc32, sizeof(struct compat_ifconf)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n",
        "post_patch_with_fix": "static int compat_dev_ifconf(struct net *net, struct compat_ifconf __user *uifc32)\n{\n\tstruct compat_ifconf ifc32;\n\tstruct ifconf ifc;\n\tint err;\n\n\tif (copy_from_user(&ifc32, uifc32, sizeof(struct compat_ifconf)))\n\t\treturn -EFAULT;\n\n\tifc.ifc_len = ifc32.ifc_len;\n\tifc.ifc_req = compat_ptr(ifc32.ifcbuf);\n\n\trtnl_lock();\n\terr = dev_ifconf(net, &ifc, sizeof(struct compat_ifreq));\n\trtnl_unlock();\n\tif (err)\n\t\treturn err;\n\n\tifc32.ifc_len = ifc.ifc_len;\n\tif (copy_to_user(uifc32, &ifc32, sizeof(struct compat_ifconf)))\n\t\treturn -EFAULT;\n\n\treturn 0;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int muscle_create_directory(sc_card_t *card, sc_file_t *file)\n{\n\tmscfs_t *fs = MUSCLE_FS(card);\n\tmsc_id objectId;\n\tu8* oid = objectId.id;\n\tunsigned id = file->id;\n\tunsigned short read_perm = 0, write_perm = 0, delete_perm = 0;\n\tint objectSize;\n\tint r;\n\tif(id == 0) /* No null name files */\n\t\treturn SC_ERROR_INVALID_ARGUMENTS;\n\n\t/* No nesting directories */\n\tif(fs->currentPath[0] != 0x3F || fs->currentPath[1] != 0x00)\n\t\treturn SC_ERROR_NOT_SUPPORTED;\n\toid[0] = ((id & 0xFF00) >> 8) & 0xFF;\n\toid[1] = id & 0xFF;\n\toid[2] = oid[3] = 0;\n\n\tobjectSize = file->size;\n\n\tmuscle_parse_acls(file, &read_perm, &write_perm, &delete_perm);\n\tr = msc_create_object(card, objectId, objectSize, read_perm, write_perm, delete_perm);\n\tmscfs_clear_cache(fs);\n\tif(r >= 0) return 0;\n\treturn r;\n}\n",
        "post_patch": "static int muscle_create_directory(sc_card_t *card, sc_file_t *file)\n{\n\tmscfs_t *fs = MUSCLE_FS(card);\n\tmsc_id objectId;\n\tu8* oid = objectId.id;\n\tunsigned id = file->id;\n\tunsigned short read_perm = 0, write_perm = 0, delete_perm = 0;\n\tint objectSize;\n\tint r;\n\tif(id == 0) /* No null name files */\n\t\treturn SC_ERROR_INVALID_ARGUMENTS;\n\n\t/* No nesting directories */\n\tif(fs->currentPath[0] != 0x3F || fs->currentPath[1] != 0x00)\n\t\treturn SC_ERROR_NOT_SUPPORTED;\n\toid[0] = ((id & 0xFF00) >> 8) & 0xFF;\n\toid[1] = id & 0xFF;\n\toid[2] = oid[3] = 0;\n\n\tobjectSize = file->size;\n\n\tmuscle_parse_acls(file, &read_perm, &write_perm, &delete_perm);\n\tr = msc_create_object(card, objectId, objectSize, read_perm, write_perm, delete_perm);\n\tmscfs_clear_cache(fs);\n\tif(r >= 0) return 0;\n\treturn r;\n}\n",
        "post_patch_with_fix": "static int muscle_create_directory(sc_card_t *card, sc_file_t *file)\n{\n\tmscfs_t *fs = MUSCLE_FS(card);\n\tmsc_id objectId;\n\tu8* oid = objectId.id;\n\tunsigned id = file->id;\n\tunsigned short read_perm = 0, write_perm = 0, delete_perm = 0;\n\tint objectSize;\n\tint r;\n\tif(id == 0) /* No null name files */\n\t\treturn SC_ERROR_INVALID_ARGUMENTS;\n\n\t/* No nesting directories */\n\tif(fs->currentPath[0] != 0x3F || fs->currentPath[1] != 0x00)\n\t\treturn SC_ERROR_NOT_SUPPORTED;\n\toid[0] = ((id & 0xFF00) >> 8) & 0xFF;\n\toid[1] = id & 0xFF;\n\toid[2] = oid[3] = 0;\n\n\tobjectSize = file->size;\n\n\tmuscle_parse_acls(file, &read_perm, &write_perm, &delete_perm);\n\tr = msc_create_object(card, objectId, objectSize, read_perm, write_perm, delete_perm);\n\tmscfs_clear_cache(fs);\n\tif(r >= 0) return 0;\n\treturn r;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void ServiceWorkerContextCore::OnRegistrationFinishedForCheckHasServiceWorker(\n    ServiceWorkerContext::CheckHasServiceWorkerCallback callback,\n    scoped_refptr<ServiceWorkerRegistration> registration) {\n  if (!registration->active_version() && !registration->waiting_version()) {\n    std::move(callback).Run(ServiceWorkerCapability::NO_SERVICE_WORKER);\n    return;\n  }\n\n  CheckFetchHandlerOfInstalledServiceWorker(std::move(callback), registration);\n}\n",
        "post_patch": "void ServiceWorkerContextCore::OnRegistrationFinishedForCheckHasServiceWorker(\n    ServiceWorkerContext::CheckHasServiceWorkerCallback callback,\n    scoped_refptr<ServiceWorkerRegistration> registration) {\n  if (!registration->active_version() && !registration->waiting_version()) {\n    std::move(callback).Run(ServiceWorkerCapability::NO_SERVICE_WORKER);\n    return;\n  }\n\n  CheckFetchHandlerOfInstalledServiceWorker(std::move(callback), registration);\n}\n",
        "post_patch_with_fix": "void ServiceWorkerContextCore::OnRegistrationFinishedForCheckHasServiceWorker(\n    ServiceWorkerContext::CheckHasServiceWorkerCallback callback,\n    scoped_refptr<ServiceWorkerRegistration> registration) {\n  if (!registration->active_version() && !registration->waiting_version()) {\n    std::move(callback).Run(ServiceWorkerCapability::NO_SERVICE_WORKER);\n    return;\n  }\n\n  CheckFetchHandlerOfInstalledServiceWorker(std::move(callback), registration);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "static int packet_do_bind(struct sock *sk, const char *name, int ifindex,\n\t\t\t  __be16 proto)\n{\n\tstruct packet_sock *po = pkt_sk(sk);\n\tstruct net_device *dev_curr;\n\t__be16 proto_curr;\n\tbool need_rehook;\n\tstruct net_device *dev = NULL;\n \tint ret = 0;\n \tbool unlisted = false;\n \n\tif (po->fanout)\n\t\treturn -EINVAL;\n \tlock_sock(sk);\n \tspin_lock(&po->bind_lock);\n \trcu_read_lock();\n \n \tif (name) {\n \t\tdev = dev_get_by_name_rcu(sock_net(sk), name);\n \t\tif (!dev) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_unlock;\n\t\t}\n\t} else if (ifindex) {\n\t\tdev = dev_get_by_index_rcu(sock_net(sk), ifindex);\n\t\tif (!dev) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (dev)\n\t\tdev_hold(dev);\n\n\tproto_curr = po->prot_hook.type;\n\tdev_curr = po->prot_hook.dev;\n\n\tneed_rehook = proto_curr != proto || dev_curr != dev;\n\n\tif (need_rehook) {\n\t\tif (po->running) {\n\t\t\trcu_read_unlock();\n\t\t\t__unregister_prot_hook(sk, true);\n\t\t\trcu_read_lock();\n\t\t\tdev_curr = po->prot_hook.dev;\n\t\t\tif (dev)\n\t\t\t\tunlisted = !dev_get_by_index_rcu(sock_net(sk),\n\t\t\t\t\t\t\t\t dev->ifindex);\n\t\t}\n\n\t\tpo->num = proto;\n\t\tpo->prot_hook.type = proto;\n\n\t\tif (unlikely(unlisted)) {\n\t\t\tdev_put(dev);\n\t\t\tpo->prot_hook.dev = NULL;\n\t\t\tpo->ifindex = -1;\n\t\t\tpacket_cached_dev_reset(po);\n\t\t} else {\n\t\t\tpo->prot_hook.dev = dev;\n\t\t\tpo->ifindex = dev ? dev->ifindex : 0;\n\t\t\tpacket_cached_dev_assign(po, dev);\n\t\t}\n\t}\n\tif (dev_curr)\n\t\tdev_put(dev_curr);\n\n\tif (proto == 0 || !need_rehook)\n\t\tgoto out_unlock;\n\n\tif (!unlisted && (!dev || (dev->flags & IFF_UP))) {\n\t\tregister_prot_hook(sk);\n\t} else {\n\t\tsk->sk_err = ENETDOWN;\n\t\tif (!sock_flag(sk, SOCK_DEAD))\n\t\t\tsk->sk_error_report(sk);\n\t}\n\nout_unlock:\n\trcu_read_unlock();\n\tspin_unlock(&po->bind_lock);\n\trelease_sock(sk);\n\treturn ret;\n}\n",
        "post_patch": "static int packet_do_bind(struct sock *sk, const char *name, int ifindex,\n\t\t\t  __be16 proto)\n{\n\tstruct packet_sock *po = pkt_sk(sk);\n\tstruct net_device *dev_curr;\n\t__be16 proto_curr;\n\tbool need_rehook;\n\tstruct net_device *dev = NULL;\n \tint ret = 0;\n \tbool unlisted = false;\n \n \tlock_sock(sk);\n \tspin_lock(&po->bind_lock);\n \trcu_read_lock();\n \n\tif (po->fanout) {\n\t\tret = -EINVAL;\n\t\tgoto out_unlock;\n\t}\n\n \tif (name) {\n \t\tdev = dev_get_by_name_rcu(sock_net(sk), name);\n \t\tif (!dev) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_unlock;\n\t\t}\n\t} else if (ifindex) {\n\t\tdev = dev_get_by_index_rcu(sock_net(sk), ifindex);\n\t\tif (!dev) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (dev)\n\t\tdev_hold(dev);\n\n\tproto_curr = po->prot_hook.type;\n\tdev_curr = po->prot_hook.dev;\n\n\tneed_rehook = proto_curr != proto || dev_curr != dev;\n\n\tif (need_rehook) {\n\t\tif (po->running) {\n\t\t\trcu_read_unlock();\n\t\t\t__unregister_prot_hook(sk, true);\n\t\t\trcu_read_lock();\n\t\t\tdev_curr = po->prot_hook.dev;\n\t\t\tif (dev)\n\t\t\t\tunlisted = !dev_get_by_index_rcu(sock_net(sk),\n\t\t\t\t\t\t\t\t dev->ifindex);\n\t\t}\n\n\t\tpo->num = proto;\n\t\tpo->prot_hook.type = proto;\n\n\t\tif (unlikely(unlisted)) {\n\t\t\tdev_put(dev);\n\t\t\tpo->prot_hook.dev = NULL;\n\t\t\tpo->ifindex = -1;\n\t\t\tpacket_cached_dev_reset(po);\n\t\t} else {\n\t\t\tpo->prot_hook.dev = dev;\n\t\t\tpo->ifindex = dev ? dev->ifindex : 0;\n\t\t\tpacket_cached_dev_assign(po, dev);\n\t\t}\n\t}\n\tif (dev_curr)\n\t\tdev_put(dev_curr);\n\n\tif (proto == 0 || !need_rehook)\n\t\tgoto out_unlock;\n\n\tif (!unlisted && (!dev || (dev->flags & IFF_UP))) {\n\t\tregister_prot_hook(sk);\n\t} else {\n\t\tsk->sk_err = ENETDOWN;\n\t\tif (!sock_flag(sk, SOCK_DEAD))\n\t\t\tsk->sk_error_report(sk);\n\t}\n\nout_unlock:\n\trcu_read_unlock();\n\tspin_unlock(&po->bind_lock);\n\trelease_sock(sk);\n\treturn ret;\n}\n",
        "post_patch_with_fix": "static int packet_do_bind(struct sock *sk, const char *name, int ifindex,\n\t\t\t  __be16 proto)\n{\n\tstruct packet_sock *po = pkt_sk(sk);\n\tstruct net_device *dev_curr;\n\t__be16 proto_curr;\n\tbool need_rehook;\n\tstruct net_device *dev = NULL;\n \tint ret = 0;\n \tbool unlisted = false;\n \n//flaw_line_below:\n\tif (po->fanout)\n//flaw_line_below:\n\t\treturn -EINVAL;\n//flaw_line_below:\n\n \tlock_sock(sk);\n \tspin_lock(&po->bind_lock);\n \trcu_read_lock();\n \n//fix_flaw_line_below:\n//\tif (po->fanout) {\n//fix_flaw_line_below:\n//\t\tret = -EINVAL;\n//fix_flaw_line_below:\n//\t\tgoto out_unlock;\n//fix_flaw_line_below:\n//\t}\n//fix_flaw_line_below:\n//\n \tif (name) {\n \t\tdev = dev_get_by_name_rcu(sock_net(sk), name);\n \t\tif (!dev) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_unlock;\n\t\t}\n\t} else if (ifindex) {\n\t\tdev = dev_get_by_index_rcu(sock_net(sk), ifindex);\n\t\tif (!dev) {\n\t\t\tret = -ENODEV;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (dev)\n\t\tdev_hold(dev);\n\n\tproto_curr = po->prot_hook.type;\n\tdev_curr = po->prot_hook.dev;\n\n\tneed_rehook = proto_curr != proto || dev_curr != dev;\n\n\tif (need_rehook) {\n\t\tif (po->running) {\n\t\t\trcu_read_unlock();\n\t\t\t__unregister_prot_hook(sk, true);\n\t\t\trcu_read_lock();\n\t\t\tdev_curr = po->prot_hook.dev;\n\t\t\tif (dev)\n\t\t\t\tunlisted = !dev_get_by_index_rcu(sock_net(sk),\n\t\t\t\t\t\t\t\t dev->ifindex);\n\t\t}\n\n\t\tpo->num = proto;\n\t\tpo->prot_hook.type = proto;\n\n\t\tif (unlikely(unlisted)) {\n\t\t\tdev_put(dev);\n\t\t\tpo->prot_hook.dev = NULL;\n\t\t\tpo->ifindex = -1;\n\t\t\tpacket_cached_dev_reset(po);\n\t\t} else {\n\t\t\tpo->prot_hook.dev = dev;\n\t\t\tpo->ifindex = dev ? dev->ifindex : 0;\n\t\t\tpacket_cached_dev_assign(po, dev);\n\t\t}\n\t}\n\tif (dev_curr)\n\t\tdev_put(dev_curr);\n\n\tif (proto == 0 || !need_rehook)\n\t\tgoto out_unlock;\n\n\tif (!unlisted && (!dev || (dev->flags & IFF_UP))) {\n\t\tregister_prot_hook(sk);\n\t} else {\n\t\tsk->sk_err = ENETDOWN;\n\t\tif (!sock_flag(sk, SOCK_DEAD))\n\t\t\tsk->sk_error_report(sk);\n\t}\n\nout_unlock:\n\trcu_read_unlock();\n\tspin_unlock(&po->bind_lock);\n\trelease_sock(sk);\n\treturn ret;\n}\n",
        "label": 1
    },
    {
        "pre_patch": "int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\n\tif (icsk->icsk_af_ops->compat_getsockopt)\n\t\treturn icsk->icsk_af_ops->compat_getsockopt(sk, level, optname,\n\t\t\t\t\t\t\t    optval, optlen);\n\treturn icsk->icsk_af_ops->getsockopt(sk, level, optname,\n\t\t\t\t\t     optval, optlen);\n}\n",
        "post_patch": "int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\n\tif (icsk->icsk_af_ops->compat_getsockopt)\n\t\treturn icsk->icsk_af_ops->compat_getsockopt(sk, level, optname,\n\t\t\t\t\t\t\t    optval, optlen);\n\treturn icsk->icsk_af_ops->getsockopt(sk, level, optname,\n\t\t\t\t\t     optval, optlen);\n}\n",
        "post_patch_with_fix": "int inet_csk_compat_getsockopt(struct sock *sk, int level, int optname,\n\t\t\t       char __user *optval, int __user *optlen)\n{\n\tconst struct inet_connection_sock *icsk = inet_csk(sk);\n\n\tif (icsk->icsk_af_ops->compat_getsockopt)\n\t\treturn icsk->icsk_af_ops->compat_getsockopt(sk, level, optname,\n\t\t\t\t\t\t\t    optval, optlen);\n\treturn icsk->icsk_af_ops->getsockopt(sk, level, optname,\n\t\t\t\t\t     optval, optlen);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "nfsd_inject_forget_clients(u64 max)\n{\n\tu64 count = 0;\n\tstruct nfs4_client *clp, *next;\n\tstruct nfsd_net *nn = net_generic(current->nsproxy->net_ns,\n\t\t\t\t\t\tnfsd_net_id);\n\tLIST_HEAD(reaplist);\n\n\tif (!nfsd_netns_ready(nn))\n\t\treturn count;\n\n\tspin_lock(&nn->client_lock);\n\tlist_for_each_entry_safe(clp, next, &nn->client_lru, cl_lru) {\n\t\tif (mark_client_expired_locked(clp) == nfs_ok) {\n\t\t\tlist_add(&clp->cl_lru, &reaplist);\n\t\t\tif (max != 0 && ++count >= max)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&nn->client_lock);\n\n\tlist_for_each_entry_safe(clp, next, &reaplist, cl_lru)\n\t\texpire_client(clp);\n\n\treturn count;\n}\n",
        "post_patch": "nfsd_inject_forget_clients(u64 max)\n{\n\tu64 count = 0;\n\tstruct nfs4_client *clp, *next;\n\tstruct nfsd_net *nn = net_generic(current->nsproxy->net_ns,\n\t\t\t\t\t\tnfsd_net_id);\n\tLIST_HEAD(reaplist);\n\n\tif (!nfsd_netns_ready(nn))\n\t\treturn count;\n\n\tspin_lock(&nn->client_lock);\n\tlist_for_each_entry_safe(clp, next, &nn->client_lru, cl_lru) {\n\t\tif (mark_client_expired_locked(clp) == nfs_ok) {\n\t\t\tlist_add(&clp->cl_lru, &reaplist);\n\t\t\tif (max != 0 && ++count >= max)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&nn->client_lock);\n\n\tlist_for_each_entry_safe(clp, next, &reaplist, cl_lru)\n\t\texpire_client(clp);\n\n\treturn count;\n}\n",
        "post_patch_with_fix": "nfsd_inject_forget_clients(u64 max)\n{\n\tu64 count = 0;\n\tstruct nfs4_client *clp, *next;\n\tstruct nfsd_net *nn = net_generic(current->nsproxy->net_ns,\n\t\t\t\t\t\tnfsd_net_id);\n\tLIST_HEAD(reaplist);\n\n\tif (!nfsd_netns_ready(nn))\n\t\treturn count;\n\n\tspin_lock(&nn->client_lock);\n\tlist_for_each_entry_safe(clp, next, &nn->client_lru, cl_lru) {\n\t\tif (mark_client_expired_locked(clp) == nfs_ok) {\n\t\t\tlist_add(&clp->cl_lru, &reaplist);\n\t\t\tif (max != 0 && ++count >= max)\n\t\t\t\tbreak;\n\t\t}\n\t}\n\tspin_unlock(&nn->client_lock);\n\n\tlist_for_each_entry_safe(clp, next, &reaplist, cl_lru)\n\t\texpire_client(clp);\n\n\treturn count;\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void snd_pcm_period_elapsed(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_runtime *runtime;\n\tunsigned long flags;\n\n\tif (PCM_RUNTIME_CHECK(substream))\n\t\treturn;\n\truntime = substream->runtime;\n\n\tsnd_pcm_stream_lock_irqsave(substream, flags);\n\tif (!snd_pcm_running(substream) ||\n\t    snd_pcm_update_hw_ptr0(substream, 1) < 0)\n\t\tgoto _end;\n\n#ifdef CONFIG_SND_PCM_TIMER\n\tif (substream->timer_running)\n \t\tsnd_timer_interrupt(substream->timer, 1);\n #endif\n  _end:\n\tsnd_pcm_stream_unlock_irqrestore(substream, flags);\n \tkill_fasync(&runtime->fasync, SIGIO, POLL_IN);\n }\n",
        "post_patch": "void snd_pcm_period_elapsed(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_runtime *runtime;\n\tunsigned long flags;\n\n\tif (PCM_RUNTIME_CHECK(substream))\n\t\treturn;\n\truntime = substream->runtime;\n\n\tsnd_pcm_stream_lock_irqsave(substream, flags);\n\tif (!snd_pcm_running(substream) ||\n\t    snd_pcm_update_hw_ptr0(substream, 1) < 0)\n\t\tgoto _end;\n\n#ifdef CONFIG_SND_PCM_TIMER\n\tif (substream->timer_running)\n \t\tsnd_timer_interrupt(substream->timer, 1);\n #endif\n  _end:\n \tkill_fasync(&runtime->fasync, SIGIO, POLL_IN);\n\tsnd_pcm_stream_unlock_irqrestore(substream, flags);\n }\n",
        "post_patch_with_fix": "void snd_pcm_period_elapsed(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_runtime *runtime;\n\tunsigned long flags;\n\n\tif (PCM_RUNTIME_CHECK(substream))\n\t\treturn;\n\truntime = substream->runtime;\n\n\tsnd_pcm_stream_lock_irqsave(substream, flags);\n\tif (!snd_pcm_running(substream) ||\n\t    snd_pcm_update_hw_ptr0(substream, 1) < 0)\n\t\tgoto _end;\n\n#ifdef CONFIG_SND_PCM_TIMER\n\tif (substream->timer_running)\n \t\tsnd_timer_interrupt(substream->timer, 1);\n #endif\n  _end:\n//flaw_line_below:\n\tsnd_pcm_stream_unlock_irqrestore(substream, flags);\n \tkill_fasync(&runtime->fasync, SIGIO, POLL_IN);\n//fix_flaw_line_below:\n//\tsnd_pcm_stream_unlock_irqrestore(substream, flags);\n }\n",
        "label": 1
    },
    {
        "pre_patch": "static struct bio_map_data *bio_alloc_map_data(unsigned int iov_count,\n\t\t\t\t\t       gfp_t gfp_mask)\n{\n\tif (iov_count > UIO_MAXIOV)\n\t\treturn NULL;\n\n\treturn kmalloc(sizeof(struct bio_map_data) +\n\t\t       sizeof(struct iovec) * iov_count, gfp_mask);\n}\n",
        "post_patch": "static struct bio_map_data *bio_alloc_map_data(unsigned int iov_count,\n\t\t\t\t\t       gfp_t gfp_mask)\n{\n\tif (iov_count > UIO_MAXIOV)\n\t\treturn NULL;\n\n\treturn kmalloc(sizeof(struct bio_map_data) +\n\t\t       sizeof(struct iovec) * iov_count, gfp_mask);\n}\n",
        "post_patch_with_fix": "static struct bio_map_data *bio_alloc_map_data(unsigned int iov_count,\n\t\t\t\t\t       gfp_t gfp_mask)\n{\n\tif (iov_count > UIO_MAXIOV)\n\t\treturn NULL;\n\n\treturn kmalloc(sizeof(struct bio_map_data) +\n\t\t       sizeof(struct iovec) * iov_count, gfp_mask);\n}\n",
        "label": 0
    },
    {
        "pre_patch": "void NavigationControllerImpl::DiscardNonCommittedEntries() {\n  bool transient = transient_entry_index_ != -1;\n  DiscardNonCommittedEntriesInternal();\n\n  if (transient) {\n    delegate_->NotifyNavigationStateChanged(INVALIDATE_TYPE_ALL);\n  }\n}\n",
        "post_patch": "void NavigationControllerImpl::DiscardNonCommittedEntries() {\n  bool transient = transient_entry_index_ != -1;\n  DiscardNonCommittedEntriesInternal();\n\n  if (transient) {\n    delegate_->NotifyNavigationStateChanged(INVALIDATE_TYPE_ALL);\n  }\n}\n",
        "post_patch_with_fix": "void NavigationControllerImpl::DiscardNonCommittedEntries() {\n  bool transient = transient_entry_index_ != -1;\n  DiscardNonCommittedEntriesInternal();\n\n  // If there was a transient entry, invalidate everything so the new active\n  // entry state is shown.\n  if (transient) {\n    delegate_->NotifyNavigationStateChanged(INVALIDATE_TYPE_ALL);\n  }\n}\n",
        "label": 0
    },
    {
        "pre_patch": "bool blk_mq_can_queue(struct blk_mq_hw_ctx *hctx)\n{\n\treturn blk_mq_has_free_tags(hctx->tags);\n}\n",
        "post_patch": "bool blk_mq_can_queue(struct blk_mq_hw_ctx *hctx)\n{\n\treturn blk_mq_has_free_tags(hctx->tags);\n}\n",
        "post_patch_with_fix": "bool blk_mq_can_queue(struct blk_mq_hw_ctx *hctx)\n{\n\treturn blk_mq_has_free_tags(hctx->tags);\n}\n",
        "label": 0
    }
]
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "# ==============================================================================\n",
    "# GI·∫¢I PH√ÅP TRI·ªÜT ƒê·ªÇ: PATCH OUTLINES ƒê·ªÇ B·ªé QUA PYAIRPORTS\n",
    "# ==============================================================================\n",
    "print(\"üõ†Ô∏è ƒêang c√†i ƒë·∫∑t v√† patch th∆∞ vi·ªán...\")\n",
    "\n",
    "# G·ª° b·ªè ƒë·ªÉ tr√°nh xung ƒë·ªôt\n",
    "subprocess.run(\"pip uninstall -y tensorflow keras vllm\", shell=True, \n",
    "               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# C√†i ƒë·∫∑t c√°c g√≥i c·∫ßn thi·∫øt\n",
    "cmd = [\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \n",
    "    \"vllm\",\n",
    "    \"xformers\",\n",
    "    \"pyngrok\",\n",
    "    \"numpy<2.0.0\",\n",
    "    \"transformers[torch]\",\n",
    "    \"pycountry\",\n",
    "    \"outlines\"\n",
    "]\n",
    "subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL)\n",
    "\n",
    "# V√° l·ªói Cuda\n",
    "if not os.path.exists(\"/usr/local/cuda/lib64/libcuda.so\"):\n",
    "    subprocess.run(\"ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/libcuda.so\", \n",
    "                   shell=True, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# ==============================================================================\n",
    "# PATCH OUTLINES ƒê·ªÇ B·ªé QUA PYAIRPORTS\n",
    "# ==============================================================================\n",
    "def patch_outlines():\n",
    "    \"\"\"V√° file outlines/types/__init__.py ƒë·ªÉ kh√¥ng import airports\"\"\"\n",
    "    try:\n",
    "        import outlines\n",
    "        outlines_path = os.path.dirname(outlines.__file__)\n",
    "        types_init = os.path.join(outlines_path, \"types\", \"__init__.py\")\n",
    "        \n",
    "        if os.path.exists(types_init):\n",
    "            with open(types_init, 'r') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Thay ƒë·ªïi: from . import airports, countries -> from . import countries\n",
    "            if 'airports' in content:\n",
    "                new_content = content.replace(\n",
    "                    'from . import airports, countries',\n",
    "                    'from . import countries  # airports removed - pyairports not available'\n",
    "                )\n",
    "                \n",
    "                with open(types_init, 'w') as f:\n",
    "                    f.write(new_content)\n",
    "                \n",
    "                print(\"‚úÖ ƒê√£ patch outlines/types/__init__.py\")\n",
    "                return True\n",
    "        \n",
    "        print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file c·∫ßn patch\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ patch: {e}\")\n",
    "        return False\n",
    "\n",
    "# Th·ª±c hi·ªán patch\n",
    "patched = patch_outlines()\n",
    "\n",
    "# ==============================================================================\n",
    "# GI·∫¢I PH√ÅP D·ª∞ PH√íNG: T·∫†O MODULE GI·∫¢\n",
    "# ==============================================================================\n",
    "if not patched:\n",
    "    print(\"üì¶ T·∫°o module pyairports gi·∫£...\")\n",
    "    import site\n",
    "    site_packages = site.getsitepackages()[0]\n",
    "    pyairports_dir = os.path.join(site_packages, \"pyairports\")\n",
    "    os.makedirs(pyairports_dir, exist_ok=True)\n",
    "    \n",
    "    # T·∫°o __init__.py\n",
    "    with open(os.path.join(pyairports_dir, \"__init__.py\"), \"w\") as f:\n",
    "        f.write(\"# Dummy module\\n\")\n",
    "    \n",
    "    # T·∫°o airports.py v·ªõi AIRPORT_LIST r·ªóng\n",
    "    with open(os.path.join(pyairports_dir, \"airports.py\"), \"w\") as f:\n",
    "        f.write(\"AIRPORT_LIST = []  # Dummy data\\n\")\n",
    "    \n",
    "    print(\"‚úÖ ƒê√£ t·∫°o pyairports gi·∫£\")\n",
    "\n",
    "print(\"‚úÖ Ho√†n t·∫•t c√†i ƒë·∫∑t!\")\n",
    "\n",
    "# ==============================================================================\n",
    "# KH·ªûI CH·∫†Y SERVER\n",
    "# ==============================================================================\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "# Model ID ho·∫∑c ƒë∆∞·ªùng d·∫´n local\n",
    "# Ch·ªçn 1 trong c√°c model sau t√πy VRAM c·ªßa b·∫°n:\n",
    "\n",
    "# üîπ Model nh·ªè (~8GB VRAM) - Nhanh, ph√π h·ª£p GPU th∆∞·ªùng\n",
    "# MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct-AWQ\"\n",
    "\n",
    "# üîπ Model v·ª´a (~16GB VRAM) - C√¢n b·∫±ng\n",
    "# MODEL_ID = \"Qwen/Qwen2.5-14B-Instruct-AWQ\"\n",
    "\n",
    "# üîπ Model l·ªõn (~18-20GB VRAM v·ªõi AWQ) - Ph√π h·ª£p T4x2\n",
    "MODEL_ID = \"Qwen/Qwen2.5-32B-Instruct-AWQ\"\n",
    "\n",
    "# üîπ Ho·∫∑c d√πng ƒë∆∞·ªùng d·∫´n local (Kaggle dataset)\n",
    "# MODEL_ID = \"/kaggle/input/qwen-3/transformers/32b/1\"\n",
    "\n",
    "# T√™n model hi·ªÉn th·ªã trong API\n",
    "SERVED_MODEL_NAME = \"Qwen2.5-32B-Instruct-AWQ\"\n",
    "\n",
    "NGROK_AUTH_TOKEN = \"2loaj9mCBrswSefBAn7cebLdfDT_6o8gA9vCBpVDi7P3m2c2e\"\n",
    "\n",
    "# Thi·∫øt l·∫≠p Ngrok\n",
    "try:\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    ngrok.kill()\n",
    "    public_url = ngrok.connect(8000).public_url\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói Ngrok: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üöÄ SERVER INFO DASHBOARD\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ü§ñ MODEL      : {MODEL_ID}\")\n",
    "print(f\"üìõ SERVED AS  : {SERVED_MODEL_NAME}\")\n",
    "print(f\"üîó BASE URL   : {public_url}/v1\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# L·ªánh ch·∫°y Server - T·ªëi ∆∞u cho Kaggle T4x2\n",
    "command = [\n",
    "    \"python3\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n",
    "    \"--model\", MODEL_ID,\n",
    "    \"--served-model-name\", SERVED_MODEL_NAME,\n",
    "    \"--dtype\", \"float16\",             # float16 cho T4\n",
    "    \"--gpu-memory-utilization\", \"0.9\",\n",
    "    \"--tensor-parallel-size\", \"2\",    # 2 GPU T4\n",
    "    \"--enforce-eager\",                # T·∫Øt CUDA graphs, ti·∫øt ki·ªám VRAM\n",
    "    \"--max-model-len\", \"16384\",\n",
    "    \"--host\", \"0.0.0.0\",\n",
    "    \"--port\", \"8000\",\n",
    "    \"--disable-log-requests\",\n",
    "    \"--disable-log-stats\",\n",
    "]\n",
    "\n",
    "def run_server():\n",
    "    env = os.environ.copy()\n",
    "    \n",
    "    # ‚úÖ QUAN TR·ªåNG: D√πng TORCH_SDPA cho T4 (compute capability 7.5)\n",
    "    # Flash Attention 2 y√™u c·∫ßu compute capability >= 8.0\n",
    "    # XFORMERS ƒë√£ b·ªã lo·∫°i b·ªè trong vLLM 0.12.0\n",
    "    env['VLLM_ATTENTION_BACKEND'] = 'TORCH_SDPA'\n",
    "    \n",
    "    # ‚úÖ T·∫Øt V1 engine ƒë·ªÉ tr√°nh l·ªói tr√™n T4\n",
    "    env['VLLM_USE_V1'] = '0'\n",
    "    \n",
    "    print(\"‚è≥ ƒêang kh·ªüi ƒë·ªông Server (TORCH_SDPA backend cho T4)...\\n\")\n",
    "    \n",
    "    process = subprocess.Popen(\n",
    "        command,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1,\n",
    "        env=env\n",
    "    )\n",
    "    \n",
    "    # In log real-time\n",
    "    for line in process.stdout:\n",
    "        print(line, end=\"\")\n",
    "\n",
    "# Ch·∫°y server\n",
    "run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc531ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# KEEP-ALIVE LOOP - GI·ªÆ SESSION KAGGLE S·ªêNG\n",
    "# ==============================================================================\n",
    "# Ch·∫°y cell n√†y SAU KHI server ƒë√£ kh·ªüi ƒë·ªông th√†nh c√¥ng\n",
    "# V√≤ng l·∫∑p n√†y gi·ªØ cho session Kaggle kh√¥ng b·ªã timeout\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"üîÑ B·∫ÆT ƒê·∫¶U KEEP-ALIVE LOOP\")\n",
    "print(\"‚ö†Ô∏è  ƒê·ª™NG ƒê√ìNG TAB N√ÄY! ƒê·ªÉ gi·ªØ session Kaggle s·ªëng.\\n\")\n",
    "\n",
    "while True:\n",
    "    print(\"‚öôÔ∏è Still running...\")\n",
    "    time.sleep(60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:00:44.427159Z",
     "iopub.status.busy": "2025-11-18T12:00:44.426948Z",
     "iopub.status.idle": "2025-11-18T12:13:48.196569Z",
     "shell.execute_reply": "2025-11-18T12:13:48.195804Z",
     "shell.execute_reply.started": "2025-11-18T12:00:44.427141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q torch_geometric\n",
    "!pip install -q torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:48.199144Z",
     "iopub.status.busy": "2025-11-18T12:13:48.198804Z",
     "iopub.status.idle": "2025-11-18T12:13:57.433334Z",
     "shell.execute_reply": "2025-11-18T12:13:57.432677Z",
     "shell.execute_reply.started": "2025-11-18T12:13:48.199118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter, Linear, BatchNorm1d\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn import MessagePassing, GATConv, global_add_pool\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score, confusion_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.434404Z",
     "iopub.status.busy": "2025-11-18T12:13:57.434049Z",
     "iopub.status.idle": "2025-11-18T12:13:57.445588Z",
     "shell.execute_reply": "2025-11-18T12:13:57.444800Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.434385Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GitHub**\n",
    "https://github.com/yongduosui/CAL/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.447183Z",
     "iopub.status.busy": "2025-11-18T12:13:57.446588Z",
     "iopub.status.idle": "2025-11-18T12:13:57.462915Z",
     "shell.execute_reply": "2025-11-18T12:13:57.462224Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.447154Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GCNConv(MessagePassing):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 improved=False,\n",
    "                 cached=False,\n",
    "                 bias=True,\n",
    "                 edge_norm=True,\n",
    "                 gfn=False):\n",
    "        super(GCNConv, self).__init__('add')\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.improved = improved\n",
    "        self.cached = cached\n",
    "        self.cached_result = None\n",
    "        self.edge_norm = edge_norm\n",
    "        self.gfn = gfn\n",
    "        self.message_mask = None\n",
    "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight)\n",
    "        zeros(self.bias)\n",
    "        self.cached_result = None\n",
    "\n",
    "    @staticmethod\n",
    "    def norm(edge_index, num_nodes, edge_weight, improved=False, dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ),\n",
    "                                     dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "        \n",
    "        edge_weight = edge_weight.view(-1)\n",
    "        \n",
    "        \n",
    "        assert edge_weight.size(0) == edge_index.size(1)\n",
    "        \n",
    "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n",
    "        # Add edge_weight for loop edges.\n",
    "        loop_weight = torch.full((num_nodes, ),\n",
    "                                 1 if not improved else 2,\n",
    "                                 dtype=edge_weight.dtype,\n",
    "                                 device=edge_weight.device)\n",
    "        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "        \n",
    "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\"\"\"\n",
    "        \n",
    "        x = torch.matmul(x, self.weight)\n",
    "        if self.gfn:\n",
    "            return x\n",
    "    \n",
    "        if not self.cached or self.cached_result is None:\n",
    "            if self.edge_norm:\n",
    "                edge_index, norm = GCNConv.norm(\n",
    "                    edge_index, \n",
    "                    x.size(0), \n",
    "                    edge_weight, \n",
    "                    self.improved, \n",
    "                    x.dtype)\n",
    "            else:\n",
    "                norm = None\n",
    "            self.cached_result = edge_index, norm\n",
    "\n",
    "        edge_index, norm = self.cached_result\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "\n",
    "        if self.edge_norm:\n",
    "            return norm.view(-1, 1) * x_j\n",
    "        else:\n",
    "            return x_j\n",
    "        \n",
    "    def update(self, aggr_out):\n",
    "        if self.bias is not None:\n",
    "            aggr_out = aggr_out + self.bias\n",
    "        return aggr_out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n",
    "                                   self.out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.464062Z",
     "iopub.status.busy": "2025-11-18T12:13:57.463785Z",
     "iopub.status.idle": "2025-11-18T12:13:57.485603Z",
     "shell.execute_reply": "2025-11-18T12:13:57.484806Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.464034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CausalGAT(torch.nn.Module):\n",
    "    def __init__(self, num_features,\n",
    "                       num_classes,\n",
    "                       tokens_dim=768,\n",
    "                       hidden_dim=256,\n",
    "                       num_conv_layers=3,\n",
    "                       fusion_mode=None,\n",
    "                       head=4, \n",
    "                       dropout=0.3):\n",
    "        super(CausalGAT, self).__init__()\n",
    "        self.cat_or_add = \"add\"\n",
    "        self.fusion_mode = fusion_mode\n",
    "        self.global_pool = global_add_pool\n",
    "        self.dropout = dropout\n",
    "        GConv = partial(GCNConv, edge_norm=True, gfn=False)\n",
    "\n",
    "        hidden_in = num_features\n",
    "        self.num_classes = num_classes\n",
    "        hidden_out = num_classes\n",
    "        self.fc_num = 222\n",
    "\n",
    "        if self.fusion_mode == 'concat':\n",
    "            total_input_dim = num_features + tokens_dim\n",
    "            self.concat_proj = Linear(total_input_dim, hidden_dim)\n",
    "        elif self.fusion_mode == 'gated':\n",
    "            self.feat_proj_gate = Linear(num_features, hidden_dim)\n",
    "            self.code_proj_gate = Linear(tokens_dim, hidden_dim)\n",
    "            self.gate_linear = Linear(num_features + tokens_dim, hidden_dim)\n",
    "        elif self.fusion_mode == 'cross_atten':\n",
    "            self.q_proj = Linear(num_features, hidden_dim)\n",
    "            self.k_proj = Linear(tokens_dim, hidden_dim)\n",
    "            self.v_proj = Linear(tokens_dim, hidden_dim)\n",
    "            self.cross_attn = nn.MultiheadAttention(\n",
    "                embed_dim=hidden_dim, \n",
    "                num_heads=head, \n",
    "                batch_first=True\n",
    "            )\n",
    "\n",
    "        if self.fusion_mode is not None:\n",
    "            self.bn_feat = BatchNorm1d(hidden_dim)\n",
    "            self.conv_feat = GCNConv(hidden_dim, hidden_dim, gfn=True)\n",
    "        else:\n",
    "            self.bn_feat = BatchNorm1d(hidden_in)\n",
    "            self.conv_feat = GCNConv(hidden_in, hidden_dim, gfn=True)\n",
    "        \n",
    "        self.bns_conv = torch.nn.ModuleList()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(num_conv_layers):\n",
    "            self.bns_conv.append(BatchNorm1d(hidden_dim))\n",
    "            self.convs.append(GATConv(hidden_dim, int(hidden_dim / head), heads=head, dropout=dropout))\n",
    "\n",
    "        self.edge_att_mlp = Linear(hidden_dim * 2, 2)\n",
    "        self.node_att_mlp = Linear(hidden_dim, 2)\n",
    "        self.bnc = BatchNorm1d(hidden_dim)\n",
    "        self.bno= BatchNorm1d(hidden_dim)\n",
    "        self.context_convs = GConv(hidden_dim, hidden_dim)\n",
    "        self.objects_convs = GConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        # context mlp\n",
    "        self.fc1_bn_c = BatchNorm1d(hidden_dim)\n",
    "        self.fc1_c = Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2_bn_c = BatchNorm1d(hidden_dim)\n",
    "        self.fc2_c = Linear(hidden_dim, hidden_out)\n",
    "        # object mlp\n",
    "        self.fc1_bn_o = BatchNorm1d(hidden_dim)\n",
    "        self.fc1_o = Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2_bn_o = BatchNorm1d(hidden_dim)\n",
    "        self.fc2_o = Linear(hidden_dim, hidden_out)\n",
    "        # random mlp\n",
    "        if self.cat_or_add == \"cat\":\n",
    "            self.fc1_bn_co = BatchNorm1d(hidden_dim * 2)\n",
    "            self.fc1_co = Linear(hidden_dim * 2, hidden_dim)\n",
    "            self.fc2_bn_co = BatchNorm1d(hidden_dim)\n",
    "            self.fc2_co = Linear(hidden_dim, hidden_out)\n",
    "\n",
    "        elif self.cat_or_add == \"add\":\n",
    "            self.fc1_bn_co = BatchNorm1d(hidden_dim)\n",
    "            self.fc1_co = Linear(hidden_dim, hidden_dim)\n",
    "            self.fc2_bn_co = BatchNorm1d(hidden_dim)\n",
    "            self.fc2_co = Linear(hidden_dim, hidden_out)\n",
    "        else:\n",
    "            assert False\n",
    "        \n",
    "        # BN initialization.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (torch.nn.BatchNorm1d)):\n",
    "                torch.nn.init.constant_(m.weight, 1)\n",
    "                torch.nn.init.constant_(m.bias, 0.0001)\n",
    "\n",
    "    def forward(self, data, eval_random=True):\n",
    "\n",
    "        x_features = data.x if data.x is not None else data.feat\n",
    "        x_tokens = data.tokens if data.tokens is not None else data.feat\n",
    "        edge_index, batch = data.edge_index, data.batch\n",
    "        row, col = edge_index\n",
    "\n",
    "        if self.fusion_mode == 'concat':\n",
    "            x_concat = torch.cat([x_features, x_tokens], dim=-1)\n",
    "            x = self.concat_proj(x_concat)\n",
    "        elif self.fusion_mode == 'gated':\n",
    "            x_feat_proj = self.feat_proj_gate(x_features)\n",
    "            x_code_proj = self.code_proj_gate(x_tokens)\n",
    "            gate_input = torch.cat([x_features, x_tokens], dim=-1)\n",
    "            g = torch.sigmoid(self.gate_linear(gate_input))\n",
    "            x = g * x_feat_proj + (1.0 - g) * x_code_proj\n",
    "        elif self.fusion_mode == 'cross_atten':\n",
    "            q = self.q_proj(x_features).unsqueeze(1)\n",
    "            k = self.k_proj(x_tokens).unsqueeze(1)\n",
    "            v = self.v_proj(x_tokens).unsqueeze(1)\n",
    "            attn_output, _ = self.cross_attn(q, k, v)\n",
    "            x = attn_output.squeeze(1)\n",
    "        else:\n",
    "            x = x_features\n",
    "        \n",
    "        x = self.bn_feat(x)\n",
    "        x = F.relu(self.conv_feat(x, edge_index))\n",
    "        \n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = self.bns_conv[i](x)\n",
    "            x = F.relu(conv(x, edge_index))\n",
    "        \n",
    "        edge_rep = torch.cat([x[row], x[col]], dim=-1)\n",
    "        edge_att = F.softmax(self.edge_att_mlp(edge_rep), dim=-1)\n",
    "        edge_weight_c = edge_att[:, 0]\n",
    "        edge_weight_o = edge_att[:, 1]\n",
    "\n",
    "        node_att = F.softmax(self.node_att_mlp(x), dim=-1)\n",
    "        xc = node_att[:, 0].view(-1, 1) * x\n",
    "        xo = node_att[:, 1].view(-1, 1) * x\n",
    "        xc = F.relu(self.context_convs(self.bnc(xc), edge_index, edge_weight_c))\n",
    "        xo = F.relu(self.objects_convs(self.bno(xo), edge_index, edge_weight_o))\n",
    "\n",
    "        xc = self.global_pool(xc, batch)\n",
    "        xo = self.global_pool(xo, batch)\n",
    "        \n",
    "        xc_logis = self.context_readout_layer(xc)\n",
    "        xo_logis = self.objects_readout_layer(xo)\n",
    "        xco_logis = self.random_readout_layer(xc, xo, eval_random=eval_random)\n",
    "        return xc_logis, xo_logis, xco_logis\n",
    "\n",
    "    def context_readout_layer(self, x):\n",
    "        \n",
    "        x = self.fc1_bn_c(x)\n",
    "        x = self.fc1_c(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2_bn_c(x)\n",
    "        x = self.fc2_c(x)\n",
    "        x_logis = F.log_softmax(x, dim=-1)\n",
    "        return x_logis\n",
    "\n",
    "    def objects_readout_layer(self, x):\n",
    "   \n",
    "        x = self.fc1_bn_o(x)\n",
    "        x = self.fc1_o(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2_bn_o(x)\n",
    "        x = self.fc2_o(x)\n",
    "        x_logis = F.log_softmax(x, dim=-1)\n",
    "        return x_logis\n",
    "\n",
    "    def random_readout_layer(self, xc, xo, eval_random):\n",
    "\n",
    "        num = xc.shape[0]\n",
    "        l = [i for i in range(num)]\n",
    "        if eval_random:\n",
    "            random.shuffle(l)\n",
    "        random_idx = torch.tensor(l)\n",
    "        \n",
    "        if self.cat_or_add == \"cat\":\n",
    "            x = torch.cat((xc[random_idx], xo), dim=1)\n",
    "        else:\n",
    "            x = xc[random_idx] + xo\n",
    "\n",
    "        x = self.fc1_bn_co(x)\n",
    "        x = self.fc1_co(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2_bn_co(x)\n",
    "        x = self.fc2_co(x)\n",
    "        x_logis = F.log_softmax(x, dim=-1)\n",
    "        return x_logis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.486780Z",
     "iopub.status.busy": "2025-11-18T12:13:57.486512Z",
     "iopub.status.idle": "2025-11-18T12:13:57.503764Z",
     "shell.execute_reply": "2025-11-18T12:13:57.503061Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.486753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_class_weights(label_list, device):\n",
    "    \"\"\"\n",
    "    Calculate class weights for imbalanced dataset\n",
    "    Returns:\n",
    "        Tensor of shape [num_classes] with class weights\n",
    "    \"\"\"\n",
    "    labels_tensor = torch.tensor([l.item() if isinstance(l, torch.Tensor) else l for l in label_list])\n",
    "    class_counts = torch.bincount(labels_tensor)\n",
    "    total = class_counts.sum().float()\n",
    "    class_weights = total / (class_counts.float() + 1e-8)\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_counts)  # Normalize\n",
    "    return class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.506686Z",
     "iopub.status.busy": "2025-11-18T12:13:57.506483Z",
     "iopub.status.idle": "2025-11-18T12:13:57.523906Z",
     "shell.execute_reply": "2025-11-18T12:13:57.523217Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.506671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_parallel(codelm_embedd_path, graph_embedd_path, adjmat_path, meta_path, device):\n",
    "    codelm_emb_tensor_all = torch.load(codelm_embedd_path)\n",
    "    graph_emb_tensor_all = torch.load(graph_embedd_path)\n",
    "    adj_tensor_all = torch.load(adjmat_path)\n",
    "\n",
    "    with open(meta_path, 'r') as f:\n",
    "        meta_data = json.load(f)\n",
    "\n",
    "    labels_all = meta_data['labels']\n",
    "    partitions = meta_data['partition']\n",
    "\n",
    "    train_idx  = [i for i, p in enumerate(partitions) if p == 'train']\n",
    "    valid_idx  = [i for i, p in enumerate(partitions) if p == 'valid']\n",
    "    test_idx  = [i for i, p in enumerate(partitions) if p == 'test']\n",
    "    \n",
    "    def select_indices(indices):\n",
    "        return (\n",
    "            [codelm_emb_tensor_all[i].to(device) for i in indices],\n",
    "            [graph_emb_tensor_all[i].to(device) for i in indices],\n",
    "            [adj_tensor_all[i].to(device) for i in indices],\n",
    "            [torch.tensor(labels_all[i], dtype=torch.long).numpy() for i in indices]\n",
    "        )\n",
    "\n",
    "    def shuffle_dataset(embedd_list, adj_list, label_list, indices):\n",
    "        combined = list(zip(embedd_list, adj_list, label_list, indices))\n",
    "        random.shuffle(combined)\n",
    "        shuffled_embedd_list, shuffled_adj_list, shuffled_label_list, shuffled_indices = zip(*combined)\n",
    "        return (\n",
    "            list(shuffled_embedd_list),\n",
    "            list(shuffled_adj_list),\n",
    "            list(shuffled_label_list),\n",
    "            list(shuffled_indices)\n",
    "        )\n",
    "\n",
    "    if len(train_idx) > 0:\n",
    "        train_codelm_emb, train_graph_emb, train_adj, train_lbl = select_indices(train_idx)\n",
    "        train_codelm_emb, train_graph_emb, train_adj, train_lbl = shuffle_dataset(train_codelm_emb, train_graph_emb, train_adj, train_lbl)\n",
    "    else:\n",
    "        train_codelm_emb, train_graph_emb, train_adj, train_lbl = [], [], [], []\n",
    "\n",
    "    if len(valid_idx) > 0:\n",
    "        valid_codelm_emb, valid_graph_emb, valid_adj, valid_lbl = select_indices(valid_idx)\n",
    "        valid_codelm_emb, valid_graph_emb, valid_adj, valid_lbl = shuffle_dataset(valid_codelm_emb, valid_graph_emb, valid_adj, valid_lbl)\n",
    "    else:\n",
    "        valid_codelm_emb, valid_graph_emb, valid_adj, valid_lbl = [], [], [], []\n",
    "    \n",
    "    if len(test_idx) > 0:\n",
    "        test_codelm_emb, test_graph_emb, test_adj, test_lbl = select_indices(test_idx)\n",
    "        test_codelm_emb, test_graph_emb, test_adj, test_lbl = shuffle_dataset(test_codelm_emb, test_graph_emb, test_adj, test_lbl)\n",
    "    else:\n",
    "        test_codelm_emb, test_graph_emb, test_adj, test_lbl = [], [], [], []\n",
    "    \n",
    "    return {\n",
    "        'train': (train_codelm_emb, train_graph_emb, train_adj, train_lbl),\n",
    "        'valid': (valid_codelm_emb, valid_graph_emb, valid_adj, valid_lbl),\n",
    "        'test': (test_codelm_emb, test_graph_emb, test_adj, test_lbl)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.524815Z",
     "iopub.status.busy": "2025-11-18T12:13:57.524562Z",
     "iopub.status.idle": "2025-11-18T12:13:57.544114Z",
     "shell.execute_reply": "2025-11-18T12:13:57.543395Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.524792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def merge_adversarial_dataset(original_test, adversarial_test):\n",
    "    codelm_embedd_test, graph_embedd_test, adjmat_test, label_test = original_test\n",
    "    adv_codelm_embedd_test, adv_graph_embedd_test, adv_adjmat_test, adv_label_test = adversarial_test\n",
    "\n",
    "    # Split non-vulnerable samples\n",
    "    nonvul_codelm, nonvul_graph, nonvul_adj, nonvul_lbl = [], [], [], []\n",
    "    for emb_c, emb_g, adj, lbl in zip(codelm_embedd_test, graph_embedd_test, adjmat_test, label_test):\n",
    "        if int(lbl) != 1:\n",
    "            nonvul_codelm.append(emb_c)\n",
    "            nonvul_graph.append(emb_g)\n",
    "            nonvul_adj.append(adj)\n",
    "            nonvul_lbl.append(lbl)\n",
    "\n",
    "    print(f\"ðŸ§© Non-vulnerable samples: {len(nonvul_lbl)}\")\n",
    "    print(f\"âš”ï¸  Adversarial samples to add: {len(adv_label_test)}\")\n",
    "\n",
    "    # Merge dataset\n",
    "    merged_codelm = nonvul_codelm + list(adv_codelm_embedd_test)\n",
    "    merged_graph = nonvul_graph + list(adv_graph_embedd_test)\n",
    "    merged_adj = nonvul_adj + list(adv_adjmat_test)\n",
    "    merged_lbl = nonvul_lbl + list(adv_label_test)\n",
    "\n",
    "    # Shuffle dataset\n",
    "    combined = list(zip(merged_codelm, merged_graph, merged_adj, merged_lbl))\n",
    "    random.shuffle(combined)\n",
    "    sh_codelm, sh_graph, sh_adj, sh_lbl = zip(*combined)\n",
    "\n",
    "    return list(sh_codelm), list(sh_graph), list(sh_adj), list(sh_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.545127Z",
     "iopub.status.busy": "2025-11-18T12:13:57.544867Z",
     "iopub.status.idle": "2025-11-18T12:13:57.563661Z",
     "shell.execute_reply": "2025-11-18T12:13:57.562975Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.545110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:13:57.564543Z",
     "iopub.status.busy": "2025-11-18T12:13:57.564299Z",
     "iopub.status.idle": "2025-11-18T12:14:58.973666Z",
     "shell.execute_reply": "2025-11-18T12:14:58.973031Z",
     "shell.execute_reply.started": "2025-11-18T12:13:57.564522Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_benign1_dataset = load_parallel(codelm_embedd_path=\"/kaggle/input/primevul-vuln-data/train_benign_part1/aggregated_codet5_embeddings.pt\",\n",
    "                                      graph_embedd_path=\"/kaggle/input/primevul-vuln-data/train_benign_part1/n2v_node_embeddings.pt\",\n",
    "                                      adjmat_path=\"/kaggle/input/primevul-vuln-data/train_benign_part1/adj_matrices.pt\",\n",
    "                                      meta_path=\"/kaggle/input/primevul-vuln-data/train_benign_part1/AlUNed.json\",\n",
    "                                      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_benign2_dataset = load_parallel(codelm_embedd_path=\"/kaggle/input/primevul-vuln-data/train_benign_part2/aggregated_codet5_embeddings.pt\",\n",
    "                                      graph_embedd_path=\"/kaggle/input/primevul-vuln-data/train_benign_part2/n2v_node_embeddings.pt\",\n",
    "                                      adjmat_path=\"/kaggle/input/primevul-vuln-data/train_benign_part2/adj_matrices.pt\",\n",
    "                                      meta_path=\"/kaggle/input/primevul-vuln-data/train_benign_part2/AlUNed.json\",\n",
    "                                      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_vulnerable_dataset = load_parallel(codelm_embedd_path=\"/kaggle/input/primevul-vuln-data/train_vuln/aggregated_codet5_embeddings.pt\",\n",
    "                                         graph_embedd_path=\"/kaggle/input/primevul-vuln-data/train_vuln/n2v_node_embeddings.pt\",\n",
    "                                         adjmat_path=\"/kaggle/input/primevul-vuln-data/train_vuln/adj_matrices.pt\",\n",
    "                                         meta_path=\"/kaggle/input/primevul-vuln-data/train_vuln/AlUNed.json\",\n",
    "                                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:14:58.974728Z",
     "iopub.status.busy": "2025-11-18T12:14:58.974508Z",
     "iopub.status.idle": "2025-11-18T12:14:59.236677Z",
     "shell.execute_reply": "2025-11-18T12:14:59.236111Z",
     "shell.execute_reply.started": "2025-11-18T12:14:58.974712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = load_parallel(codelm_embedd_path=\"/kaggle/input/primevul-vuln-data/eatvul_primevul_covul/aggregated_codet5_embeddings.pt\",\n",
    "                             graph_embedd_path=\"/kaggle/input/primevul-vuln-data/eatvul_primevul_covul/n2v_node_embeddings.pt\",\n",
    "                             adjmat_path=\"/kaggle/input/primevul-vuln-data/eatvul_primevul_covul/adj_matrices.pt\",\n",
    "                             meta_path=\"/kaggle/input/primevul-vuln-data/eatvul_primevul_covul/AlUNed.json\",\n",
    "                             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:14:59.237689Z",
     "iopub.status.busy": "2025-11-18T12:14:59.237437Z",
     "iopub.status.idle": "2025-11-18T12:14:59.241294Z",
     "shell.execute_reply": "2025-11-18T12:14:59.240496Z",
     "shell.execute_reply.started": "2025-11-18T12:14:59.237665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokens_embedd_train1, graph_embedd_train1, adjmat_train1, label_train1 = train_benign1_dataset['train']\n",
    "tokens_embedd_train2, graph_embedd_train2, adjmat_train2, label_train2 = train_benign2_dataset['train']\n",
    "tokens_embedd_train3, graph_embedd_train3, adjmat_train3, label_train3 = train_vulnerable_dataset['train']\n",
    "tokens_embedd_test, graph_embedd_test, adjmat_test, label_test = test_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokens_embedd_train = tokens_embedd_train1 + tokens_embedd_train2 + tokens_embedd_train3\n",
    "graph_embedd_train = graph_embedd_train1 + graph_embedd_train2 + graph_embedd_train3\n",
    "adjmat_train = adjmat_train1 + adjmat_train2 + adjmat_train3\n",
    "label_train = label_train1 + label_train2 + label_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:14:59.242499Z",
     "iopub.status.busy": "2025-11-18T12:14:59.242214Z",
     "iopub.status.idle": "2025-11-18T12:14:59.272051Z",
     "shell.execute_reply": "2025-11-18T12:14:59.271424Z",
     "shell.execute_reply.started": "2025-11-18T12:14:59.242477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ----------------- Helpers -----------------\n",
    "def _to_tensor(x, dtype=None, device=None):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        t = torch.from_numpy(x)\n",
    "    elif isinstance(x, torch.Tensor):\n",
    "        t = x\n",
    "    else:\n",
    "        t = torch.tensor(x)\n",
    "    if dtype is not None:\n",
    "        t = t.to(dtype)\n",
    "    if device is not None:\n",
    "        t = t.to(device)\n",
    "    return t\n",
    "\n",
    "def _prepare_edge_index(edge_index):\n",
    "    \"\"\" Ensure edge_index is LongTensor with shape [2, num_edges]. \"\"\"\n",
    "    if isinstance(edge_index, np.ndarray):\n",
    "        ei = torch.from_numpy(edge_index)\n",
    "    elif isinstance(edge_index, torch.Tensor):\n",
    "        ei = edge_index\n",
    "    else:\n",
    "        ei = torch.tensor(edge_index)\n",
    "    ei = ei.long()\n",
    "    if ei.dim() == 2 and ei.shape[0] == 2:\n",
    "        return ei.contiguous()\n",
    "    if ei.dim() == 2 and ei.shape[1] == 2:\n",
    "        return ei.t().contiguous()\n",
    "    raise ValueError(f\"edge_index has unsupported shape {ei.shape}\")\n",
    "\n",
    "def create_data_from_sample(graph_emb, edge_index, token_emb, label=None):\n",
    "    x = _to_tensor(graph_emb, dtype=torch.float)\n",
    "    ei = _prepare_edge_index(edge_index)\n",
    "    tk = _to_tensor(token_emb, dtype=torch.float)\n",
    "    data = Data(x=x, edge_index=ei, tokens=tk)\n",
    "    if label is not None:\n",
    "        data.y = _to_tensor(label, dtype=torch.long)\n",
    "    return data\n",
    "\n",
    "# ----------------- Class weight fallback -----------------\n",
    "def _compute_class_weights(labels, device):\n",
    "    \"\"\"Fallback compute class weights if calculate_class_weights is not available.\n",
    "       labels: 1D array-like integers\"\"\"\n",
    "    labels = np.asarray(labels)\n",
    "    classes, counts = np.unique(labels, return_counts=True)\n",
    "    # weight = total / (num_classes * count)\n",
    "    total = labels.shape[0]\n",
    "    num_classes = classes.shape[0]\n",
    "    weights = np.zeros(num_classes, dtype=np.float32)\n",
    "    for i, c in enumerate(classes):\n",
    "        weights[c] = total / (num_classes * counts[i])\n",
    "    return torch.tensor(weights, dtype=torch.float, device=device)\n",
    "\n",
    "# ----------------- Core: train single epoch (used inside fold) -----------------\n",
    "def _train_one_epoch(model, loader, optimizer, loss_fn, device, aux_on=True, aux_weight=0.5, verbose=False):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    pbar = tqdm(loader, desc=\"train\", leave=False) if verbose else loader\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        xc_logis, xo_logis, xco_logis = model(batch, eval_random=True)\n",
    "        if batch.y is None:\n",
    "            raise ValueError(\"Batch item must contain .y\")\n",
    "        y = batch.y.view(-1).to(device)\n",
    "        loss_main = loss_fn(xco_logis, y)\n",
    "        if aux_on:\n",
    "            loss_c = loss_fn(xc_logis, y)\n",
    "            loss_o = loss_fn(xo_logis, y)\n",
    "            loss = loss_main + aux_weight * (loss_c + loss_o)\n",
    "        else:\n",
    "            loss = loss_main\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        bs = y.size(0)\n",
    "        epoch_loss += loss.item() * bs\n",
    "        total += bs\n",
    "        preds = xo_logis.argmax(dim=1).detach().cpu().numpy()\n",
    "        labs = y.detach().cpu().numpy()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labs.tolist())\n",
    "        if verbose:\n",
    "            pbar.set_postfix({'batch_loss': loss.item()})\n",
    "    avg_loss = epoch_loss / max(1, total)\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds) if total>0 else 0.0\n",
    "    return avg_loss, bal_acc\n",
    "\n",
    "# ----------------- Core: evaluate on loader -----------------\n",
    "def _eval_model(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            xc_logis, xo_logis, xco_logis = model(batch, eval_random=False)\n",
    "            y = batch.y.view(-1).to(device)\n",
    "            preds = xo_logis.argmax(dim=1).detach().cpu().numpy()\n",
    "            labs = y.detach().cpu().numpy()\n",
    "            all_preds.extend(preds.tolist())\n",
    "            all_labels.extend(labs.tolist())\n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "def _save_confusion_matrix(y_true, y_pred, filename=\"confusion_matrix.png\", labels=[\"Class 0\", \"Class 1\"]):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"ðŸ“ Saved confusion matrix to: {filename}\")\n",
    "\n",
    "# ----------------- Main k-fold training function -----------------\n",
    "def train_kfold_causalgat(\n",
    "    token_emb_list, graph_emb_list, edgeindex_list, label_list, device,\n",
    "    n_splits=5,\n",
    "    epochs=100,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-3,\n",
    "    batch_size=32,\n",
    "    aux_weight=0.7,\n",
    "    aux_on=True,\n",
    "    patience=20,\n",
    "    head=8,\n",
    "    dropout=0.3,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    emb_list, edgeindex_list, label_list: parallel lists (or arrays)\n",
    "    Returns: dict containing per-fold metrics and saved best model states\n",
    "    \"\"\"\n",
    "    labels_np = np.asarray(label_list).astype(int)\n",
    "    unique_labels = np.unique(labels_np)\n",
    "    num_classes = int(unique_labels.max()) + 1\n",
    "\n",
    "    # Choose average strategy for precision/recall:\n",
    "    avg_strategy = 'binary' if num_classes == 2 else 'macro'\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    fold_results = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(labels_np)), labels_np), start=1):\n",
    "        if verbose:\n",
    "            print(f\"\\n--- Fold {fold_idx}/{n_splits} ---\")\n",
    "        # Build train/val datasets\n",
    "        train_dataset = [create_data_from_sample(graph_emb_list[i], edgeindex_list[i], token_emb_list[i], label_list[i]) for i in train_idx]\n",
    "        val_dataset   = [create_data_from_sample(graph_emb_list[i], edgeindex_list[i], token_emb_list[i], label_list[i]) for i in val_idx]\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # compute class weights for this fold\n",
    "        try:\n",
    "            # try user-provided helper\n",
    "            cw = calculate_class_weights([label_list[i] for i in train_idx], device)\n",
    "            if not isinstance(cw, torch.Tensor):\n",
    "                cw = torch.tensor(cw, dtype=torch.float, device=device)\n",
    "        except Exception:\n",
    "            cw = _compute_class_weights([label_list[i] for i in train_idx], device)\n",
    "\n",
    "        # model init (infer num_features from first training sample)\n",
    "        sample_feat = train_dataset[0].x.shape[1]\n",
    "        model = CausalGAT(num_features=sample_feat, num_classes=num_classes, fusion_mode='cross_atten', head=head, dropout=dropout).to(device)\n",
    "\n",
    "        loss_fn = nn.NLLLoss(weight=cw)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "        best_val_score = -1.0  # we use balanced acc as selection criterion\n",
    "        best_state = None\n",
    "        best_epoch = -1\n",
    "        no_imp = 0\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "            # train one epoch\n",
    "            train_loss, _ = _train_one_epoch(\n",
    "                model, train_loader, optimizer, loss_fn, device,\n",
    "                aux_on=aux_on, aux_weight=aux_weight, verbose=verbose\n",
    "            )\n",
    "            scheduler.step()\n",
    "\n",
    "            # eval on validation\n",
    "            y_val, y_pred = _eval_model(model, val_loader, device)\n",
    "            prec = precision_score(y_val, y_pred, average=avg_strategy, zero_division=0)\n",
    "            rec  = recall_score(y_val, y_pred, average=avg_strategy, zero_division=0)\n",
    "            bal_acc = balanced_accuracy_score(y_val, y_pred)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch:03d} | TrainLoss: {train_loss:.4f} | BalAcc: {bal_acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f}\")\n",
    "\n",
    "            # early stopping on balanced accuracy (you can change to other metric)\n",
    "            if bal_acc > best_val_score:\n",
    "                best_val_score = bal_acc\n",
    "                best_state = copy.deepcopy(model.state_dict())\n",
    "                best_epoch = epoch\n",
    "                no_imp = 0\n",
    "            else:\n",
    "                no_imp += 1\n",
    "\n",
    "            if no_imp >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping (no improvement in {patience} epochs). Best val BalAcc={best_val_score:.4f} at epoch {best_epoch}\")\n",
    "                break\n",
    "\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        # After fold training, evaluate best model on val set\n",
    "        if best_state is not None:\n",
    "            torch.save(best_state, f\"/kaggle/working/best_model_fold{fold_idx}.pt\")\n",
    "            model.load_state_dict(best_state)\n",
    "        \n",
    "        y_val, y_pred = _eval_model(model, val_loader, device)\n",
    "        prec = precision_score(y_val, y_pred, average=avg_strategy, zero_division=0)\n",
    "        rec  = recall_score(y_val, y_pred, average=avg_strategy, zero_division=0)\n",
    "        bal_acc = balanced_accuracy_score(y_val, y_pred)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold {fold_idx} results -> BalAcc: {bal_acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold_idx,\n",
    "            'bal_acc': bal_acc,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'best_epoch': best_epoch\n",
    "        })\n",
    "\n",
    "    # aggregate metrics\n",
    "    precisions = [f['precision'] for f in fold_results]\n",
    "    recalls = [f['recall'] for f in fold_results]\n",
    "    bal_accs = [f['bal_acc'] for f in fold_results]\n",
    "\n",
    "    summary = {\n",
    "        'folds': fold_results,\n",
    "        'precision_mean': float(np.mean(precisions)),\n",
    "        'precision_std': float(np.std(precisions)),\n",
    "        'recall_mean': float(np.mean(recalls)),\n",
    "        'recall_std': float(np.std(recalls)),\n",
    "        'bal_acc_mean': float(np.mean(bal_accs)),\n",
    "        'bal_acc_std': float(np.std(bal_accs))\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n=== K-Fold Summary ===\")\n",
    "        print(f\"Precision: {summary['precision_mean']:.4f} Â± {summary['precision_std']:.4f}\")\n",
    "        print(f\"Recall   : {summary['recall_mean']:.4f} Â± {summary['recall_std']:.4f}\")\n",
    "        print(f\"BalAcc   : {summary['bal_acc_mean']:.4f} Â± {summary['bal_acc_std']:.4f}\")\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T12:14:59.272988Z",
     "iopub.status.busy": "2025-11-18T12:14:59.272730Z",
     "iopub.status.idle": "2025-11-18T12:14:59.289543Z",
     "shell.execute_reply": "2025-11-18T12:14:59.288826Z",
     "shell.execute_reply.started": "2025-11-18T12:14:59.272966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_kfold_causalgat(token_emb_list, graph_emb_list, edgeindex_list, label_list, device, kfold=5, best_state=None):\n",
    "    \"\"\"\n",
    "    emb_list, edgeindex_list, label_list: parallel lists (or arrays)\n",
    "    Returns: dict containing per-fold metrics and saved best model states\n",
    "    \"\"\"\n",
    "    for fold_idx in range(1, kfold + 1):\n",
    "        # Build test datasets\n",
    "        test_dataset = [create_data_from_sample(graph_emb_list[i], edgeindex_list[i], token_emb_list[i], label_list[i]) for i in range(len(label_list))]\n",
    "        test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Evaluate best model on test set\n",
    "        model = CausalGAT(num_features=200, num_classes=2, fusion_mode='cross_atten', head=8, dropout=0.5).to(device)\n",
    "        if best_state is None:\n",
    "            model.load_state_dict(torch.load(f\"/kaggle/working/best_model_fold{fold_idx}.pt\", map_location=device))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(best_state, map_location=device))\n",
    "        \n",
    "        y_val, y_pred = _eval_model(model, test_loader, device)\n",
    "        _save_confusion_matrix(y_val, y_pred, f\"/kaggle/working/fold{fold_idx}_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_kfold_causalgat(token_emb_list=tokens_embedd_train, graph_emb_list=graph_embedd_train, edgeindex_list=adjmat_train, label_list=label_train, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-18T12:15:00.099881Z",
     "iopub.status.idle": "2025-11-18T12:15:00.100246Z",
     "shell.execute_reply": "2025-11-18T12:15:00.100062Z",
     "shell.execute_reply.started": "2025-11-18T12:15:00.100045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_kfold_causalgat(token_emb_list=tokens_embedd_test, graph_emb_list=graph_embedd_test, edgeindex_list=adjmat_test, label_list=label_test, device=device)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8469771,
     "sourceId": 13354026,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8716470,
     "sourceId": 13702445,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8286290,
     "sourceId": 13864516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
